"use strict";(self.webpackChunkacd=self.webpackChunkacd||[]).push([[5997],{7955:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"task/sensor_data_processing/Geometric-OGM","title":"Geometric Point Cloud Occupancy Grid Mapping","description":"ROS1","source":"@site/docs/task/02_sensor_data_processing/03_Geometric-OGM.md","sourceDirName":"task/02_sensor_data_processing","slug":"/task/sensor_data_processing/Geometric-OGM","permalink":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/Geometric-OGM","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/task/02_sensor_data_processing/03_Geometric-OGM.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{},"sidebar":"taskSidebar","previous":{"title":"Deep Learning-based Point Cloud Occupancy Grid Mapping","permalink":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/Deep-OGM"},"next":{"title":"Localization","permalink":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/Localization"}}');var t=i(4848),r=i(8453);const l={},o="Geometric Point Cloud Occupancy Grid Mapping",c={},a=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Setup Instructions",id:"setup-instructions",level:2},{value:"1. Clone the Repository and Navigate to the Workspace",id:"1-clone-the-repository-and-navigate-to-the-workspace",level:3},{value:"2. Clone the Necessary Packages",id:"2-clone-the-necessary-packages",level:3},{value:"3. Download the Required Bag File",id:"3-download-the-required-bag-file",level:3},{value:"4. Build the Workspace",id:"4-build-the-workspace",level:3},{value:"5. Launch the ROS Environment with RViz and Rosbag",id:"5-launch-the-ros-environment-with-rviz-and-rosbag",level:3},{value:"Expected Terminal Output:",id:"expected-terminal-output",level:4},{value:"Expected RViz Visualization:",id:"expected-rviz-visualization",level:4},{value:"RViz Navigation Controls:",id:"rviz-navigation-controls",level:4},{value:"Definitions",id:"definitions",level:2},{value:"ROS Object Definitions",id:"ros-object-definitions",level:3},{value:"ika ROS Object Definition",id:"ika-ros-object-definition",level:4},{value:"IkaObject.msg",id:"ikaobjectmsg",level:5},{value:"object_definitions.h",id:"object_definitionsh",level:5},{value:"ika ROS Object Lists Definition",id:"ika-ros-object-lists-definition",level:4},{value:"IkaObjectList.msg",id:"ikaobjectlistmsg",level:5},{value:"Tasks",id:"tasks",level:2},{value:"Task 1: Set Up and Test the ROS Workspace",id:"task-1-set-up-and-test-the-ros-workspace",level:3},{value:"Steps:",id:"steps",level:4},{value:"Task 2: Separate Obstacles from Ground",id:"task-2-separate-obstacles-from-ground",level:3},{value:"Steps:",id:"steps-1",level:4},{value:"Task 3: Complete the Geometric Inverse Sensor Model (ISM)",id:"task-3-complete-the-geometric-inverse-sensor-model-ism",level:3},{value:"Understanding the Inverse Sensor Model",id:"understanding-the-inverse-sensor-model",level:4},{value:"Steps:",id:"steps-2",level:4},{value:"Wrap-up",id:"wrap-up",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"geometric-point-cloud-occupancy-grid-mapping",children:"Geometric Point Cloud Occupancy Grid Mapping"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:"https://img.shields.io/badge/ROS1-blue",alt:"ROS1"})}),"\n",(0,t.jsxs)(n.p,{children:["Occupancy grid mapping is a cornerstone technique in autonomous vehicle perception systems, enabling the creation of a probabilistic representation of the environment. By converting raw LiDAR point clouds into structured grid maps, vehicles can efficiently navigate, detect obstacles, and make informed decisions. This workshop delves into ",(0,t.jsx)(n.strong,{children:"geometric inverse sensor models"})," for generating occupancy grids from LiDAR data within the ",(0,t.jsx)(n.strong,{children:"Robot Operating System (ROS)"})," framework. Participants will gain hands-on experience in implementing and visualizing occupancy grid maps, understanding the nuances of sensor data processing, and leveraging ROS tools for effective perception."]}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By the end of this workshop, participants will be able to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Understand Object Definitions in ROS:"})," Comprehend how objects are defined and structured within ROS messages."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Visualize LiDAR Point Clouds in RViz:"})," Utilize RViz to visualize and interpret raw LiDAR data."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Launch and Operate ROS Nodes:"})," Execute ROS nodes that apply occupancy grid mapping algorithms to raw sensor data."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Implement Geometric Inverse Sensor Models:"})," Develop and integrate simple geometric inverse sensor models for occupancy grid mapping."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Separate Ground from Obstacles:"})," Use existing ROS packages to preprocess point clouds by distinguishing ground points from obstacles."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Basic Knowledge of ROS:"})," Familiarity with ROS concepts, including nodes, topics, and messages."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"C++ Programming Skills:"})," Ability to read and modify C++ code."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Understanding of LiDAR Technology:"})," Basic comprehension of LiDAR sensors and point cloud data."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Experience with RViz:"})," Prior experience using RViz for visualization is beneficial but not mandatory."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"setup-instructions",children:"Setup Instructions"}),"\n",(0,t.jsx)(n.h3,{id:"1-clone-the-repository-and-navigate-to-the-workspace",children:"1. Clone the Repository and Navigate to the Workspace"}),"\n",(0,t.jsx)(n.p,{children:"Ensure you have access to the necessary ROS workspace. Navigate to your workspace directory:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd ~/catkin_workspace/src\n"})}),"\n",(0,t.jsx)(n.h3,{id:"2-clone-the-necessary-packages",children:"2. Clone the Necessary Packages"}),"\n",(0,t.jsxs)(n.p,{children:["Clone the ",(0,t.jsx)(n.code,{children:"pointcloud_ogm"})," package along with its dependencies:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/ika-rwth-aachen/acdc.git\ncd acdc/catkin_workspace/src\ngit clone https://github.com/ika-rwth-aachen/acdc.git\n"})}),"\n",(0,t.jsx)(n.h3,{id:"3-download-the-required-bag-file",children:"3. Download the Required Bag File"}),"\n",(0,t.jsx)(n.p,{children:"Download the LiDAR data recording from Campus Melaten in Aachen:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"wget -O lidar_campus_melaten.bag https://rwth-aachen.sciebo.de/s/udlMYloXpCdVtyp/download\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Alternatively, access the bag file directly ",(0,t.jsx)(n.a,{href:"https://rwth-aachen.sciebo.de/s/udlMYloXpCdVtyp",children:(0,t.jsx)(n.strong,{children:"here"})})," (approx. 1.5 GB). Save the file to the local directory ",(0,t.jsx)(n.code,{children:"${REPOSITORY}/bag"})," on your host machine, which is mounted to ",(0,t.jsx)(n.code,{children:"~/bag"})," within the Docker container."]}),"\n",(0,t.jsx)(n.h3,{id:"4-build-the-workspace",children:"4. Build the Workspace"}),"\n",(0,t.jsx)(n.p,{children:"Navigate to your workspace and build the packages:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd ~/catkin_workspace\ncatkin build\nsource devel/setup.bash\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," If you encounter a compilation error similar to ",(0,t.jsx)(n.code,{children:"g++: internal compiler error: Killed (program cc1plus)"}),", it indicates excessive resource consumption. To resolve this, disable parallel building:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"catkin build -j 1\nsource devel/setup.bash\n"})}),"\n",(0,t.jsx)(n.h3,{id:"5-launch-the-ros-environment-with-rviz-and-rosbag",children:"5. Launch the ROS Environment with RViz and Rosbag"}),"\n",(0,t.jsxs)(n.p,{children:["To streamline the process of launching ",(0,t.jsx)(n.code,{children:"roscore"}),", ",(0,t.jsx)(n.code,{children:"rviz"}),", and ",(0,t.jsx)(n.code,{children:"rosbag play"})," simultaneously, utilize the provided launch file:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"roslaunch pointcloud_ogm GeometricISM.launch\n"})}),"\n",(0,t.jsx)(n.p,{children:"This command performs the following actions:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Rosbag Playback:"})," Plays the ",(0,t.jsx)(n.code,{children:"lidar_campus_melaten.bag"})," file."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"RViz Visualization:"})," Launches RViz with pre-configured displays for point clouds and occupancy grids."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"expected-terminal-output",children:"Expected Terminal Output:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"rosuser@******:~/ws/catkin_workspace$ roslaunch pointcloud_ogm GeometricISM.launch\n... logging to /home/rosuser/.ros/log/52caca3c-4495-11ec-82b7-b49691b9ac50/roslaunch-I2102656-linux-14791.log\nChecking log directory for disk usage. This may take a while.\nPress Ctrl-C to interrupt\nDone checking log file disk usage. Usage is <1GB.\n\nstarted roslaunch server http://******:34069/\nros_comm version 1.15.11\n...\nstarted core service [/rosout]\nrosbag play --loop ../bag/lidar_campus_melaten.bag\n[ INFO] [1636816879.584949638]: Opening ../bag/lidar_campus_melaten.bag\n\nWaiting 0.2 seconds after advertising topics... done.\n\nHit space to toggle paused, or 's' to step.\n [RUNNING]  Bag Time: 1580916332.230592   Duration: 0.820823 / 119.955245\n"})}),"\n",(0,t.jsx)(n.h4,{id:"expected-rviz-visualization",children:"Expected RViz Visualization:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Image Segmentation",src:i(7274).A+"",width:"1200",height:"846"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Original Point Cloud:"})," Colored by the intensity of reflections."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Obstacle Point Cloud:"})," Colored in purple."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Ground Points:"})," Visualized separately (de-)activated via the RViz interface."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," Adjust visualization settings such as ",(0,t.jsx)(n.code,{children:"Size"}),", ",(0,t.jsx)(n.code,{children:"Style"}),", ",(0,t.jsx)(n.code,{children:"Decay Time"}),", and ",(0,t.jsx)(n.code,{children:"Color Transformer"})," in the ",(0,t.jsx)(n.code,{children:"PointCloud2"})," tab for enhanced clarity."]}),"\n",(0,t.jsx)(n.h4,{id:"rviz-navigation-controls",children:"RViz Navigation Controls:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Left Mouse Button:"})," Rotate the view around the Z-axis."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Middle Mouse Button:"})," Pan the camera along the XY plane."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Right Mouse Button:"})," Zoom in and out."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Scroll Wheel:"})," Incremental zoom in and out."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Congratulations!"})," You have successfully visualized the raw LiDAR data and are ready to implement the occupancy grid mapping algorithms in the subsequent tasks."]}),"\n",(0,t.jsx)(n.h2,{id:"definitions",children:"Definitions"}),"\n",(0,t.jsx)(n.h3,{id:"ros-object-definitions",children:"ROS Object Definitions"}),"\n",(0,t.jsx)(n.p,{children:"Understanding how objects are defined and structured within ROS is crucial for effective communication between nodes and for processing detection results."}),"\n",(0,t.jsx)(n.h4,{id:"ika-ros-object-definition",children:"ika ROS Object Definition"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.strong,{children:"ika"})," definitions for ROS messages and internal utilities are located in the ",(0,t.jsx)(n.a,{href:"https://github.com/ika-rwth-aachen/acdc/blob/main/catkin_workspace/src/dependencies/definitions",children:(0,t.jsx)(n.em,{children:"definitions"})})," package. Specifically:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ROS Message Files:"})," Located in ",(0,t.jsx)(n.code,{children:"definitions/msg"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Internal Definitions:"})," Found in ",(0,t.jsx)(n.code,{children:"~/ws/catkin_workspace/src/dependencies/definitions/include/definitions/utility"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"ikaobjectmsg",children:"IkaObject.msg"}),"\n",(0,t.jsx)(n.p,{children:"Defines the structure of a single 3D object detected by the LiDAR sensor."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"float32[] fMean               # State vector, containing attributes based on the chosen motion model\nfloat32[] fCovariance         # Covariance matrix, representing uncertainties in the state vector\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"fMean:"})," Represents the object's bounding box attributes such as position, velocity, acceleration, and orientation."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"fCovariance:"})," Captures the uncertainties associated with each attribute in ",(0,t.jsx)(n.code,{children:"fMean"}),", essential for tasks like object fusion."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," This assignment focuses solely on 3D object detection, thus only the ",(0,t.jsx)(n.code,{children:"fMean"})," vector is utilized to describe an object's bounding box."]}),"\n",(0,t.jsx)(n.h5,{id:"object_definitionsh",children:"object_definitions.h"}),"\n",(0,t.jsx)(n.p,{children:"Defines the enumeration of object types recognized by the system."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c++",children:"enum ika_object_types {\n  UNCLASSIFIED = 0,\n  PEDESTRIAN = 1,\n  BICYCLE = 2,\n  MOTORBIKE = 3,\n  CAR = 4,\n  TRUCK = 5,\n  VAN = 6,\n  BUS = 7,\n  ANIMAL = 8,\n  ROAD_OBSTACLE = 9,\n  TRAILER = 10,\n  TYPES_COUNT = 11\n};\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Key Object Classes:"})," For simplicity, this workshop focuses on the following classes:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"CAR"})," (ID: 4)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"PEDESTRIAN"})," (ID: 1)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"TRUCK"})," (ID: 5)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"BICYCLE"})," (ID: 2)"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Example Usage:"})," Access the ",(0,t.jsx)(n.code,{children:"CAR"})," type in code using ",(0,t.jsx)(n.code,{children:"definitions::ika_object_types::CAR"}),"."]}),"\n",(0,t.jsx)(n.h4,{id:"ika-ros-object-lists-definition",children:"ika ROS Object Lists Definition"}),"\n",(0,t.jsxs)(n.p,{children:["Handling multiple objects efficiently is essential for real-time applications. The ",(0,t.jsx)(n.code,{children:"IkaObjectList.msg"})," facilitates this by aggregating multiple ",(0,t.jsx)(n.code,{children:"IkaObject"})," messages into a single list."]}),"\n",(0,t.jsx)(n.h5,{id:"ikaobjectlistmsg",children:"IkaObjectList.msg"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"std_msgs/Header header\n\n# List meta information\nuint8 IdSource    # See definitions/utility/object_definitions.h for enum of sensors\n\n# Actual objects\nIkaObject[] objects\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"header:"})," Contains timestamp and frame information."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"IdSource:"})," Identifies the sensor source of the object detections."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"objects:"})," An array of ",(0,t.jsx)(n.code,{children:"IkaObject"})," messages, allowing the transmission of multiple detected objects simultaneously."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Benefits:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Efficiency:"})," Reduces the overhead of publishing individual object messages."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Organization:"})," Simplifies the management and processing of multiple detections from various sources."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"tasks",children:"Tasks"}),"\n",(0,t.jsx)(n.h3,{id:"task-1-set-up-and-test-the-ros-workspace",children:"Task 1: Set Up and Test the ROS Workspace"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Objective:"})," Initialize the ROS workspace, build the necessary packages, and launch the geometric inverse sensor model to visualize LiDAR point clouds and occupancy grids."]}),"\n",(0,t.jsx)(n.h4,{id:"steps",children:"Steps:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Start the Docker Container:"})}),"\n",(0,t.jsxs)(n.p,{children:["If not already running, start the Docker container by executing the ",(0,t.jsx)(n.code,{children:"docker/run.sh"})," script:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"./docker/run.sh\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Open a Shell in the Container:"})}),"\n",(0,t.jsxs)(n.p,{children:["Execute the ",(0,t.jsx)(n.code,{children:"docker/run.sh"})," script again from another terminal to open a new shell within the container."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Build the ROS Package and Source the Workspace:"})}),"\n",(0,t.jsxs)(n.p,{children:["Inside the Docker container, navigate to the ROS workspace and build the ",(0,t.jsx)(n.code,{children:"pointcloud_ogm"})," package:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"catkin build pointcloud_ogm\nsource devel/setup.bash\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.strong,{children:["Start ",(0,t.jsx)(n.code,{children:"roscore"})," and Play the Rosbag:"]})}),"\n",(0,t.jsxs)(n.p,{children:["Launch ",(0,t.jsx)(n.code,{children:"roscore"})," in the background and start playing the recorded LiDAR data:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"roscore&\nrosbag play --loop ../bag/lidar_campus_melaten.bag\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Expected Terminal Output:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"rosuser@:/home/rosuser/bag# rosbag info lidar_campus_melaten.bag \npath:        lidar_campus_melaten.bag \nversion:     2.0\nduration:    1:59s (119s)\nstart:       Feb 05 2020 15:25:31.41 (1580916331.41)\nend:         Feb 05 2020 15:27:31.37 (1580916451.37)\nsize:        1.5 GB\nmessages:    1200\ncompression: none [1199/1199 chunks]\ntypes:       sensor_msgs/PointCloud2 [1158d486dd51d683ce2f1be655c3c181]\n             tf2_msgs/TFMessage      [94810edda583a504dfda3829e70d7eec]\ntopics:      /points2     1199 msgs    : sensor_msgs/PointCloud2\n             /tf_static      1 msg     : tf2_msgs/TFMessage\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Launch the Geometric Inverse Sensor Model:"})}),"\n",(0,t.jsx)(n.p,{children:"Open another shell within the Docker container and execute the launch file to start the geometric inverse sensor model:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"source devel/setup.bash\nroslaunch pointcloud_ogm GeometricISM.launch\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Expected RViz Visualization:"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Image Segmentation",src:i(7274).A+"",width:"1200",height:"846"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Original Point Cloud:"})," Colored by reflection intensity."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Obstacle Point Cloud:"})," Colored in purple."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Ground Points:"})," Visualized separately, toggleable via RViz interface."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," Adjust visualization settings in RViz to enhance clarity and focus on specific aspects of the point cloud data."]}),"\n",(0,t.jsx)(n.h3,{id:"task-2-separate-obstacles-from-ground",children:"Task 2: Separate Obstacles from Ground"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Objective:"})," Utilize the ",(0,t.jsx)(n.code,{children:"PassThrough"})," filter from the PointCloudLibrary (PCL) to preprocess LiDAR point clouds by distinguishing ground points from obstacles, enhancing the accuracy of occupancy grid mapping."]}),"\n",(0,t.jsx)(n.h4,{id:"steps-1",children:"Steps:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Understand the Data Structure:"})}),"\n",(0,t.jsxs)(n.p,{children:["The LiDAR point clouds are published as ROS messages of type ",(0,t.jsx)(n.code,{children:"sensor_msgs/PointCloud2"}),", containing points described by ",(0,t.jsx)(n.code,{children:"x"}),", ",(0,t.jsx)(n.code,{children:"y"}),", ",(0,t.jsx)(n.code,{children:"z"})," coordinates, ",(0,t.jsx)(n.code,{children:"intensity"})," of reflection, and the vertical sensor ",(0,t.jsx)(n.code,{children:"ring"})," number."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Image Segmentation",src:i(424).A+"",width:"923",height:"742"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.strong,{children:["Use the ",(0,t.jsx)(n.code,{children:"PassThrough"})," Filter:"]})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"PassThrough"})," filter allows setting parameters to determine which points to retain or discard based on specified criteria."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Locate the Filter Configuration:"})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"PassThrough"})," filter is configured in the ",(0,t.jsx)(n.code,{children:"GeometricISM.launch"})," file:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-xml",children:'<node pkg="nodelet" type="nodelet" name="GroundExtraction" args="load pcl/PassThrough $(arg nodelet_manager)" output="screen">\n  <remap from="~input" to="/points2" />\n  <remap from="~output" to="/points2_obstacles" />\n  <rosparam>\n    filter_limit_negative: False\n    filter_field_name: x\n    filter_limit_min: -50\n    filter_limit_max: 50\n  </rosparam>\n</node>\n'})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Adjust Filter Parameters:"})}),"\n",(0,t.jsx)(n.p,{children:"Modify the parameters to effectively extract ground points while retaining obstacle points:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"filter_field_name:"})," Determines the axis to filter on (",(0,t.jsx)(n.code,{children:"x"}),", ",(0,t.jsx)(n.code,{children:"y"}),", or ",(0,t.jsx)(n.code,{children:"z"}),")."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"filter_limit_min & filter_limit_max:"})," Define the range of values to retain."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example Configuration:"})}),"\n",(0,t.jsxs)(n.p,{children:["To filter out ground points based on the ",(0,t.jsx)(n.code,{children:"z"})," axis:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-xml",children:'<node pkg="nodelet" type="nodelet" name="GroundExtraction" args="load pcl/PassThrough $(arg nodelet_manager)" output="screen">\n  <remap from="~input" to="/points2" />\n  <remap from="~output" to="/points2_obstacles" />\n  <rosparam>\n    filter_limit_negative: False\n    filter_field_name: z\n    filter_limit_min: 0.2\n    filter_limit_max: 10.0\n  </rosparam>\n</node>\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"filter_field_name:"})," ",(0,t.jsx)(n.code,{children:"z"})," to target vertical positioning."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"filter_limit_min:"})," 0.2 meters to exclude points very close to the ground."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"filter_limit_max:"})," 10.0 meters to include points within a reasonable detection range."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Apply the Changes:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Kill the Running Launch File:"})," Press ",(0,t.jsx)(n.code,{children:"CTRL-C"})," in the terminal where the launch file is running."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Restart the Launch File:"})," Apply the updated filter parameters by relaunching:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"roslaunch pointcloud_ogm GeometricISM.launch\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Verify in RViz:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Toggle Point Clouds:"})," In RViz, (de-)activate the visualization of ground and obstacle point clouds by toggling the checkboxes."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Assess Filtering Effectiveness:"})," Ensure that ground points are effectively separated from obstacle points, reducing noise and enhancing occupancy grid accuracy."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Image Segmentation",src:i(424).A+"",width:"923",height:"742"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," Fine-tuning filter parameters may require iterative adjustments based on the specific environment and LiDAR characteristics."]}),"\n",(0,t.jsx)(n.h3,{id:"task-3-complete-the-geometric-inverse-sensor-model-ism",children:"Task 3: Complete the Geometric Inverse Sensor Model (ISM)"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Objective:"})," Implement a simple geometric inverse sensor model to generate occupancy grid maps from preprocessed LiDAR point clouds using a binary Bayes filter."]}),"\n",(0,t.jsx)(n.h4,{id:"understanding-the-inverse-sensor-model",children:"Understanding the Inverse Sensor Model"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.strong,{children:"inverse sensor model (ISM)"})," translates sensor measurements (LiDAR point clouds) into a probabilistic occupancy grid. The geometric ISM relies on geometric relationships between the sensor and detected points to infer occupancy probabilities of grid cells."]}),"\n",(0,t.jsx)(n.h4,{id:"steps-2",children:"Steps:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Navigate to the ISM Implementation:"})}),"\n",(0,t.jsxs)(n.p,{children:["Open the ",(0,t.jsx)(n.code,{children:"GeometricISM.src"})," file located in ",(0,t.jsx)(n.code,{children:"~/ws/catkin_workspace/src/workshops/section_2/pointcloud_ogm/src/"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Understand the Processing Pipeline:"})}),"\n",(0,t.jsx)(n.p,{children:"The ISM implementation follows these steps:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Point Cloud Reception:"})," Receives a point cloud and triggers the ",(0,t.jsx)(n.code,{children:"messageCallback()"})," method."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Grid Map Initialization:"})," Initializes a grid map with all cells set to an occupancy probability of ",(0,t.jsx)(n.code,{children:"0.5"})," (indicating unknown occupancy)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Point Evaluation:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Line Formation:"})," For each point in the cloud, a line is drawn from the sensor to the point."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ISM Application:"})," The ISM determines occupancy probabilities for all grid cells along the line."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Bayes Filter Integration:"})," Combines ISM-derived probabilities with existing grid cell probabilities using a binary Bayes filter."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Grid Map Publication:"})," Publishes the updated occupancy grid map for visualization."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Implement the Geometric ISM:"})}),"\n",(0,t.jsx)(n.p,{children:"Locate the marked section in the code where the geometric ISM needs to be implemented:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-cpp",children:'    int cell = 0;\n    for (grid_map::LineIterator iterator(grid_map_measurement, start_position, end_position); !iterator.isPastEnd(); ++iterator) {\n      auto& occupancy_probability = grid_map_measurement.at("occupancy_probability", *iterator);\n\n      /* inverse sensor model:\n          - cell containing reflection point: 90% occupancy probability\n          - next two cells towards sensor: 80%, 50% occupancy probability\n          - remaining cells towards sensor: 10% occupancy probability\n      */\n      double p_ism;\n      // TASK 2 BEGIN\n      // ADD YOUR CODE HERE...\n\n      // TASK 2 END\n      \n      // combine probability from ism with previous probability in cell using binary Bayes filter\n      occupancy_probability = (p_ism*occupancy_probability) /\n                              (p_ism*occupancy_probability + (1-p_ism)*(1-occupancy_probability));\n\n      cell++;\n    }\n'})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Define the ISM Logic:"})}),"\n",(0,t.jsx)(n.p,{children:"Implement the ISM based on the specified probabilities:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Cell with Reflection Point:"})," 90% occupancy."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Next Two Cells Towards Sensor:"})," 80% and 50% occupancy."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Remaining Cells Towards Sensor:"})," 10% occupancy."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Implementation Example:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-cpp",children:"      // TASK 2 BEGIN\n      // Determine the relative position of the current cell to the reflection point\n      if (cell == 0) {\n        p_ism = 0.9; // Cell containing the reflection point\n      } else if (cell == 1) {\n        p_ism = 0.8; // First cell towards the sensor\n      } else if (cell == 2) {\n        p_ism = 0.5; // Second cell towards the sensor\n      } else {\n        p_ism = 0.1; // Remaining cells towards the sensor\n      }\n      // TASK 2 END\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Explanation:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsxs)(n.strong,{children:[(0,t.jsx)(n.code,{children:"cell == 0"}),":"]})," The first cell on the line (closest to the reflection point) is highly likely to be occupied."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsxs)(n.strong,{children:[(0,t.jsx)(n.code,{children:"cell == 1"})," & ",(0,t.jsx)(n.code,{children:"cell == 2"}),":"]})," The next two cells are less likely to be occupied but still have a significant probability."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsxs)(n.strong,{children:[(0,t.jsx)(n.code,{children:"else"}),":"]})," All other cells further towards the sensor have a low probability of being occupied."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Rebuild the ROS Workspace:"})}),"\n",(0,t.jsxs)(n.p,{children:["After implementing the ISM logic, rebuild the ",(0,t.jsx)(n.code,{children:"pointcloud_ogm"})," package:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd ~/catkin_workspace\ncatkin build pointcloud_ogm\nsource devel/setup.bash\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Launch the Geometric ISM:"})}),"\n",(0,t.jsx)(n.p,{children:"Restart the launch file to apply the changes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"roslaunch pointcloud_ogm GeometricISM.launch\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Visualize the Occupancy Grid:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Enable Grid Map Visualization:"}),' In RViz, ensure that the "Grid Map (GeometricISM)" display is activated.']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Assess Occupancy Map:"})," The grid map should now display occupied cells (inferred from LiDAR reflections) and free cells, reflecting the environment's layout."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Image Segmentation",src:i(4115).A+"",width:"1633",height:"879"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Observation:"})," The occupancy grid map accurately represents detected obstacles and open spaces, facilitating effective navigation and obstacle avoidance."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," The geometric ISM has limitations, such as sensitivity to sensor noise and inability to capture semantic information. Future tasks will explore deep learning-based models to address these deficiencies."]}),"\n",(0,t.jsx)(n.h2,{id:"wrap-up",children:"Wrap-up"}),"\n",(0,t.jsx)(n.p,{children:"In this workshop, you have:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Learned About Inverse Sensor Models:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Understood the role of inverse sensor models in occupancy grid mapping."}),"\n",(0,t.jsx)(n.li,{children:"Implemented a simple geometric ISM to translate LiDAR point clouds into probabilistic occupancy grids."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Utilized PCL Filters:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Applied the ",(0,t.jsx)(n.code,{children:"PassThrough"})," filter to preprocess point clouds by separating ground points from obstacles."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Visualized Data with RViz:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Configured RViz to display raw and processed LiDAR data alongside occupancy grids."}),"\n",(0,t.jsx)(n.li,{children:"Enhanced visualization settings to improve data interpretation."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Handled ROS Nodes and Launch Files:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Managed multiple ROS nodes using launch files for streamlined execution."}),"\n",(0,t.jsx)(n.li,{children:"Automated the process of playing rosbag files and launching visualization tools."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Identified Deficiencies in Geometric ISM:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Noted limitations such as susceptibility to sensor noise and lack of semantic understanding."}),"\n",(0,t.jsx)(n.li,{children:"Recognized the need for advanced models, such as deep learning-based approaches, to overcome these challenges."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"These foundational skills are essential for developing robust perception systems in autonomous vehicles, enabling accurate environment mapping and informed decision-making."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},424:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/rqt_points2_fields-dff6746afb378f1f2aaa96d4e8334bb9.png"},7274:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/rviz_points2-bc11882a83116e782b82bc543d166d66.png"},4115:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/result-046938243f7028666b2ec032d779a286.png"},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var s=i(6540);const t={},r=s.createContext(t);function l(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);