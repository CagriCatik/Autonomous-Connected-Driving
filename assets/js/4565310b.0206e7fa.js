"use strict";(self.webpackChunkacd=self.webpackChunkacd||[]).push([[4632],{5978:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"task/sensor_data_processing/Object-Detection","title":"Object Detection","description":"ROS1","source":"@site/docs/task/02_sensor_data_processing/05_Object-Detection.md","sourceDirName":"task/02_sensor_data_processing","slug":"/task/sensor_data_processing/Object-Detection","permalink":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/Object-Detection","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/task/02_sensor_data_processing/05_Object-Detection.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{},"sidebar":"taskSidebar","previous":{"title":"Localization","permalink":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/Localization"},"next":{"title":"Semantic Image Segmentation Applied on Camera Images","permalink":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/Semantic-Image-Segmentation"}}');var t=i(4848),c=i(8453);const l={},d="Object Detection",a={},o=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Setup Instructions",id:"setup-instructions",level:2},{value:"1. Clone the Repository and Navigate to the Workspace",id:"1-clone-the-repository-and-navigate-to-the-workspace",level:3},{value:"2. Clone the Necessary Packages",id:"2-clone-the-necessary-packages",level:3},{value:"3. Download the Required Bag File",id:"3-download-the-required-bag-file",level:3},{value:"4. Build the Workspace",id:"4-build-the-workspace",level:3},{value:"5. Launch the ROS Environment with RViz and Rosbag",id:"5-launch-the-ros-environment-with-rviz-and-rosbag",level:3},{value:"Expected Terminal Output:",id:"expected-terminal-output",level:4},{value:"Expected RViz Visualization:",id:"expected-rviz-visualization",level:4},{value:"RViz Navigation Controls:",id:"rviz-navigation-controls",level:4},{value:"Definitions",id:"definitions",level:2},{value:"ROS Object Definitions",id:"ros-object-definitions",level:3},{value:"ika ROS Object Definition",id:"ika-ros-object-definition",level:4},{value:"IkaObject.msg",id:"ikaobjectmsg",level:5},{value:"object_definitions.h",id:"object_definitionsh",level:5},{value:"ika ROS Object Lists Definition",id:"ika-ros-object-lists-definition",level:4},{value:"IkaObjectList.msg",id:"ikaobjectlistmsg",level:5},{value:"Measurement Data",id:"measurement-data",level:2},{value:"Downloading the LiDAR Bag File",id:"downloading-the-lidar-bag-file",level:3},{value:"Rosbag Inspection",id:"rosbag-inspection",level:3},{value:"Expected Output:",id:"expected-output",level:4},{value:"Rosbag Visualization",id:"rosbag-visualization",level:3},{value:"Using a Launch File for Visualization",id:"using-a-launch-file-for-visualization",level:4},{value:"Launch File: <code>start_rosbag_play_rviz.launch</code>",id:"launch-file-start_rosbag_play_rvizlaunch",level:5},{value:"Launching the Visualization",id:"launching-the-visualization",level:4},{value:"Expected RViz Window:",id:"expected-rviz-window",level:4},{value:"Lidar Detection",id:"lidar-detection",level:2},{value:"Package Structure",id:"package-structure",level:3},{value:"Understanding the Detection Pipeline",id:"understanding-the-detection-pipeline",level:3},{value:"Launching the Detection Node",id:"launching-the-detection-node",level:3},{value:"Visualizing Detected Objects in RViz",id:"visualizing-detected-objects-in-rviz",level:3},{value:"Tasks",id:"tasks",level:2},{value:"Task 1: Correcting Bounding Box Dimensions and Orientation",id:"task-1-correcting-bounding-box-dimensions-and-orientation",level:3},{value:"Steps:",id:"steps",level:4},{value:"Task 2: Assigning Correct Object Classes",id:"task-2-assigning-correct-object-classes",level:3},{value:"Steps:",id:"steps-1",level:4},{value:"Wrap-up",id:"wrap-up",level:2},{value:"References",id:"references",level:2}];function r(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,c.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"object-detection",children:"Object Detection"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:"https://img.shields.io/badge/ROS1-blue",alt:"ROS1"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"fag1",src:i(4445).A+"",width:"1276",height:"392"})}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsxs)(n.p,{children:["Object detection is a fundamental capability in autonomous vehicle systems, enabling the vehicle to perceive and understand its surrounding environment. This workshop focuses on ",(0,t.jsx)(n.strong,{children:"3D object detection"})," using raw LiDAR data within the ",(0,t.jsx)(n.strong,{children:"Robot Operating System (ROS)"})," framework. Specifically, we will work with data recorded from a test vehicle equipped with a ",(0,t.jsx)(n.a,{href:"https://icave2.cse.buffalo.edu/resources/sensor-modeling/VLP32CManual.pdf",children:"Velodyne VLP-32C"})," LiDAR sensor. Utilizing a state-of-the-art 3D object detection model, participants will learn to predict bounding boxes around detected objects, facilitating tasks such as navigation, obstacle avoidance, and path planning."]}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By the end of this workshop, participants will be able to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Understand ROS Object Definitions:"})," Comprehend how objects are defined and structured within ROS messages."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Visualize LiDAR Point Clouds in RViz:"})," Utilize RViz to visualize and interpret raw LiDAR data."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Launch and Operate ROS Nodes:"})," Execute ROS nodes that apply detection algorithms to raw sensor data."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Visualize Detected Objects in RViz:"})," Use RViz to display and analyze detected objects with bounding boxes."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Basic Knowledge of ROS:"})," Familiarity with ROS concepts, including nodes, topics, and messages."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"C++ Programming Skills:"})," Ability to read and modify C++ code."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Understanding of LiDAR Technology:"})," Basic comprehension of LiDAR sensors and point cloud data."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Experience with RViz:"})," Prior experience using RViz for visualization is beneficial but not mandatory."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"setup-instructions",children:"Setup Instructions"}),"\n",(0,t.jsx)(n.h3,{id:"1-clone-the-repository-and-navigate-to-the-workspace",children:"1. Clone the Repository and Navigate to the Workspace"}),"\n",(0,t.jsx)(n.p,{children:"Ensure you have access to the necessary ROS workspace. Navigate to your workspace directory:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd ~/catkin_workspace/src\n"})}),"\n",(0,t.jsx)(n.h3,{id:"2-clone-the-necessary-packages",children:"2. Clone the Necessary Packages"}),"\n",(0,t.jsxs)(n.p,{children:["Clone the ",(0,t.jsx)(n.code,{children:"lidar_detection"})," package along with its dependencies:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/ika-rwth-aachen/acdc.git\ncd acdc/catkin_workspace/src\ngit clone https://github.com/ika-rwth-aachen/acdc.git\n"})}),"\n",(0,t.jsx)(n.h3,{id:"3-download-the-required-bag-file",children:"3. Download the Required Bag File"}),"\n",(0,t.jsx)(n.p,{children:"Download the LiDAR data recording from Campus Melaten in Aachen:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"wget -O lidar_campus_melaten.bag https://rwth-aachen.sciebo.de/s/udlMYloXpCdVtyp/download\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Alternatively, access the bag file directly ",(0,t.jsx)(n.a,{href:"https://rwth-aachen.sciebo.de/s/udlMYloXpCdVtyp",children:(0,t.jsx)(n.strong,{children:"here"})})," (approx. 1.5 GB). Save the file to the local directory ",(0,t.jsx)(n.code,{children:"${REPOSITORY}/bag"})," on your host machine, which is mounted to ",(0,t.jsx)(n.code,{children:"~/bag"})," in the Docker container."]}),"\n",(0,t.jsx)(n.h3,{id:"4-build-the-workspace",children:"4. Build the Workspace"}),"\n",(0,t.jsx)(n.p,{children:"Navigate to your workspace and build the packages:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd ~/catkin_workspace\ncatkin build\nsource devel/setup.bash\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," If you encounter a compilation error similar to ",(0,t.jsx)(n.code,{children:"g++: internal compiler error: Killed (program cc1plus)"}),", it indicates excessive resource consumption. To resolve this, disable parallel building:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"catkin build -j 1\nsource devel/setup.bash\n"})}),"\n",(0,t.jsx)(n.h3,{id:"5-launch-the-ros-environment-with-rviz-and-rosbag",children:"5. Launch the ROS Environment with RViz and Rosbag"}),"\n",(0,t.jsxs)(n.p,{children:["To streamline the process of launching ",(0,t.jsx)(n.code,{children:"rosbag play"})," and ",(0,t.jsx)(n.code,{children:"RViz"})," simultaneously, utilize the provided launch file:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"roslaunch lidar_detection start_rosbag_play_rviz.launch\n"})}),"\n",(0,t.jsx)(n.p,{children:"This command performs the following actions:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Rosbag Playback:"})," Plays the ",(0,t.jsx)(n.code,{children:"lidar_campus_melaten.bag"})," file."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"RViz Visualization:"})," Launches RViz with a pre-configured display for point clouds."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"expected-terminal-output",children:"Expected Terminal Output:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"Initialization of Trajectory Planner done!\nTrajectory optimization SUCCESSFUL after [...]s.\nTrajectory optimization SUCCESSFUL after [...]s.\n...\n"})}),"\n",(0,t.jsx)(n.h4,{id:"expected-rviz-visualization",children:"Expected RViz Visualization:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"fag1",src:i(9509).A+"",width:"1634",height:"881"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"PointCloud2 Display:"})," Shows the raw LiDAR point cloud data."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Adjust Visualization Settings:"})," Enhance visibility by modifying parameters such as ",(0,t.jsx)(n.code,{children:"Size"}),", ",(0,t.jsx)(n.code,{children:"Style"}),", ",(0,t.jsx)(n.code,{children:"Decay Time"}),", and ",(0,t.jsx)(n.code,{children:"Color Transformer"})," in the ",(0,t.jsx)(n.code,{children:"PointCloud2"})," tab."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"rviz-navigation-controls",children:"RViz Navigation Controls:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Left Mouse Button:"})," Rotate the view around the Z-axis."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Middle Mouse Button:"})," Pan the camera along the XY plane."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Right Mouse Button:"})," Zoom in and out."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Scroll Wheel:"})," Zoom in and out incrementally."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Congratulations!"})," You have successfully visualized the raw LiDAR data. Proceed to the object detection algorithms in the subsequent sections."]}),"\n",(0,t.jsx)(n.h2,{id:"definitions",children:"Definitions"}),"\n",(0,t.jsx)(n.h3,{id:"ros-object-definitions",children:"ROS Object Definitions"}),"\n",(0,t.jsx)(n.p,{children:"Understanding how objects are defined and structured within ROS is crucial for effective communication between nodes and for processing detection results."}),"\n",(0,t.jsx)(n.h4,{id:"ika-ros-object-definition",children:"ika ROS Object Definition"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.strong,{children:"ika"})," definitions for ROS messages and internal utilities are located in the ",(0,t.jsx)(n.a,{href:"https://github.com/ika-rwth-aachen/acdc/blob/main/catkin_workspace/src/dependencies/definitions",children:(0,t.jsx)(n.em,{children:"definitions"})})," package. Specifically:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ROS Message Files:"})," Located in ",(0,t.jsx)(n.code,{children:"definitions/msg"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Internal Definitions:"})," Found in ",(0,t.jsx)(n.code,{children:"~/ws/catkin_workspace/src/dependencies/definitions/include/definitions/utility"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"ikaobjectmsg",children:"IkaObject.msg"}),"\n",(0,t.jsx)(n.p,{children:"Defines the structure of a single 3D object detected by the LiDAR sensor."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"float32[] fMean               # State vector, containing attributes based on the chosen motion model\nfloat32[] fCovariance         # Covariance matrix, representing uncertainties in the state vector\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"fMean:"})," Represents the object's bounding box attributes such as position, velocity, acceleration, and orientation."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"fCovariance:"})," Captures the uncertainties associated with each attribute in ",(0,t.jsx)(n.code,{children:"fMean"}),", essential for tasks like object fusion."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," This assignment focuses solely on 3D object detection, thus only the ",(0,t.jsx)(n.code,{children:"fMean"})," vector is utilized to describe an object's bounding box."]}),"\n",(0,t.jsx)(n.h5,{id:"object_definitionsh",children:"object_definitions.h"}),"\n",(0,t.jsx)(n.p,{children:"Defines the enumeration of object types recognized by the system."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c++",children:"enum ika_object_types {\n  UNCLASSIFIED = 0,\n  PEDESTRIAN = 1,\n  BICYCLE = 2,\n  MOTORBIKE = 3,\n  CAR = 4,\n  TRUCK = 5,\n  VAN = 6,\n  BUS = 7,\n  ANIMAL = 8,\n  ROAD_OBSTACLE = 9,\n  TRAILER = 10,\n  TYPES_COUNT = 11\n};\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Key Object Classes:"})," For simplicity, this workshop focuses on the following classes:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"CAR"})," (ID: 4)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"PEDESTRIAN"})," (ID: 1)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"TRUCK"})," (ID: 5)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"BICYCLE"})," (ID: 2)"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Example Usage:"})," Access the ",(0,t.jsx)(n.code,{children:"CAR"})," type in code using ",(0,t.jsx)(n.code,{children:"definitions::ika_object_types::CAR"}),"."]}),"\n",(0,t.jsx)(n.h4,{id:"ika-ros-object-lists-definition",children:"ika ROS Object Lists Definition"}),"\n",(0,t.jsxs)(n.p,{children:["Handling multiple objects efficiently is essential for real-time applications. The ",(0,t.jsx)(n.code,{children:"IkaObjectList.msg"})," facilitates this by aggregating multiple ",(0,t.jsx)(n.code,{children:"IkaObject"})," messages into a single list."]}),"\n",(0,t.jsx)(n.h5,{id:"ikaobjectlistmsg",children:"IkaObjectList.msg"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"std_msgs/Header header\n\n# List meta information\nuint8 IdSource    # See definitions/utility/object_definitions.h for enum of sensors\n\n# Actual objects\nIkaObject[] objects\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"header:"})," Contains timestamp and frame information."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"IdSource:"})," Identifies the sensor source of the object detections."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"objects:"})," An array of ",(0,t.jsx)(n.code,{children:"IkaObject"})," messages, allowing the transmission of multiple detected objects simultaneously."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Benefits:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Efficiency:"})," Reduces the overhead of publishing individual object messages."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Organization:"})," Simplifies the management and processing of multiple detections from various sources."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"measurement-data",children:"Measurement Data"}),"\n",(0,t.jsxs)(n.p,{children:["For this workshop, we utilize real sensor data captured from our institute's test vehicle equipped with a ",(0,t.jsx)(n.strong,{children:"Velodyne VLP-32C"})," LiDAR sensor. This sensor provides high-resolution 3D point clouds at a rate of 10 Hz, making it ideal for dynamic object detection tasks."]}),"\n",(0,t.jsx)(n.h3,{id:"downloading-the-lidar-bag-file",children:"Downloading the LiDAR Bag File"}),"\n",(0,t.jsx)(n.p,{children:"Retrieve the recorded LiDAR data:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"wget -O lidar_campus_melaten.bag https://rwth-aachen.sciebo.de/s/udlMYloXpCdVtyp/download\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Alternatively,"})," access the bag file directly ",(0,t.jsx)(n.a,{href:"https://rwth-aachen.sciebo.de/s/udlMYloXpCdVtyp",children:(0,t.jsx)(n.strong,{children:"here"})})," (approx. 1.5 GB). Save the file to the local directory ",(0,t.jsx)(n.code,{children:"${REPOSITORY}/bag"})," on your host machine, which is mounted to ",(0,t.jsx)(n.code,{children:"~/bag"})," within the Docker container."]}),"\n",(0,t.jsx)(n.h3,{id:"rosbag-inspection",children:"Rosbag Inspection"}),"\n",(0,t.jsxs)(n.p,{children:["Inspect the contents of the bag file using the ",(0,t.jsx)(n.code,{children:"rosbag info"})," command:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"rosbag info lidar_campus_melaten.bag \n"})}),"\n",(0,t.jsx)(n.h4,{id:"expected-output",children:"Expected Output:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"path:        lidar_campus_melaten.bag \nversion:     2.0\nduration:    1:59s (119s)\nstart:       Feb 05 2020 15:25:31.41 (1580916331.41)\nend:         Feb 05 2020 15:27:31.37 (1580916451.37)\nsize:        1.5 GB\nmessages:    1200\ncompression: none [1199/1199 chunks]\ntypes:       sensor_msgs/PointCloud2 [1158d486dd51d683ce2f1be655c3c181]\n             tf2_msgs/TFMessage      [94810edda583a504dfda3829e70d7eec]\ntopics:      /points2     1199 msgs    : sensor_msgs/PointCloud2\n             /tf_static      1 msg     : tf2_msgs/TFMessage\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Topics:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"/points2"}),": Contains ",(0,t.jsx)(n.code,{children:"sensor_msgs/PointCloud2"})," messages representing raw LiDAR point clouds."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"/tf_static"}),": Contains ",(0,t.jsx)(n.code,{children:"tf2_msgs/TFMessage"})," messages for static transformations."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," ",(0,t.jsx)(n.code,{children:"sensor_msgs/PointCloud2"})," is a standard ROS message type for point cloud data, documented ",(0,t.jsx)(n.a,{href:"http://docs.ros.org/noetic/api/sensor_msgs/html/msg/PointCloud2.html",children:"here"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"rosbag-visualization",children:"Rosbag Visualization"}),"\n",(0,t.jsx)(n.p,{children:"Visualizing the LiDAR point clouds provides insights into the sensor data and facilitates debugging."}),"\n",(0,t.jsx)(n.h4,{id:"using-a-launch-file-for-visualization",children:"Using a Launch File for Visualization"}),"\n",(0,t.jsxs)(n.p,{children:["Instead of manually starting ",(0,t.jsx)(n.code,{children:"roscore"}),", ",(0,t.jsx)(n.code,{children:"rviz"}),", and ",(0,t.jsx)(n.code,{children:"rosbag play"}),", utilize the provided launch file to execute these commands simultaneously."]}),"\n",(0,t.jsxs)(n.h5,{id:"launch-file-start_rosbag_play_rvizlaunch",children:["Launch File: ",(0,t.jsx)(n.code,{children:"start_rosbag_play_rviz.launch"})]}),"\n",(0,t.jsxs)(n.p,{children:["Located in the ",(0,t.jsx)(n.code,{children:"lidar_detection"})," package, this launch file orchestrates the playback of the bag file and the visualization in RViz."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-xml",children:'<launch>\n    \x3c!-- Rosbag Playback --\x3e\n    <param name="use_sim_time" value="true"/>\n    <node \n        pkg="rosbag"\n        type="play"\n        args="--clock -l -r 0.5 -d 1 /home/rosuser/bag/lidar_campus_melaten.bag"\n        name="player"\n        output="screen">\n    </node>\n\n    \x3c!-- RViz Visualization --\x3e\n    <node\n        type="rviz"\n        name="rviz"\n        pkg="rviz"\n        args="-d $(find lidar_detection)/rviz/point_cloud.rviz">\n    </node>    \n</launch>\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"use_sim_time"}),": Synchronizes ROS time with simulation time."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"rosbag play"})," arguments:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"--clock"}),": Publishes simulated clock time."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"-l"}),": Loops the bag file indefinitely."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"-r 0.5"}),": Plays the bag file at half speed."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"-d 1"}),": Delays the start by 1 second."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"launching-the-visualization",children:"Launching the Visualization"}),"\n",(0,t.jsx)(n.p,{children:"Execute the launch file to start playback and visualization:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"roslaunch lidar_detection start_rosbag_play_rviz.launch\n"})}),"\n",(0,t.jsx)(n.h4,{id:"expected-rviz-window",children:"Expected RViz Window:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"fag1",src:i(9509).A+"",width:"1634",height:"881"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"PointCloud2 Display:"})," Visualizes the raw LiDAR point clouds."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Customization:"})," Enhance visualization by adjusting settings such as ",(0,t.jsx)(n.code,{children:"Size"}),", ",(0,t.jsx)(n.code,{children:"Style"}),", ",(0,t.jsx)(n.code,{children:"Decay Time"}),", and ",(0,t.jsx)(n.code,{children:"Color Transformer"})," within the ",(0,t.jsx)(n.code,{children:"PointCloud2"})," tab."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Tip:"})," Modify RViz settings to improve clarity and highlight specific features of the point cloud data."]}),"\n",(0,t.jsx)(n.h2,{id:"lidar-detection",children:"Lidar Detection"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"lidar_detection"})," ROS package facilitates the detection of 3D objects from raw LiDAR data. It leverages the ",(0,t.jsx)(n.strong,{children:"PointPillars"})," deep learning model to infer bounding boxes around detected objects, which are then published as ",(0,t.jsx)(n.code,{children:"IkaObjectList"})," messages for further processing."]}),"\n",(0,t.jsx)(n.h3,{id:"package-structure",children:"Package Structure"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"section_2/\n\u2514\u2500\u2500 lidar_detection\n    \u251c\u2500\u2500 CMakeLists.txt\n    \u251c\u2500\u2500 include\n    \u2502   \u251c\u2500\u2500 definitions.h\n    \u2502   \u251c\u2500\u2500 detector.h\n    \u2502   \u251c\u2500\u2500 lidar_detection.h\n    \u2502   \u251c\u2500\u2500 list_creator.h\n    \u2502   \u251c\u2500\u2500 pillar_utils.h\n    \u251c\u2500\u2500 launch\n    \u2502   \u251c\u2500\u2500 static_params.yaml\n    \u2502   \u251c\u2500\u2500 start_all.launch\n    \u2502   \u251c\u2500\u2500 start_lidar_detection.launch\n    \u2502   \u2514\u2500\u2500 start_rosbag_play_rviz.launch\n    \u251c\u2500\u2500 model\n    \u2502   \u251c\u2500\u2500 lidar_detection.yml\n    \u2502   \u2514\u2500\u2500 FrozenGraphs\n    \u2502       \u2514\u2500\u2500lidar_detection\n    \u2502           \u2514\u2500\u2500lidar_detection.pb\n    \u251c\u2500\u2500 nodelet_plugins.xml\n    \u251c\u2500\u2500 package.xml\n    \u251c\u2500\u2500 rviz\n    \u2502   \u2514\u2500\u2500 point_cloud.rviz\n    \u2514\u2500\u2500 src\n        \u251c\u2500\u2500 definitions.cpp\n        \u251c\u2500\u2500 detector.cpp\n        \u251c\u2500\u2500 lidar_detection.cpp\n        \u251c\u2500\u2500 list_creator.cpp\n        \u2514\u2500\u2500 pillar_utils.cpp\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Key Directories and Files:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"include/"}),": Header files defining classes and utilities."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"launch/"}),": ROS launch files for starting nodes and configurations."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"model/"}),": Contains the PointPillars model configuration and frozen graph."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"rviz/"}),": RViz configuration files."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"src/"}),": Source code implementing detection algorithms and message handling."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"understanding-the-detection-pipeline",children:"Understanding the Detection Pipeline"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Point Cloud Ingestion:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Raw LiDAR data is received from the ",(0,t.jsx)(n.code,{children:"/points2"})," topic as ",(0,t.jsx)(n.code,{children:"sensor_msgs/PointCloud2"})," messages."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"PointPillars Inference:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The PointPillars deep neural network processes the point cloud to identify and classify objects."}),"\n",(0,t.jsx)(n.li,{children:"Outputs include bounding boxes with associated class probabilities."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Bounding Box and Object List Creation:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Detected objects are encapsulated into ",(0,t.jsx)(n.code,{children:"IkaObject"})," messages, detailing their state vectors and classifications."]}),"\n",(0,t.jsxs)(n.li,{children:["These objects are aggregated into ",(0,t.jsx)(n.code,{children:"IkaObjectList"})," messages for efficient transmission."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Visualization:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Detected objects are visualized in RViz with bounding boxes, color-coded by class type."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," Detailed understanding of the PointPillars model is beyond the scope of this workshop. Interested participants are encouraged to refer to the original ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/1812.05784",children:"PointPillars paper"})," for in-depth knowledge."]}),"\n",(0,t.jsx)(n.h3,{id:"launching-the-detection-node",children:"Launching the Detection Node"}),"\n",(0,t.jsxs)(n.p,{children:["To initiate the object detection process, execute the combined launch file that starts both the ",(0,t.jsx)(n.code,{children:"rosbag play"})," and the ",(0,t.jsx)(n.code,{children:"lidar_detection"})," nodes:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"roslaunch lidar_detection start_all.launch\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," The bag file playback rate is set to ",(0,t.jsx)(n.code,{children:"0.1"})," to accommodate the computational demands of the neural network inference. Depending on your system's performance, you may adjust this rate for optimal processing."]}),"\n",(0,t.jsx)(n.h3,{id:"visualizing-detected-objects-in-rviz",children:"Visualizing Detected Objects in RViz"}),"\n",(0,t.jsx)(n.p,{children:"Once the detection node is running, configure RViz to display the detected objects:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Add IkaObjectList Display:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Click on ",(0,t.jsx)(n.strong,{children:"ADD"})," in RViz."]}),"\n",(0,t.jsxs)(n.li,{children:["Select ",(0,t.jsx)(n.strong,{children:"By Topic"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Choose ",(0,t.jsx)(n.code,{children:"/lidar_detection/object_list/IkaObjectList"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Click ",(0,t.jsx)(n.strong,{children:"OK"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"fag1",src:i(2246).A+"",width:"1633",height:"883"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Resulting Visualization:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Detected objects are displayed with bounding boxes."}),"\n",(0,t.jsx)(n.li,{children:"Objects are color-coded based on their classified type (e.g., cars, pedestrians)."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"fag1",src:i(5483).A+"",width:"1633",height:"881"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Issue Encountered:"})," Initially, bounding boxes may not align accurately, and all objects might be classified as ",(0,t.jsx)(n.code,{children:"UNKNOWN"}),". These issues will be addressed in the subsequent tasks."]}),"\n",(0,t.jsx)(n.h2,{id:"tasks",children:"Tasks"}),"\n",(0,t.jsx)(n.h3,{id:"task-1-correcting-bounding-box-dimensions-and-orientation",children:"Task 1: Correcting Bounding Box Dimensions and Orientation"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Objective:"})," Ensure that detected objects have accurate bounding box dimensions and correct heading angles by properly assigning values from the detection model to the ",(0,t.jsx)(n.code,{children:"IkaObject"})," message."]}),"\n",(0,t.jsx)(n.h4,{id:"steps",children:"Steps:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.strong,{children:["Navigate to ",(0,t.jsx)(n.code,{children:"list_creator.cpp"}),":"]})}),"\n",(0,t.jsxs)(n.p,{children:["Open the ",(0,t.jsx)(n.code,{children:"list_creator.cpp"})," file located in ",(0,t.jsx)(n.code,{children:"~/ws/catkin_workspace/src/workshops/section_2/lidar_detection/src/"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Locate the Code Snippet:"})}),"\n",(0,t.jsx)(n.p,{children:"Identify the section responsible for setting the object position and dimensions:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-cpp",children:"// set object position\nobject.fMean[(int)definitions::ca_model::posX] = bounding_box.center(0);\nobject.fMean[(int)definitions::ca_model::posY] = bounding_box.center(1);\n\n...  \n\n// START TASK 1 CODE  \n\n// set object dimensions and fHeading\nobject.fMean[(int)definitions::ca_model::length] = 2;\nobject.fMean[(int)definitions::ca_model::width] = 2;\nobject.fMean[(int)definitions::ca_model::height] = 2;\n\n...\n     \n// set yaw angle\nobject.fMean[(int)definitions::ca_model::heading] = 0;\n\n// END TASK 1 CODE \n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Understand the Variables:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsxs)(n.strong,{children:[(0,t.jsx)(n.code,{children:"object"}),":"]})," Instance of ",(0,t.jsx)(n.code,{children:"IkaObject.msg"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsxs)(n.strong,{children:[(0,t.jsx)(n.code,{children:"bounding_box"}),":"]})," Instance of ",(0,t.jsx)(n.code,{children:"BoundingBoxCenter"})," struct defined in ",(0,t.jsx)(n.code,{children:"definitions.h"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-cpp",children:"struct BoundingBoxCenter\n{\n  Eigen::Vector2d center;\n  float z;\n  float length;\n  float width;\n  float height;\n  float yaw;\n\n  float score;\n  int class_idx;\n  std::string class_name;\n};\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Issue:"})," The bounding box dimensions (",(0,t.jsx)(n.code,{children:"length"}),", ",(0,t.jsx)(n.code,{children:"width"}),", ",(0,t.jsx)(n.code,{children:"height"}),") and the ",(0,t.jsx)(n.code,{children:"heading"})," angle are hardcoded and do not reflect the values from ",(0,t.jsx)(n.code,{children:"bounding_box"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Implement the Corrections:"})}),"\n",(0,t.jsxs)(n.p,{children:["Modify the code between the ",(0,t.jsx)(n.code,{children:"// START TASK 1 CODE"})," and ",(0,t.jsx)(n.code,{children:"// END TASK 1 CODE"})," comments to assign the correct values from ",(0,t.jsx)(n.code,{children:"bounding_box"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-cpp",children:"// START TASK 1 CODE  \n\n// Set object dimensions and heading using bounding_box data\nobject.fMean[(int)definitions::ca_model::length] = bounding_box.length;\nobject.fMean[(int)definitions::ca_model::width] = bounding_box.width;\nobject.fMean[(int)definitions::ca_model::height] = bounding_box.height;\n\n// Set yaw angle from bounding_box\nobject.fMean[(int)definitions::ca_model::heading] = bounding_box.yaw;\n\n// END TASK 1 CODE \n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.strong,{children:["Rebuild the ",(0,t.jsx)(n.code,{children:"lidar_detection"})," Package:"]})}),"\n",(0,t.jsx)(n.p,{children:"After saving the changes, execute the following commands to rebuild the package:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd ~/catkin_workspace\ncatkin build lidar_detection\nsource devel/setup.bash\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Launch the Detection Node:"})}),"\n",(0,t.jsx)(n.p,{children:"Restart the detection node to apply the changes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"roslaunch lidar_detection start_all.launch\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Visualize the Updated Bounding Boxes:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"If RViz is not already running, execute the launch file again."}),"\n",(0,t.jsx)(n.li,{children:"Observe that the bounding boxes now reflect accurate dimensions and orientations based on the detection model's output."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Expected Visualization:"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"fag1",src:i(4115).A+"",width:"1633",height:"879"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Note:"})," The bounding boxes should align more accurately with the detected objects, and classes should start to populate correctly."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"task-2-assigning-correct-object-classes",children:"Task 2: Assigning Correct Object Classes"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Objective:"})," Ensure that detected objects are correctly classified by assigning the appropriate ",(0,t.jsx)(n.code,{children:"class_idx"})," based on the highest class probability from the detection model."]}),"\n",(0,t.jsx)(n.h4,{id:"steps-1",children:"Steps:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.strong,{children:["Navigate to ",(0,t.jsx)(n.code,{children:"detector.cpp"}),":"]})}),"\n",(0,t.jsxs)(n.p,{children:["Open the ",(0,t.jsx)(n.code,{children:"detector.cpp"})," file located in ",(0,t.jsx)(n.code,{children:"~/ws/catkin_workspace/src/workshops/section_2/lidar_detection/src/"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Locate the Code Snippet:"})}),"\n",(0,t.jsx)(n.p,{children:"Find the section marked for Task 2, responsible for determining the object's class index:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-cpp",children:"// START TASK 2 CODE\n\nint class_idx = -1;\n\n// END TASK 2 CODE\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Understand the Objective:"})}),"\n",(0,t.jsxs)(n.p,{children:["The goal is to assign ",(0,t.jsx)(n.code,{children:"class_idx"})," to the index of the class with the highest probability score from the detection model's output."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Implement the Class Index Assignment:"})}),"\n",(0,t.jsxs)(n.p,{children:["Replace the placeholder code with logic that identifies the class with the maximum score using ",(0,t.jsx)(n.code,{children:"std::max_element"}),". Here's how to implement it:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-cpp",children:"// START TASK 2 CODE\n\n// Find the index of the class with the highest score\nauto max_it = std::max_element(bounding_box.class_scores.begin(), bounding_box.class_scores.end());\nclass_idx = std::distance(bounding_box.class_scores.begin(), max_it);\n\n// END TASK 2 CODE\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Explanation:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"bounding_box.class_scores"})," is assumed to be a ",(0,t.jsx)(n.code,{children:"std::vector<float>"})," containing the probability scores for each class."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"std::max_element"})," locates the iterator pointing to the highest score."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"std::distance"})," calculates the index of this maximum score, which corresponds to the ",(0,t.jsx)(n.code,{children:"class_idx"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.strong,{children:["Rebuild the ",(0,t.jsx)(n.code,{children:"lidar_detection"})," Package:"]})}),"\n",(0,t.jsx)(n.p,{children:"After saving the changes, execute the following commands to rebuild the package:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd ~/catkin_workspace\ncatkin build lidar_detection\nsource devel/setup.bash\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Launch the Detection Node:"})}),"\n",(0,t.jsx)(n.p,{children:"Restart the detection node to apply the changes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"roslaunch lidar_detection start_all.launch\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Visualize the Correctly Classified Objects:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"If RViz is not already running, execute the launch file again."}),"\n",(0,t.jsxs)(n.li,{children:["Detected objects should now display their correct classifications (e.g., ",(0,t.jsx)(n.code,{children:"CAR"}),", ",(0,t.jsx)(n.code,{children:"PEDESTRIAN"}),", ",(0,t.jsx)(n.code,{children:"TRUCK"}),", ",(0,t.jsx)(n.code,{children:"BICYCLE"}),") instead of ",(0,t.jsx)(n.code,{children:"UNKNOWN"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Expected Visualization:"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"fag1",src:i(4115).A+"",width:"1633",height:"879"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Observation:"})," Correct class assignments reduce false positives and enhance the overall detection performance."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"wrap-up",children:"Wrap-up"}),"\n",(0,t.jsx)(n.p,{children:"In this workshop, you have:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Explored 3D Object Detection Basics:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Understood how LiDAR data is utilized for object detection in ROS."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Mastered ROS Object Definitions:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Learned about ",(0,t.jsx)(n.code,{children:"IkaObject.msg"})," and ",(0,t.jsx)(n.code,{children:"IkaObjectList.msg"})," structures."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Visualized LiDAR Point Clouds:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Utilized RViz to display and interpret raw LiDAR point cloud data."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Launched and Operated ROS Nodes:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Executed ROS nodes for point cloud playback and object detection."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Visualized Detected Objects:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Configured RViz to display detected objects with accurate bounding boxes and classifications."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Enhanced Detection Accuracy:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Corrected bounding box dimensions and orientations."}),"\n",(0,t.jsx)(n.li,{children:"Implemented class index assignment to ensure accurate object classifications."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"These skills form the foundation for advanced perception tasks in autonomous systems, enabling vehicles to navigate safely and efficiently by accurately detecting and classifying surrounding objects."}),"\n",(0,t.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"PointPillars Paper:"})," ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/1812.05784",children:"https://arxiv.org/abs/1812.05784"})]}),"\n",(0,t.jsx)(n.p,{children:"The original research paper detailing the PointPillars model used for efficient and accurate object detection in LiDAR point clouds."}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,c.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(r,{...e})}):r(e)}},4445:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/header_object_detection-0bd0074e459af002b08c758c94c9297c.png"},4115:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/result-046938243f7028666b2ec032d779a286.png"},9509:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/rviz-52e984e1783793cc0d2fc67a86d1f1fb.png"},2246:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/rviz_select-c33d091dbc6dd7315a69af14cb298ade.png"},5483:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/task-5f84fb4de6f261bca99d7f389fefe1be.png"},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>d});var s=i(6540);const t={},c=s.createContext(t);function l(e){const n=s.useContext(c);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(c.Provider,{value:n},e.children)}}}]);