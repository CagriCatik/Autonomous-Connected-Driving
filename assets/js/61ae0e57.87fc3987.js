"use strict";(self.webpackChunkacd=self.webpackChunkacd||[]).push([[8387],{577:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"theory/sensor-data-processing/point_cloud_ogm/training_evaluation","title":"Training and Evaluating Neural Networks for Occupancy Grid Maps","description":"Occupancy Grid Maps (OGMs) are pivotal in robotics and autonomous systems for environment representation and navigation. They provide a discretized spatial map where each cell indicates the probability of being occupied or free. Leveraging neural networks to predict OGMs from 3D point cloud data has shown promising results, enhancing the accuracy and efficiency of spatial understanding in dynamic environments.","source":"@site/docs/theory/sensor-data-processing/05_point_cloud_ogm/04_training_evaluation.md","sourceDirName":"theory/sensor-data-processing/05_point_cloud_ogm","slug":"/theory/sensor-data-processing/point_cloud_ogm/training_evaluation","permalink":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/point_cloud_ogm/training_evaluation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/theory/sensor-data-processing/05_point_cloud_ogm/04_training_evaluation.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"sensorSidebar","previous":{"title":"Point Cloud Occupancy Grid Mapping Using Deep Inverse Sensor Models","permalink":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/point_cloud_ogm/deep_inverse_sensor"},"next":{"title":"Camera Based Semantic Grid Mapping","permalink":"/Autonomous-Connected-Driving/docs/category/camera-based-semantic-grid-mapping"}}');var r=i(4848),a=i(8453);const t={},l="Training and Evaluating Neural Networks for Occupancy Grid Maps",o={},c=[{value:"Data Preparation and Storage",id:"data-preparation-and-storage",level:2},{value:"Training Dataset Requirements",id:"training-dataset-requirements",level:3},{value:"Data Storage Formats",id:"data-storage-formats",level:3},{value:"Common File Types",id:"common-file-types",level:4},{value:"Optimized Data Structures",id:"optimized-data-structures",level:4},{value:"Data Loading Pipeline",id:"data-loading-pipeline",level:2},{value:"Efficient Data Handling",id:"efficient-data-handling",level:3},{value:"Code Snippet: Data Loading in TensorFlow",id:"code-snippet-data-loading-in-tensorflow",level:3},{value:"Metrics for Model Evaluation",id:"metrics-for-model-evaluation",level:2},{value:"Precision and Recall",id:"precision-and-recall",level:3},{value:"Evaluating Binary Predictions",id:"evaluating-binary-predictions",level:3},{value:"Precision-Recall for Binary Metrics",id:"precision-recall-for-binary-metrics",level:3},{value:"Evidential Occupancy Grid Maps",id:"evidential-occupancy-grid-maps",level:3},{value:"Model Evaluation and Insights",id:"model-evaluation-and-insights",level:2},{value:"Interpreting Precision and Recall",id:"interpreting-precision-and-recall",level:3},{value:"State: Free",id:"state-free",level:4},{value:"State: Occupied",id:"state-occupied",level:4},{value:"Visual Validation",id:"visual-validation",level:3},{value:"Key Recommendations",id:"key-recommendations",level:2},{value:"Conclusion",id:"conclusion",level:2},{value:"Glossary",id:"glossary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"training-and-evaluating-neural-networks-for-occupancy-grid-maps",children:"Training and Evaluating Neural Networks for Occupancy Grid Maps"})}),"\n",(0,r.jsx)(n.p,{children:"Occupancy Grid Maps (OGMs) are pivotal in robotics and autonomous systems for environment representation and navigation. They provide a discretized spatial map where each cell indicates the probability of being occupied or free. Leveraging neural networks to predict OGMs from 3D point cloud data has shown promising results, enhancing the accuracy and efficiency of spatial understanding in dynamic environments."}),"\n",(0,r.jsx)(n.p,{children:"In the previous development phase, a neural network architecture was constructed to process 3D point clouds and predict tensors representing OGMs. This document delineates the subsequent steps essential for effective model training, encompassing data preparation, storage formats, performance metrics, and evaluation strategies. By adhering to these guidelines, developers can streamline their training pipelines, optimize model performance, and ensure scalability for real-world applications."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"data-preparation-and-storage",children:"Data Preparation and Storage"}),"\n",(0,r.jsx)(n.p,{children:"Effective data preparation and storage are foundational to training robust neural networks. This section outlines the requirements for training datasets and explores various data storage formats suitable for handling large-scale OGM datasets."}),"\n",(0,r.jsx)(n.h3,{id:"training-dataset-requirements",children:"Training Dataset Requirements"}),"\n",(0,r.jsx)(n.p,{children:"Training a neural network necessitates a comprehensive dataset comprising numerous input-label pairs. For OGMs, inputs are typically 3D point clouds, and labels are the corresponding occupancy grid maps. The following criteria are essential for dataset preparation:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Quantity and Diversity"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Volume"}),": Thousands to millions of samples ensure the model generalizes well."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Diversity"}),": Variations in environments, object types, and sensor noise enhance model robustness."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Organization and Storage Efficiency"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Structured Storage"}),": Organize data hierarchically (e.g., by scene or sequence) to facilitate easy access and management."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compression"}),": Utilize compression techniques to reduce storage footprint without compromising data integrity."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Accessibility for Deep Learning Frameworks"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compatibility"}),": Ensure data formats are compatible with frameworks like TensorFlow, PyTorch, or others to enable seamless integration."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Scalability"}),": Support for distributed training and parallel data loading mechanisms."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Data Quality and Annotation Accuracy"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Precision"}),": Accurate annotations of occupied and free spaces are crucial."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Consistency"}),": Uniform data formats and labeling conventions across the dataset."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"data-storage-formats",children:"Data Storage Formats"}),"\n",(0,r.jsx)(n.p,{children:"Selecting appropriate data storage formats can significantly impact training efficiency and performance. This section explores common file types and optimized data structures tailored for handling OGM datasets."}),"\n",(0,r.jsx)(n.h4,{id:"common-file-types",children:"Common File Types"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Image-based Data"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Format"}),": PNG, JPEG, or TIFF."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Usage"}),": Occupancy grid maps can be represented as 2D or 3D images where each pixel or voxel denotes occupancy probability."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advantages"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Ease of Sharing"}),": Standard image formats are widely supported and can be easily visualized."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compression"}),": Lossless compression (e.g., PNG) preserves data integrity."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from PIL import Image\nimport numpy as np\n\n# Save occupancy grid map as PNG\noccupancy_grid = np.random.rand(256, 256)  # Example grid\nimg = Image.fromarray((occupancy_grid * 255).astype(np.uint8))\nimg.save('occupancy_map.png')\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"3D Point Cloud Data"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Format"}),": PCD (Point Cloud Data), LAS, or XYZ."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Usage"}),": Represent 3D spatial information captured by sensors like LiDAR."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advantages"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Visualization"}),": Tools like PCL (Point Cloud Library) support visualization and manipulation."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Standardization"}),": Widely accepted formats facilitate interoperability."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import open3d as o3d\nimport numpy as np\n\n# Create a point cloud\npoints = np.random.rand(1000, 3)\npcd = o3d.geometry.PointCloud()\npcd.points = o3d.utility.Vector3dVector(points)\no3d.io.write_point_cloud("point_cloud.pcd", pcd)\n'})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"optimized-data-structures",children:"Optimized Data Structures"}),"\n",(0,r.jsx)(n.p,{children:"For large-scale datasets, especially those involving high-dimensional data like 3D point clouds and OGMs, optimized data structures can enhance I/O performance and streamline data loading during training."}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"TensorFlow TFRecord Files"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Description"}),": A binary format optimized for TensorFlow, enabling efficient storage and retrieval of large datasets."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Benefits"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reduced I/O Bottlenecks"}),": Sequential access patterns minimize disk seek times."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parallelism"}),": Supports multi-threaded data reading and prefetching."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Flexibility"}),": Can store various data types, including images, point clouds, and labels."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Creating TFRecord Files"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import tensorflow as tf\nimport numpy as np\n\ndef serialize_example(input_data, label_data):\n    feature = {\n        'input': tf.train.Feature(float_list=tf.train.FloatList(value=input_data.flatten())),\n        'label': tf.train.Feature(float_list=tf.train.FloatList(value=label_data.flatten())),\n    }\n    example = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example.SerializeToString()\n\n# Example data\ninput_data = np.random.rand(100, 100, 3)  # Example point cloud\nlabel_data = np.random.rand(100, 100)     # Example occupancy grid\n\nwith tf.io.TFRecordWriter('data.tfrecord') as writer:\n    serialized_example = serialize_example(input_data, label_data)\n    writer.write(serialized_example)\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"HDF5 (Hierarchical Data Format)"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Description"}),": A versatile data model that can store complex data types and relationships."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advantages"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Hierarchical Organization"}),": Facilitates storage of datasets with multiple dimensions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Partial I/O"}),": Enables reading subsets of data without loading entire datasets into memory."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import h5py\nimport numpy as np\n\n# Create HDF5 file\nwith h5py.File('data.h5', 'w') as f:\n    f.create_dataset('inputs', data=np.random.rand(1000, 100, 100, 3))\n    f.create_dataset('labels', data=np.random.rand(1000, 100, 100))\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"data-loading-pipeline",children:"Data Loading Pipeline"}),"\n",(0,r.jsx)(n.p,{children:"An efficient data loading pipeline is critical to maximize GPU utilization and minimize training time. This section discusses strategies for efficient data handling and provides a practical code example using TensorFlow."}),"\n",(0,r.jsx)(n.h3,{id:"efficient-data-handling",children:"Efficient Data Handling"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Minimize Latency"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Prefetching"}),": Load data batches in advance to keep the GPU fed."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parallel Processing"}),": Utilize multiple CPU cores to preprocess data concurrently."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Data Augmentation"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Apply real-time data augmentation (e.g., rotations, translations) to increase dataset diversity without expanding storage."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Caching"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cache frequently accessed data in memory to reduce disk I/O during epochs."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Shuffling"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Shuffle data to ensure that each mini-batch is representative and to prevent the model from learning the order of data."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"code-snippet-data-loading-in-tensorflow",children:"Code Snippet: Data Loading in TensorFlow"}),"\n",(0,r.jsxs)(n.p,{children:["The following Python code demonstrates an efficient data loading pipeline using TensorFlow's ",(0,r.jsx)(n.code,{children:"tf.data"})," API. It includes parsing TFRecord files, batching, shuffling, and prefetching to optimize training performance."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import tensorflow as tf\n\n# Define dimensions\ndim_input = 300  # Example dimension for input data\ndim_label = 100  # Example dimension for label data\n\ndef parse_tfrecord(example_proto):\n    feature_description = {\n        'input': tf.io.FixedLenFeature([dim_input, dim_input, 3], tf.float32),\n        'label': tf.io.FixedLenFeature([dim_label, dim_label], tf.float32),\n    }\n    parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n    input_data = parsed_features['input']\n    label_data = parsed_features['label']\n    return input_data, label_data\n\n# Load TFRecord dataset\ndef load_dataset(tfrecord_path, batch_size=32, shuffle_buffer=1000):\n    dataset = tf.data.TFRecordDataset(tfrecord_path)\n    dataset = dataset.map(parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.shuffle(buffer_size=shuffle_buffer)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    return dataset\n\n# Example usage\ntrain_dataset = load_dataset(\"data.tfrecord\", batch_size=64)\nfor batch_inputs, batch_labels in train_dataset.take(1):\n    print(\"Inputs shape:\", batch_inputs.shape)\n    print(\"Labels shape:\", batch_labels.shape)\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Explanation"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parsing Function"}),": ",(0,r.jsx)(n.code,{children:"parse_tfrecord"})," defines how to decode each TFRecord example into input and label tensors."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Loading Function"}),": ",(0,r.jsx)(n.code,{children:"load_dataset"})," sets up the data pipeline with shuffling, batching, and prefetching."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Batch Size"}),": Adjusting the batch size (",(0,r.jsx)(n.code,{children:"batch_size=64"}),") can impact training speed and memory usage."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Prefetching"}),": ",(0,r.jsx)(n.code,{children:"tf.data.AUTOTUNE"})," automatically tunes the prefetch buffer size for optimal performance."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"metrics-for-model-evaluation",children:"Metrics for Model Evaluation"}),"\n",(0,r.jsx)(n.p,{children:"Selecting appropriate metrics is essential to assess the performance of neural networks accurately. This section delves into precision, recall, and their application in evaluating binary occupancy predictions."}),"\n",(0,r.jsx)(n.h3,{id:"precision-and-recall",children:"Precision and Recall"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Precision"})," and ",(0,r.jsx)(n.strong,{children:"Recall"})," are fundamental metrics in classification tasks, providing insights into the model's accuracy and completeness."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Precision"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Definition"}),": The ratio of true positive predictions to the total predicted positives."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Formula"}),":"]}),"\n"]}),"\n",(0,r.jsx)(n.span,{className:"katex-error",title:"ParseError: KaTeX parse error: Can't use function '\\]' in math mode at position 106: \u2026 Positives}}\n  \\\u0332]\u0332",style:{color:"#cc0000"},children:"  \\[\n  \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n  \\]"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Interpretation"}),": High precision indicates that when the model predicts a cell as occupied, it is usually correct."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Recall"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Definition"}),": The ratio of true positive predictions to the total actual positives."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Formula"}),":","\n",(0,r.jsx)(n.span,{className:"katex-error",title:"ParseError: KaTeX parse error: Can't use function '\\]' in math mode at position 97: \u2026se Negatives}}\n\\\u0332]\u0332",style:{color:"#cc0000"},children:"\\[\n\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n\\]"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Interpretation"}),": High recall signifies that the model successfully identifies most of the occupied cells."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"evaluating-binary-predictions",children:"Evaluating Binary Predictions"}),"\n",(0,r.jsxs)(n.p,{children:["For occupancy grid maps, predictions are often binary, indicating whether a cell is ",(0,r.jsx)(n.strong,{children:"occupied"})," or ",(0,r.jsx)(n.strong,{children:"free"}),". To compute precision and recall, continuous belief masses (probabilities) must be converted into binary classifications using a predefined threshold."]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Thresholding"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Threshold ((\\theta))"}),": A value between 0 and 1 used to convert probabilities into binary classes."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Example"}),": (\\theta = 0.5)","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Cells with a belief mass > 0.5 are classified as ",(0,r.jsx)(n.strong,{children:"occupied"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Cells with a belief mass \u2264 0.5 are classified as ",(0,r.jsx)(n.strong,{children:"free"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Confusion Matrix Components"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"True Positives (TP)"}),": Cells correctly predicted as occupied."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"False Positives (FP)"}),": Cells incorrectly predicted as occupied."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"True Negatives (TN)"}),": Cells correctly predicted as free."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"False Negatives (FN)"}),": Cells incorrectly predicted as free."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example Calculation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import numpy as np\n\ndef compute_confusion_matrix(predictions, labels, threshold=0.5):\n    pred_binary = predictions > threshold\n    label_binary = labels > threshold\n\n    TP = np.sum(np.logical_and(pred_binary, label_binary))\n    FP = np.sum(np.logical_and(pred_binary, np.logical_not(label_binary)))\n    TN = np.sum(np.logical_and(np.logical_not(pred_binary), np.logical_not(label_binary)))\n    FN = np.sum(np.logical_and(np.logical_not(pred_binary), label_binary))\n    \n    return TP, FP, TN, FN\n\n# Example data\npredictions = np.random.rand(100, 100)\nlabels = np.random.rand(100, 100)\n\nTP, FP, TN, FN = compute_confusion_matrix(predictions, labels)\nprecision = TP / (TP + FP) if (TP + FP) > 0 else 0\nrecall = TP / (TP + FN) if (TP + FN) > 0 else 0\n\nprint(f"Precision: {precision:.2f}")\nprint(f"Recall: {recall:.2f}")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"precision-recall-for-binary-metrics",children:"Precision-Recall for Binary Metrics"}),"\n",(0,r.jsx)(n.p,{children:"The precision-recall trade-off is critical, especially in applications where false positives and false negatives have different consequences. By adjusting the threshold (\\theta), developers can balance precision and recall based on application requirements."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"High Precision, Low Recall"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Few false positives, but many false negatives."}),"\n",(0,r.jsx)(n.li,{children:"Suitable for applications where false positives are costly."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Low Precision, High Recall"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Many false positives, but few false negatives."}),"\n",(0,r.jsx)(n.li,{children:"Ideal for safety-critical systems where missing an occupied cell is unacceptable."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"evidential-occupancy-grid-maps",children:"Evidential Occupancy Grid Maps"}),"\n",(0,r.jsxs)(n.p,{children:["Evidential OGMs represent uncertainty by assigning belief masses to both ",(0,r.jsx)(n.strong,{children:"free"})," and ",(0,r.jsx)(n.strong,{children:"occupied"})," states for each cell. These masses lie in the range [0, 1] and must sum to 1. Before computing precision and recall, it is necessary to convert these continuous masses into binary classifications."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Conversion Process"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Threshold Selection"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Determine a threshold (\\theta) to decide the state of each cell based on belief masses."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Binary Classification"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Occupied"}),": ",(0,r.jsx)(n.span,{className:"katex-error",title:"ParseError: KaTeX parse error: Can't use function '\\(' in math mode at position 1: \\\u0332(\u0332 \\text{belief\\_\u2026",style:{color:"#cc0000"},children:"\\( \\text{belief\\_occupied} > \\theta \\)"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Free"}),": ",(0,r.jsx)(n.span,{className:"katex-error",title:"ParseError: KaTeX parse error: Can't use function '\\(' in math mode at position 1: \\\u0332(\u0332 \\text{belief\\_\u2026",style:{color:"#cc0000"},children:"\\( \\text{belief\\_free} > \\theta \\)"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def convert_evidential_to_binary(belief_free, belief_occupied, threshold=0.5):\n    pred_occupied = belief_occupied > threshold\n    pred_free = belief_free > threshold\n    return pred_occupied, pred_free\n\n# Example data\nbelief_free = np.random.rand(100, 100)\nbelief_occupied = np.random.rand(100, 100)\n\npred_occupied, pred_free = convert_evidential_to_binary(belief_free, belief_occupied)\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"model-evaluation-and-insights",children:"Model Evaluation and Insights"}),"\n",(0,r.jsx)(n.p,{children:"Evaluating the performance of neural networks for OGMs involves both quantitative metrics and qualitative analysis. This section explores the interpretation of precision and recall, as well as the importance of visual validation."}),"\n",(0,r.jsx)(n.h3,{id:"interpreting-precision-and-recall",children:"Interpreting Precision and Recall"}),"\n",(0,r.jsx)(n.p,{children:"Understanding the implications of precision and recall scores helps in assessing model reliability and suitability for specific applications."}),"\n",(0,r.jsx)(n.h4,{id:"state-free",children:"State: Free"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"High Precision"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Implication"}),": Most cells predicted as free are indeed free."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advantage"}),": Reduces the likelihood of collisions due to misclassified occupied cells."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Slightly Lower Recall"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Implication"}),": Some truly free cells are misclassified as occupied."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advantage"}),": Safer for navigation as it errs on the side of caution, avoiding potential obstacles."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"state-occupied",children:"State: Occupied"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Moderate Recall"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Implication"}),": Not all occupied cells are detected."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Risk"}),": Potential collisions if occupied cells are missed."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lower Precision (e.g., 60%)"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Implication"}),": Overestimation of occupied regions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advantage"}),": Enhances safety by treating uncertain areas as occupied."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Consideration"}),": May limit navigable space, affecting efficiency."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Balancing Act"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Safety vs. Efficiency"}),": In safety-critical applications (e.g., autonomous vehicles), prioritizing high precision in the free state ensures fewer collisions. Conversely, in less critical applications, higher recall might be acceptable to maximize navigable areas."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"visual-validation",children:"Visual Validation"}),"\n",(0,r.jsx)(n.p,{children:"Quantitative metrics provide a numerical assessment of model performance, but visual validation offers intuitive insights into model behavior and potential shortcomings."}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Overlaying Predictions with Ground Truth"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Method"}),": Superimpose predicted OGMs onto ground truth maps to identify discrepancies."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tools"}),": Use visualization libraries like Matplotlib or specialized tools like RViz for 3D data."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import matplotlib.pyplot as plt\n\ndef visualize_ogms(prediction, ground_truth, threshold=0.5):\n    pred_binary = prediction > threshold\n    gt_binary = ground_truth > threshold\n\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n    axs[0].imshow(gt_binary, cmap='gray')\n    axs[0].set_title('Ground Truth')\n    axs[1].imshow(pred_binary, cmap='gray')\n    axs[1].set_title('Prediction')\n    plt.show()\n\n# Example usage\nvisualize_ogms(predictions, labels)\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Analyzing Boundaries"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Objective"}),": Examine the precision of detected boundaries between free and occupied regions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Insights"}),": Identify areas where the model consistently overestimates or underestimates occupancy."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Error Mapping"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Method"}),": Generate maps highlighting false positives and false negatives."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Benefit"}),": Pinpoints specific regions or conditions where the model struggles, guiding targeted improvements."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def plot_errors(prediction, ground_truth, threshold=0.5):\n    pred_binary = prediction > threshold\n    gt_binary = ground_truth > threshold\n\n    false_positives = np.logical_and(pred_binary, np.logical_not(gt_binary))\n    false_negatives = np.logical_and(np.logical_not(pred_binary), gt_binary)\n\n    plt.figure(figsize=(15, 5))\n\n    plt.subplot(1, 3, 1)\n    plt.title('False Positives')\n    plt.imshow(false_positives, cmap='Reds')\n\n    plt.subplot(1, 3, 2)\n    plt.title('False Negatives')\n    plt.imshow(false_negatives, cmap='Blues')\n\n    plt.subplot(1, 3, 3)\n    plt.title('Correct Predictions')\n    correct = np.logical_or(np.logical_and(pred_binary, gt_binary), \n                            np.logical_and(np.logical_not(pred_binary), np.logical_not(gt_binary)))\n    plt.imshow(correct, cmap='Greens')\n\n    plt.show()\n\n# Example usage\nplot_errors(predictions, labels)\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Benefits of Visual Validation"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Intuitive Understanding"}),": Helps stakeholders comprehend model performance beyond numerical metrics."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Debugging Tool"}),": Facilitates the identification of specific failure modes."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Communication Aid"}),": Effective for presenting results to non-technical audiences."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"key-recommendations",children:"Key Recommendations"}),"\n",(0,r.jsx)(n.p,{children:"To ensure the successful training and evaluation of neural networks for occupancy grid maps, the following recommendations are proposed:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Optimize Data Storage"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Adopt Efficient Formats"}),": Utilize formats like TFRecord or HDF5 to enhance data loading speeds and reduce I/O bottlenecks."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Ensure Compatibility"}),": Verify that the chosen storage format seamlessly integrates with the deep learning framework in use."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Implement Data Versioning"}),": Maintain version control for datasets to track changes and facilitate reproducibility."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Select Appropriate Metrics"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Comprehensive Evaluation"}),": Beyond precision and recall, consider additional metrics like F1-score, Intersection over Union (IoU), and Area Under the Curve (AUC) for a holistic assessment."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Contextual Relevance"}),": Choose metrics that align with the specific application requirements, balancing safety, accuracy, and efficiency."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Understand Predictions"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Qualitative Analysis"}),": Regularly perform visual inspections of predicted OGMs to gain insights into model behavior."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Error Analysis"}),": Investigate patterns in false positives and false negatives to identify underlying issues, such as sensor noise or model biases."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Uncertainty Quantification"}),": Incorporate uncertainty estimates to enhance decision-making, especially in ambiguous scenarios."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Iterate and Refine"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Threshold Tuning"}),": Experiment with different threshold values to balance precision and recall based on application needs."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model Architecture Adjustments"}),": Modify or enhance the neural network architecture (e.g., adding layers, changing activation functions) to improve performance."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Hyperparameter Optimization"}),": Utilize techniques like grid search, random search, or Bayesian optimization to fine-tune hyperparameters for optimal results."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Regularization Techniques"}),": Apply methods like dropout, weight decay, or data augmentation to prevent overfitting and enhance generalization."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Scalability and Efficiency"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Distributed Training"}),": Leverage multi-GPU or multi-node setups to accelerate training on large datasets."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model Pruning and Compression"}),": Optimize model size and inference speed without significantly compromising accuracy."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Continuous Integration"}),": Implement automated pipelines for data preprocessing, training, evaluation, and deployment to streamline workflows."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Documentation and Reproducibility"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Maintain Comprehensive Documentation"}),": Record all aspects of the training process, including data sources, preprocessing steps, model configurations, and evaluation results."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Ensure Reproducibility"}),": Use fixed random seeds, containerization (e.g., Docker), and version-controlled codebases to facilitate reproducible experiments."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,r.jsx)(n.p,{children:"Training and evaluating neural networks for occupancy grid maps is a multifaceted process that demands meticulous attention to data handling, storage optimization, metric selection, and qualitative analysis. By systematically addressing these components, developers can cultivate robust and reliable models capable of performing effectively in diverse and dynamic environments."}),"\n",(0,r.jsx)(n.p,{children:"This guide serves as a comprehensive reference, bridging foundational concepts with advanced strategies to cater to both novice practitioners and seasoned experts. Adhering to the outlined recommendations and best practices will empower developers to harness the full potential of neural networks in generating accurate and efficient occupancy grid maps, thereby advancing the capabilities of autonomous systems and robotic applications."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"glossary",children:"Glossary"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Occupancy Grid Map (OGM)"}),": A representation of the environment where space is divided into discrete cells, each indicating the probability of being occupied or free."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"3D Point Cloud"}),": A collection of data points in space, typically obtained from sensors like LiDAR, representing the external surface of objects."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Precision"}),": A metric indicating the proportion of true positive predictions among all positive predictions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Recall"}),": A metric indicating the proportion of true positive predictions among all actual positives."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TFRecord"}),": A binary file format used by TensorFlow for efficient data storage and retrieval."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"HDF5"}),": A file format and set of tools for managing complex data, supporting large, heterogeneous, and hierarchical data."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Belief Mass"}),": In evidential frameworks, the degree of belief assigned to a particular state or hypothesis."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"F1-Score"}),": The harmonic mean of precision and recall, providing a single metric that balances both."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Intersection over Union (IoU)"}),": A metric measuring the overlap between predicted and ground truth regions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Area Under the Curve (AUC)"}),": A performance metric summarizing the ROC curve, indicating the model's ability to distinguish between classes."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var s=i(6540);const r={},a=s.createContext(r);function t(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);