"use strict";(self.webpackChunkacd=self.webpackChunkacd||[]).push([[1360],{3707:(s,e,n)=>{n.r(e),n.d(e,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>m});const i=JSON.parse('{"id":"theory/sensor-data-processing/camera_based_semantic_grid_mapping/introduction","title":"Semantic Grid Mapping from Camera Images","description":"Semantic grid mapping is an essential technique in the field of autonomous driving and robotics, enabling vehicles to understand and navigate their environment effectively. By transforming semantically segmented camera images into structured grid maps, vehicles can make informed decisions based on the types and locations of objects within their surroundings.","source":"@site/docs/theory/sensor-data-processing/06_camera_based_semantic_grid_mapping/01_introduction.md","sourceDirName":"theory/sensor-data-processing/06_camera_based_semantic_grid_mapping","slug":"/theory/sensor-data-processing/camera_based_semantic_grid_mapping/introduction","permalink":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/camera_based_semantic_grid_mapping/introduction","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/theory/sensor-data-processing/06_camera_based_semantic_grid_mapping/01_introduction.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{},"sidebar":"sensorSidebar","previous":{"title":"Camera Based Semantic Grid Mapping","permalink":"/Autonomous-Connected-Driving/docs/category/camera-based-semantic-grid-mapping"},"next":{"title":"Camera-Based Semantic Grid Mapping - Challenges","permalink":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/camera_based_semantic_grid_mapping/challenges"}}');var a=n(4848),t=n(8453);const r={},l="Semantic Grid Mapping from Camera Images",c={},m=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Semantic Grid Maps",id:"semantic-grid-maps",level:3},{value:"Inverse Perspective Mapping (IPM)",id:"inverse-perspective-mapping-ipm",level:3},{value:"Camera Setup",id:"camera-setup",level:3},{value:"Camera-Based Semantic Grid Mapping Approaches",id:"camera-based-semantic-grid-mapping-approaches",level:2},{value:"Geometry-Based Approaches",id:"geometry-based-approaches",level:3},{value:"Deep Learning-Based Approaches",id:"deep-learning-based-approaches",level:3},{value:"Hybrid Approaches",id:"hybrid-approaches",level:3},{value:"Geometry-Based Approach: Inverse Perspective Mapping (IPM)",id:"geometry-based-approach-inverse-perspective-mapping-ipm",level:2},{value:"Overview",id:"overview",level:3},{value:"Mathematical Foundation",id:"mathematical-foundation",level:3},{value:"Step 1: Camera Model",id:"step-1-camera-model",level:4},{value:"Step 2: Inverse Transformation",id:"step-2-inverse-transformation",level:4},{value:"Step 3: Grid Map Stitching",id:"step-3-grid-map-stitching",level:4},{value:"Implementation Example",id:"implementation-example",level:3},{value:"Code Explanation",id:"code-explanation",level:4},{value:"Optimized IPM Implementation",id:"optimized-ipm-implementation",level:4},{value:"Semantic Grid Map Design Choices",id:"semantic-grid-map-design-choices",level:2},{value:"Class Selection",id:"class-selection",level:3},{value:"Grid Resolution",id:"grid-resolution",level:3},{value:"Color Coding and Visualization",id:"color-coding-and-visualization",level:3},{value:"Challenges and Future Directions",id:"challenges-and-future-directions",level:2},{value:"Field of View Limitations",id:"field-of-view-limitations",level:3},{value:"Computational Overhead",id:"computational-overhead",level:3},{value:"Deep Learning Integration",id:"deep-learning-integration",level:3},{value:"Real-Time Processing",id:"real-time-processing",level:3},{value:"Environmental Variability",id:"environmental-variability",level:3},{value:"Conclusion",id:"conclusion",level:2},{value:"Further Exploration",id:"further-exploration",level:3},{value:"Glossary",id:"glossary",level:2}];function d(s){const e={annotation:"annotation",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",math:"math",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",mstyle:"mstyle",msub:"msub",msup:"msup",mtable:"mtable",mtd:"mtd",mtext:"mtext",mtr:"mtr",ol:"ol",p:"p",path:"path",pre:"pre",semantics:"semantics",span:"span",strong:"strong",svg:"svg",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...s.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"semantic-grid-mapping-from-camera-images",children:"Semantic Grid Mapping from Camera Images"})}),"\n",(0,a.jsx)(e.p,{children:"Semantic grid mapping is an essential technique in the field of autonomous driving and robotics, enabling vehicles to understand and navigate their environment effectively. By transforming semantically segmented camera images into structured grid maps, vehicles can make informed decisions based on the types and locations of objects within their surroundings."}),"\n",(0,a.jsx)(e.p,{children:"This documentation delves into the methodologies of semantic grid mapping, with a particular focus on geometry-based approaches using Inverse Perspective Mapping (IPM). It aims to provide both theoretical insights and practical implementations, catering to beginners and advanced practitioners alike."}),"\n",(0,a.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,a.jsx)(e.p,{children:"After studying this documentation, you will:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:"Gain a deep understanding of the mathematical concepts behind IPM."}),"\n",(0,a.jsx)(e.li,{children:"Learn to apply IPM to generate semantic grid maps from camera images."}),"\n",(0,a.jsx)(e.li,{children:"Understand the distinctions between semantic and occupancy grid maps."}),"\n",(0,a.jsx)(e.li,{children:"Explore various approaches to semantic grid mapping, including deep learning and hybrid methods."}),"\n",(0,a.jsx)(e.li,{children:"Identify design choices and challenges in implementing semantic grid maps."}),"\n",(0,a.jsx)(e.li,{children:"Acquire the skills to develop optimized and real-time semantic grid mapping systems."}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,a.jsx)(e.p,{children:"Before diving into the specifics of semantic grid mapping, it's crucial to understand the foundational concepts that underpin this technology."}),"\n",(0,a.jsx)(e.h3,{id:"semantic-grid-maps",children:"Semantic Grid Maps"}),"\n",(0,a.jsx)(e.p,{children:"Semantic grid maps extend the traditional occupancy grid maps by not only indicating the presence of objects but also classifying them into predefined categories. Each cell in a semantic grid map contains information about the type of object occupying that space, such as roads, buildings, pedestrians, vehicles, or dynamic obstacles."}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Key Features:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Semantic Labels:"})," Assign meaningful labels to each cell."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Spatial Resolution:"})," Define the granularity of the grid."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Contextual Information:"})," Provide context for decision-making processes."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"inverse-perspective-mapping-ipm",children:"Inverse Perspective Mapping (IPM)"}),"\n",(0,a.jsx)(e.p,{children:"Inverse Perspective Mapping is a geometric transformation technique that converts an image captured from a camera's perspective into a top-down (bird\u2019s eye) view. This transformation facilitates the alignment of image data with real-world coordinates, enabling the creation of accurate semantic grid maps."}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Key Components:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Intrinsic Parameters:"})," Define the camera's internal characteristics, such as focal length and optical center."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Extrinsic Parameters:"})," Describe the camera's position and orientation in the world frame."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Homography Matrix:"})," Used to perform the perspective transformation."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"camera-setup",children:"Camera Setup"}),"\n",(0,a.jsx)(e.p,{children:"Achieving a comprehensive 360\xb0 view around the vehicle requires the integration of multiple cameras positioned at strategic locations. The outputs from these cameras are stitched together to form a unified semantic grid map, providing a complete representation of the vehicle's environment."}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Considerations:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Camera Calibration:"})," Ensuring accurate intrinsic and extrinsic parameters."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Overlap Management:"})," Handling overlapping fields of view from multiple cameras."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Synchronization:"})," Coordinating data streams from different cameras for real-time mapping."]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"camera-based-semantic-grid-mapping-approaches",children:"Camera-Based Semantic Grid Mapping Approaches"}),"\n",(0,a.jsx)(e.p,{children:"Semantic grid mapping from camera images can be achieved through various methodologies. The primary approaches include geometry-based, deep learning-based, and hybrid methods. Each approach has its strengths, limitations, and suitable applications."}),"\n",(0,a.jsx)(e.h3,{id:"geometry-based-approaches",children:"Geometry-Based Approaches"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Overview:"}),"\nGeometry-based approaches rely on mathematical models and camera parameters to transform camera images into semantic grid maps. The fundamental technique in this category is Inverse Perspective Mapping (IPM), which leverages the camera's intrinsic and extrinsic parameters to achieve perspective transformation."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Advantages:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Deterministic:"})," Provides predictable and explainable results."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Computational Efficiency:"})," Generally less computationally intensive compared to deep learning methods."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Real-Time Capability:"})," Suitable for real-time applications with proper optimization."]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Limitations:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Sensitivity to Calibration Errors:"})," Requires precise camera calibration for accurate mapping."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Limited Robustness:"})," May struggle with dynamic environments and varying lighting conditions."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"deep-learning-based-approaches",children:"Deep Learning-Based Approaches"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Overview:"}),"\nDeep learning-based approaches utilize neural networks to directly predict semantic grid representations from camera images. These methods learn complex patterns and relationships within the data, enabling more robust and flexible mapping."]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Example: Cross-View Methodologies"}),"\nCross-view approaches aim to bridge the gap between different perspectives (e.g., from camera view to top-down view) using deep learning architectures. These methods often incorporate encoder-decoder structures and attention mechanisms to enhance prediction accuracy."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Advantages:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"High Accuracy:"})," Capable of capturing intricate details and variations in the environment."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Robustness:"})," Better performance in dynamic and complex scenarios."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Adaptability:"})," Can be trained to handle diverse conditions and environments."]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Limitations:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Computationally Intensive:"})," Requires significant processing power, especially for large-scale deployments."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Data Dependency:"})," Performance heavily reliant on the quality and quantity of training data."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Black-Box Nature:"})," Lack of interpretability compared to geometry-based methods."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"hybrid-approaches",children:"Hybrid Approaches"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Overview:"}),"\nHybrid approaches combine the strengths of geometry-based and deep learning-based methods to create more robust and accurate semantic grid maps. By integrating geometric transformations as a guide for neural networks, these methods aim to leverage both deterministic transformations and the learning capabilities of deep models."]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Example: Cam2BEV (Developed at IKA)"}),"\nCam2BEV utilizes inverse perspective mapping to preprocess camera images before feeding them into a neural network. This combination enhances the network's ability to understand spatial relationships and improve overall mapping accuracy."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Advantages:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Balanced Performance:"})," Combines accuracy and computational efficiency."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Enhanced Robustness:"})," Benefits from both deterministic transformations and learned features."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Scalability:"})," More adaptable to various environments and conditions."]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Limitations:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Complex Integration:"})," Requires careful coordination between geometric and deep learning components."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Increased Development Effort:"})," More intricate to design and optimize compared to single-method approaches."]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"geometry-based-approach-inverse-perspective-mapping-ipm",children:"Geometry-Based Approach: Inverse Perspective Mapping (IPM)"}),"\n",(0,a.jsx)(e.p,{children:"Inverse Perspective Mapping (IPM) is a cornerstone technique in geometry-based semantic grid mapping. It transforms camera images into a top-down view, facilitating the alignment of image data with the vehicle's real-world environment."}),"\n",(0,a.jsx)(e.h3,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(e.p,{children:"IPM leverages the camera's intrinsic and extrinsic parameters to perform a perspective transformation on semantically segmented images. The resulting top-down view, or bird\u2019s eye view, allows for accurate placement of objects within a semantic grid map, providing a structured and actionable representation of the environment."}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Applications:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Autonomous Driving:"})," Enhancing situational awareness for navigation and obstacle avoidance."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Robotics:"})," Enabling robots to understand and interact with their surroundings."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Urban Planning:"})," Assisting in the analysis and visualization of urban infrastructures."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"mathematical-foundation",children:"Mathematical Foundation"}),"\n",(0,a.jsx)(e.p,{children:"Understanding the mathematical principles behind IPM is crucial for implementing effective geometry-based semantic grid mapping systems. The process involves transforming pixel coordinates from the camera image to real-world coordinates and mapping them onto a semantic grid."}),"\n",(0,a.jsx)(e.h4,{id:"step-1-camera-model",children:"Step 1: Camera Model"}),"\n",(0,a.jsx)(e.p,{children:"A camera's projection model describes how 3D world coordinates are mapped to 2D image coordinates. This relationship is captured by the camera's intrinsic and extrinsic parameters."}),"\n",(0,a.jsx)(e.p,{children:"The projection can be represented as:"}),"\n",(0,a.jsx)(e.span,{className:"katex-display",children:(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{mathvariant:"bold",children:"x"}),(0,a.jsx)(e.mtext,{children:"image"})]}),(0,a.jsx)(e.mo,{children:"="}),(0,a.jsx)(e.mi,{mathvariant:"bold",children:"K"}),(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mo,{fence:"true",children:"["}),(0,a.jsx)(e.mtable,{rowspacing:"0.16em",columnalign:"center center",columnspacing:"1em",children:(0,a.jsxs)(e.mtr,{children:[(0,a.jsx)(e.mtd,{children:(0,a.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,a.jsx)(e.mi,{mathvariant:"bold",children:"R"})})}),(0,a.jsx)(e.mtd,{children:(0,a.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,a.jsx)(e.mi,{mathvariant:"bold",children:"t"})})})]})}),(0,a.jsx)(e.mo,{fence:"true",children:"]"})]}),(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{mathvariant:"bold",children:"X"}),(0,a.jsx)(e.mtext,{children:"world"})]})]}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\mathbf{x}_{\\text{image}} = \\mathbf{K} \\begin{bmatrix} \\mathbf{R} & \\mathbf{t} \\end{bmatrix} \\mathbf{X}_{\\text{world}}"})]})})}),(0,a.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.7305em",verticalAlign:"-0.2861em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathbf",children:"x"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.3175em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:(0,a.jsx)(e.span,{className:"mord text mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:"image"})})})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.2861em"},children:(0,a.jsx)(e.span,{})})})]})})]}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(e.span,{className:"mrel",children:"="}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"1.2em",verticalAlign:"-0.35em"}}),(0,a.jsx)(e.span,{className:"mord mathbf",children:"K"}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(e.span,{className:"minner",children:[(0,a.jsx)(e.span,{className:"mopen delimcenter",style:{top:"0em"},children:(0,a.jsx)(e.span,{className:"delimsizing size1",children:"["})}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsxs)(e.span,{className:"mtable",children:[(0,a.jsx)(e.span,{className:"col-align-c",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.85em"},children:(0,a.jsxs)(e.span,{style:{top:"-3.01em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsx)(e.span,{className:"mord mathbf",children:"R"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.35em"},children:(0,a.jsx)(e.span,{})})})]})}),(0,a.jsx)(e.span,{className:"arraycolsep",style:{width:"0.5em"}}),(0,a.jsx)(e.span,{className:"arraycolsep",style:{width:"0.5em"}}),(0,a.jsx)(e.span,{className:"col-align-c",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.85em"},children:(0,a.jsxs)(e.span,{style:{top:"-3.01em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsx)(e.span,{className:"mord mathbf",children:"t"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.35em"},children:(0,a.jsx)(e.span,{})})})]})})]})}),(0,a.jsx)(e.span,{className:"mclose delimcenter",style:{top:"0em"},children:(0,a.jsx)(e.span,{className:"delimsizing size1",children:"]"})})]}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathbf",children:"X"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:(0,a.jsx)(e.span,{className:"mord text mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:"world"})})})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(e.span,{})})})]})})]})]})]})]})}),"\n",(0,a.jsx)(e.p,{children:"Where:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsx)(e.mrow,{children:(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{mathvariant:"bold",children:"x"}),(0,a.jsx)(e.mtext,{children:"image"})]})}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\mathbf{x}_{\\text{image}}"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.7305em",verticalAlign:"-0.2861em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathbf",children:"x"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.3175em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:(0,a.jsx)(e.span,{className:"mord text mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:"image"})})})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.2861em"},children:(0,a.jsx)(e.span,{})})})]})})]})]})})]}),": Homogeneous pixel coordinates in the image."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsx)(e.mrow,{children:(0,a.jsx)(e.mi,{mathvariant:"bold",children:"K"})}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\mathbf{K}"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.6861em"}}),(0,a.jsx)(e.span,{className:"mord mathbf",children:"K"})]})})]}),": Intrinsic matrix, encapsulating focal length and principal point."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsx)(e.mrow,{children:(0,a.jsx)(e.mi,{mathvariant:"bold",children:"R"})}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\mathbf{R}"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.6861em"}}),(0,a.jsx)(e.span,{className:"mord mathbf",children:"R"})]})})]}),": Rotation matrix, representing the camera's orientation."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsx)(e.mrow,{children:(0,a.jsx)(e.mi,{mathvariant:"bold",children:"t"})}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\mathbf{t}"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.6349em"}}),(0,a.jsx)(e.span,{className:"mord mathbf",children:"t"})]})})]}),": Translation vector, representing the camera's position."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsx)(e.mrow,{children:(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{mathvariant:"bold",children:"X"}),(0,a.jsx)(e.mtext,{children:"world"})]})}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\mathbf{X}_{\\text{world}}"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.8361em",verticalAlign:"-0.15em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathbf",children:"X"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:(0,a.jsx)(e.span,{className:"mord text mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:"world"})})})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(e.span,{})})})]})})]})]})})]}),": Homogeneous world coordinates."]}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Intrinsic Matrix"})," (",(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsx)(e.mrow,{children:(0,a.jsx)(e.mi,{mathvariant:"bold",children:"K"})}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\mathbf{K}"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.6861em"}}),(0,a.jsx)(e.span,{className:"mord mathbf",children:"K"})]})})]}),") ",(0,a.jsx)(e.strong,{children:"Example:"})]}),"\n",(0,a.jsx)(e.span,{className:"katex-display",children:(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mi,{mathvariant:"bold",children:"K"}),(0,a.jsx)(e.mo,{children:"="}),(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mo,{fence:"true",children:"["}),(0,a.jsxs)(e.mtable,{rowspacing:"0.16em",columnalign:"center center center",columnspacing:"1em",children:[(0,a.jsxs)(e.mtr,{children:[(0,a.jsx)(e.mtd,{children:(0,a.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{children:"f"}),(0,a.jsx)(e.mi,{children:"x"})]})})}),(0,a.jsx)(e.mtd,{children:(0,a.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,a.jsx)(e.mn,{children:"0"})})}),(0,a.jsx)(e.mtd,{children:(0,a.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{children:"c"}),(0,a.jsx)(e.mi,{children:"x"})]})})})]}),(0,a.jsxs)(e.mtr,{children:[(0,a.jsx)(e.mtd,{children:(0,a.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,a.jsx)(e.mn,{children:"0"})})}),(0,a.jsx)(e.mtd,{children:(0,a.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{children:"f"}),(0,a.jsx)(e.mi,{children:"y"})]})})}),(0,a.jsx)(e.mtd,{children:(0,a.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{children:"c"}),(0,a.jsx)(e.mi,{children:"y"})]})})})]}),(0,a.jsxs)(e.mtr,{children:[(0,a.jsx)(e.mtd,{children:(0,a.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,a.jsx)(e.mn,{children:"0"})})}),(0,a.jsx)(e.mtd,{children:(0,a.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,a.jsx)(e.mn,{children:"0"})})}),(0,a.jsx)(e.mtd,{children:(0,a.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,a.jsx)(e.mn,{children:"1"})})})]})]}),(0,a.jsx)(e.mo,{fence:"true",children:"]"})]})]}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\mathbf{K} = \\begin{bmatrix}\nf_x & 0 & c_x \\\\\n0 & f_y & c_y \\\\\n0 & 0 & 1\n\\end{bmatrix}"})]})})}),(0,a.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.6861em"}}),(0,a.jsx)(e.span,{className:"mord mathbf",children:"K"}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(e.span,{className:"mrel",children:"="}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"3.6em",verticalAlign:"-1.55em"}}),(0,a.jsxs)(e.span,{className:"minner",children:[(0,a.jsx)(e.span,{className:"mopen",children:(0,a.jsx)(e.span,{className:"delimsizing mult",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"2.05em"},children:(0,a.jsxs)(e.span,{style:{top:"-4.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"5.6em"}}),(0,a.jsx)(e.span,{style:{width:"0.667em",height:"3.600em"},children:(0,a.jsx)(e.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.667em",height:"3.600em",viewBox:"0 0 667 3600",children:(0,a.jsx)(e.path,{d:"M403 1759 V84 H666 V0 H319 V1759 v0 v1759 h347 v-84\nH403z M403 1759 V0 H319 V1759 v0 v1759 h84z"})})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"1.55em"},children:(0,a.jsx)(e.span,{})})})]})})}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsxs)(e.span,{className:"mtable",children:[(0,a.jsx)(e.span,{className:"col-align-c",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsxs)(e.span,{className:"vlist",style:{height:"2.05em"},children:[(0,a.jsxs)(e.span,{style:{top:"-4.21em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.10764em"},children:"f"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.1514em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.1076em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",children:"x"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(e.span,{})})})]})})]})})]}),(0,a.jsxs)(e.span,{style:{top:"-3.01em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsx)(e.span,{className:"mord",children:"0"})})]}),(0,a.jsxs)(e.span,{style:{top:"-1.81em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsx)(e.span,{className:"mord",children:"0"})})]})]}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"1.55em"},children:(0,a.jsx)(e.span,{})})})]})}),(0,a.jsx)(e.span,{className:"arraycolsep",style:{width:"0.5em"}}),(0,a.jsx)(e.span,{className:"arraycolsep",style:{width:"0.5em"}}),(0,a.jsx)(e.span,{className:"col-align-c",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsxs)(e.span,{className:"vlist",style:{height:"2.05em"},children:[(0,a.jsxs)(e.span,{style:{top:"-4.21em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsx)(e.span,{className:"mord",children:"0"})})]}),(0,a.jsxs)(e.span,{style:{top:"-3.01em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.10764em"},children:"f"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.1514em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.1076em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03588em"},children:"y"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.2861em"},children:(0,a.jsx)(e.span,{})})})]})})]})})]}),(0,a.jsxs)(e.span,{style:{top:"-1.81em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsx)(e.span,{className:"mord",children:"0"})})]})]}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"1.55em"},children:(0,a.jsx)(e.span,{})})})]})}),(0,a.jsx)(e.span,{className:"arraycolsep",style:{width:"0.5em"}}),(0,a.jsx)(e.span,{className:"arraycolsep",style:{width:"0.5em"}}),(0,a.jsx)(e.span,{className:"col-align-c",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsxs)(e.span,{className:"vlist",style:{height:"2.05em"},children:[(0,a.jsxs)(e.span,{style:{top:"-4.21em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",children:"c"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.1514em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",children:"x"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(e.span,{})})})]})})]})})]}),(0,a.jsxs)(e.span,{style:{top:"-3.01em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",children:"c"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.1514em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03588em"},children:"y"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.2861em"},children:(0,a.jsx)(e.span,{})})})]})})]})})]}),(0,a.jsxs)(e.span,{style:{top:"-1.81em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(e.span,{className:"mord",children:(0,a.jsx)(e.span,{className:"mord",children:"1"})})]})]}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"1.55em"},children:(0,a.jsx)(e.span,{})})})]})})]})}),(0,a.jsx)(e.span,{className:"mclose",children:(0,a.jsx)(e.span,{className:"delimsizing mult",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"2.05em"},children:(0,a.jsxs)(e.span,{style:{top:"-4.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"5.6em"}}),(0,a.jsx)(e.span,{style:{width:"0.667em",height:"3.600em"},children:(0,a.jsx)(e.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.667em",height:"3.600em",viewBox:"0 0 667 3600",children:(0,a.jsx)(e.path,{d:"M347 1759 V0 H0 V84 H263 V1759 v0 v1759 H0 v84 H347z\nM347 1759 V0 H263 V1759 v0 v1759 h84z"})})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"1.55em"},children:(0,a.jsx)(e.span,{})})})]})})})]})]})]})]})}),"\n",(0,a.jsx)(e.p,{children:"Where:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{children:"f"}),(0,a.jsx)(e.mi,{children:"x"})]}),(0,a.jsx)(e.mo,{separator:"true",children:","}),(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{children:"f"}),(0,a.jsx)(e.mi,{children:"y"})]})]}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"f_x, f_y"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.9805em",verticalAlign:"-0.2861em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.10764em"},children:"f"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.1514em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.1076em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",children:"x"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(e.span,{})})})]})})]}),(0,a.jsx)(e.span,{className:"mpunct",children:","}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.10764em"},children:"f"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.1514em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.1076em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03588em"},children:"y"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.2861em"},children:(0,a.jsx)(e.span,{})})})]})})]})]})})]}),": Focal lengths in pixels."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{children:"c"}),(0,a.jsx)(e.mi,{children:"x"})]}),(0,a.jsx)(e.mo,{separator:"true",children:","}),(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{children:"c"}),(0,a.jsx)(e.mi,{children:"y"})]})]}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"c_x, c_y"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.7167em",verticalAlign:"-0.2861em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",children:"c"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.1514em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",children:"x"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(e.span,{})})})]})})]}),(0,a.jsx)(e.span,{className:"mpunct",children:","}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathnormal",children:"c"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.1514em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03588em"},children:"y"})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.2861em"},children:(0,a.jsx)(e.span,{})})})]})})]})]})})]}),": Principal point coordinates."]}),"\n"]}),"\n",(0,a.jsx)(e.h4,{id:"step-2-inverse-transformation",children:"Step 2: Inverse Transformation"}),"\n",(0,a.jsx)(e.p,{children:"To map image coordinates back to the world frame, an inverse transformation is applied. This involves computing the inverse of the rotation matrix and intrinsic matrix, followed by adjusting for translation."}),"\n",(0,a.jsx)(e.span,{className:"katex-display",children:(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{mathvariant:"bold",children:"X"}),(0,a.jsx)(e.mtext,{children:"world"})]}),(0,a.jsx)(e.mo,{children:"="}),(0,a.jsxs)(e.msup,{children:[(0,a.jsx)(e.mi,{mathvariant:"bold",children:"R"}),(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mo,{children:"\u2212"}),(0,a.jsx)(e.mn,{children:"1"})]})]}),(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mo,{fence:"true",children:"("}),(0,a.jsxs)(e.msup,{children:[(0,a.jsx)(e.mi,{mathvariant:"bold",children:"K"}),(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mo,{children:"\u2212"}),(0,a.jsx)(e.mn,{children:"1"})]})]}),(0,a.jsxs)(e.msub,{children:[(0,a.jsx)(e.mi,{mathvariant:"bold",children:"x"}),(0,a.jsx)(e.mtext,{children:"image"})]}),(0,a.jsx)(e.mo,{children:"\u2212"}),(0,a.jsx)(e.mi,{mathvariant:"bold",children:"t"}),(0,a.jsx)(e.mo,{fence:"true",children:")"})]})]}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\mathbf{X}_{\\text{world}} = \\mathbf{R}^{-1} \\left( \\mathbf{K}^{-1} \\mathbf{x}_{\\text{image}} - \\mathbf{t} \\right)"})]})})}),(0,a.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.8361em",verticalAlign:"-0.15em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathbf",children:"X"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:(0,a.jsx)(e.span,{className:"mord text mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:"world"})})})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(e.span,{})})})]})})]}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(e.span,{className:"mrel",children:"="}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"1.2141em",verticalAlign:"-0.35em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathbf",children:"R"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsx)(e.span,{className:"vlist-t",children:(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.8641em"},children:(0,a.jsxs)(e.span,{style:{top:"-3.113em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(e.span,{className:"mord mtight",children:[(0,a.jsx)(e.span,{className:"mord mtight",children:"\u2212"}),(0,a.jsx)(e.span,{className:"mord mtight",children:"1"})]})})]})})})})})]}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(e.span,{className:"minner",children:[(0,a.jsx)(e.span,{className:"mopen delimcenter",style:{top:"0em"},children:(0,a.jsx)(e.span,{className:"delimsizing size1",children:"("})}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathbf",children:"K"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsx)(e.span,{className:"vlist-t",children:(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.8641em"},children:(0,a.jsxs)(e.span,{style:{top:"-3.113em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(e.span,{className:"mord mtight",children:[(0,a.jsx)(e.span,{className:"mord mtight",children:"\u2212"}),(0,a.jsx)(e.span,{className:"mord mtight",children:"1"})]})})]})})})})})]}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathbf",children:"x"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(e.span,{className:"vlist-r",children:[(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.3175em"},children:(0,a.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:(0,a.jsx)(e.span,{className:"mord text mtight",children:(0,a.jsx)(e.span,{className:"mord mtight",children:"image"})})})})]})}),(0,a.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.2861em"},children:(0,a.jsx)(e.span,{})})})]})})]}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,a.jsx)(e.span,{className:"mbin",children:"\u2212"}),(0,a.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,a.jsx)(e.span,{className:"mord mathbf",children:"t"}),(0,a.jsx)(e.span,{className:"mclose delimcenter",style:{top:"0em"},children:(0,a.jsx)(e.span,{className:"delimsizing size1",children:")"})})]})]})]})]})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Explanation:"})}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.strong,{children:["Intrinsic Inversion (",(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsx)(e.mrow,{children:(0,a.jsxs)(e.msup,{children:[(0,a.jsx)(e.mi,{mathvariant:"bold",children:"K"}),(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mo,{children:"\u2212"}),(0,a.jsx)(e.mn,{children:"1"})]})]})}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\mathbf{K}^{-1}"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.8141em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathbf",children:"K"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsx)(e.span,{className:"vlist-t",children:(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.8141em"},children:(0,a.jsxs)(e.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(e.span,{className:"mord mtight",children:[(0,a.jsx)(e.span,{className:"mord mtight",children:"\u2212"}),(0,a.jsx)(e.span,{className:"mord mtight",children:"1"})]})})]})})})})})]})]})})]}),"):"]})," Converts pixel coordinates to normalized camera coordinates."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.strong,{children:["Translation Adjustment (",(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mo,{children:"\u2212"}),(0,a.jsx)(e.mi,{mathvariant:"bold",children:"t"})]}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"-\\mathbf{t}"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.7183em",verticalAlign:"-0.0833em"}}),(0,a.jsx)(e.span,{className:"mord",children:"\u2212"}),(0,a.jsx)(e.span,{className:"mord mathbf",children:"t"})]})})]}),"):"]})," Accounts for the camera's position in the world frame."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsxs)(e.strong,{children:["Rotation Adjustment (",(0,a.jsxs)(e.span,{className:"katex",children:[(0,a.jsx)(e.span,{className:"katex-mathml",children:(0,a.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(e.semantics,{children:[(0,a.jsx)(e.mrow,{children:(0,a.jsxs)(e.msup,{children:[(0,a.jsx)(e.mi,{mathvariant:"bold",children:"R"}),(0,a.jsxs)(e.mrow,{children:[(0,a.jsx)(e.mo,{children:"\u2212"}),(0,a.jsx)(e.mn,{children:"1"})]})]})}),(0,a.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\mathbf{R}^{-1}"})]})})}),(0,a.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(e.span,{className:"base",children:[(0,a.jsx)(e.span,{className:"strut",style:{height:"0.8141em"}}),(0,a.jsxs)(e.span,{className:"mord",children:[(0,a.jsx)(e.span,{className:"mord mathbf",children:"R"}),(0,a.jsx)(e.span,{className:"msupsub",children:(0,a.jsx)(e.span,{className:"vlist-t",children:(0,a.jsx)(e.span,{className:"vlist-r",children:(0,a.jsx)(e.span,{className:"vlist",style:{height:"0.8141em"},children:(0,a.jsxs)(e.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,a.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(e.span,{className:"mord mtight",children:[(0,a.jsx)(e.span,{className:"mord mtight",children:"\u2212"}),(0,a.jsx)(e.span,{className:"mord mtight",children:"1"})]})})]})})})})})]})]})})]}),"):"]})," Aligns the coordinates with the world frame's orientation."]}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Homogeneous Coordinates:"}),"\nIt's essential to use homogeneous coordinates (adding a third component with value 1) to facilitate matrix operations and transformations."]}),"\n",(0,a.jsx)(e.h4,{id:"step-3-grid-map-stitching",children:"Step 3: Grid Map Stitching"}),"\n",(0,a.jsx)(e.p,{children:"When multiple cameras are employed to achieve a 360\xb0 view, their individual semantic grids must be aligned and stitched into a unified grid map. This process requires precise knowledge of each camera's position and orientation to ensure seamless integration."}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Steps:"})}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Calibration:"})," Determine the intrinsic and extrinsic parameters for each camera."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Transformation:"})," Apply IPM to each camera's semantically segmented image to obtain individual grid maps."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Alignment:"})," Use the extrinsic parameters to align the grid maps in the world frame."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Stitching:"})," Merge the aligned grid maps, resolving overlaps and ensuring consistency."]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Challenges:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Calibration Accuracy:"})," Inaccurate parameters can lead to misalignment."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Overlap Handling:"})," Efficiently managing overlapping regions to avoid redundancy or conflicts."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Computational Efficiency:"})," Optimizing the stitching process for real-time applications."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"implementation-example",children:"Implementation Example"}),"\n",(0,a.jsx)(e.p,{children:"To illustrate the practical application of IPM, consider a Python implementation using OpenCV and NumPy. This example demonstrates how to transform a semantically segmented image into a top-down semantic grid map."}),"\n",(0,a.jsx)(e.h4,{id:"code-explanation",children:"Code Explanation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import numpy as np\nimport cv2\n\ndef inverse_perspective_mapping(image, K, R, t, grid_size=(500, 500), cell_size=0.1):\n    """\n    Perform inverse perspective mapping on a semantically segmented image.\n\n    Args:\n        image (np.ndarray): Input semantically segmented image.\n        K (np.ndarray): Intrinsic matrix (3x3).\n        R (np.ndarray): Rotation matrix (3x3).\n        t (np.ndarray): Translation vector (3x1).\n        grid_size (tuple): Size of the output grid map (height, width).\n        cell_size (float): Size of each grid cell in meters.\n\n    Returns:\n        np.ndarray: Top-down view of the semantic grid.\n    """\n    height, width = grid_size\n    grid_map = np.zeros((height, width, 3), dtype=np.uint8)\n\n    # Precompute the inverse matrices\n    K_inv = np.linalg.inv(K)\n    R_inv = np.linalg.inv(R)\n\n    for y in range(image.shape[0]):\n        for x in range(image.shape[1]):\n            pixel = np.array([x, y, 1]).reshape(3, 1)\n            # Convert pixel to normalized camera coordinates\n            cam_coords = K_inv @ pixel\n            # Apply inverse rotation and translation\n            world_coords = R_inv @ (cam_coords - t)\n            grid_x = int(world_coords[0][0] / cell_size) + width // 2\n            grid_y = int(world_coords[1][0] / cell_size) + height // 2\n\n            if 0 <= grid_x < width and 0 <= grid_y < height:\n                grid_map[grid_y, grid_x] = image[y, x]\n\n    return grid_map\n\n# Example usage\nif __name__ == "__main__":\n    # Load the semantically segmented image\n    image = cv2.imread("semantic_image.png")\n\n    # Define intrinsic parameters\n    fx, fy = 800, 800  # Focal lengths in pixels\n    cx, cy = image.shape[1] / 2, image.shape[0] / 2  # Principal point\n    K = np.array([[fx, 0, cx],\n                  [0, fy, cy],\n                  [0,  0,  1]])\n\n    # Define extrinsic parameters (assuming camera is level and at origin)\n    R = np.eye(3)  # No rotation\n    t = np.zeros((3, 1))  # No translation\n\n    # Perform IPM\n    semantic_grid = inverse_perspective_mapping(image, K, R, t)\n\n    # Save the resulting semantic grid map\n    cv2.imwrite("semantic_grid.png", semantic_grid)\n'})}),"\n",(0,a.jsx)(e.h4,{id:"optimized-ipm-implementation",children:"Optimized IPM Implementation"}),"\n",(0,a.jsx)(e.p,{children:"While the above implementation provides a foundational understanding of IPM, it can be optimized for better performance and accuracy. Below is an enhanced version that utilizes vectorized operations and homography matrices to reduce computational overhead."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import numpy as np\nimport cv2\n\ndef optimized_inverse_perspective_mapping(image, K, R, t, grid_size=(500, 500), cell_size=0.1):\n    """\n    Optimized Inverse Perspective Mapping using homography.\n\n    Args:\n        image (np.ndarray): Input semantically segmented image.\n        K (np.ndarray): Intrinsic matrix (3x3).\n        R (np.ndarray): Rotation matrix (3x3).\n        t (np.ndarray): Translation vector (3x1).\n        grid_size (tuple): Size of the output grid map (height, width).\n        cell_size (float): Size of each grid cell in meters.\n\n    Returns:\n        np.ndarray: Top-down view of the semantic grid.\n    """\n    height, width = grid_size\n    grid_map = np.zeros((height, width, 3), dtype=np.uint8)\n\n    # Compute homography matrix\n    H = K @ np.hstack((R, t))\n    H_inv = np.linalg.inv(H)\n\n    # Generate grid coordinates\n    xx, yy = np.meshgrid(np.arange(width), np.arange(height))\n    grid_coords = np.stack([xx * cell_size - (width / 2) * cell_size,\n                            yy * cell_size - (height / 2) * cell_size,\n                            np.ones_like(xx)], axis=-1).reshape(-1, 3).T\n\n    # Map grid coordinates to image pixels\n    image_coords = H_inv @ grid_coords\n    image_coords /= image_coords[2, :]\n\n    x_img = image_coords[0, :].astype(np.int32)\n    y_img = image_coords[1, :].astype(np.int32)\n\n    # Filter valid coordinates\n    valid = (x_img >= 0) & (x_img < image.shape[1]) & (y_img >= 0) & (y_img < image.shape[0])\n\n    grid_map[yy.flatten()[valid], xx.flatten()[valid]] = image[y_img[valid], x_img[valid]]\n\n    return grid_map\n\n# Example usage\nif __name__ == "__main__":\n    # Load the semantically segmented image\n    image = cv2.imread("semantic_image.png")\n\n    # Define intrinsic parameters\n    fx, fy = 800, 800  # Focal lengths in pixels\n    cx, cy = image.shape[1] / 2, image.shape[0] / 2  # Principal point\n    K = np.array([[fx, 0, cx],\n                  [0, fy, cy],\n                  [0,  0,  1]])\n\n    # Define extrinsic parameters (assuming camera is level and at origin)\n    R = np.eye(3)  # No rotation\n    t = np.zeros((3, 1))  # No translation\n\n    # Perform optimized IPM\n    semantic_grid = optimized_inverse_perspective_mapping(image, K, R, t)\n\n    # Save the resulting semantic grid map\n    cv2.imwrite("semantic_grid_optimized.png", semantic_grid)\n'})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Enhancements in the Optimized Implementation:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Vectorization:"})," Reduces the use of explicit loops by leveraging NumPy's vectorized operations."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Homography Matrix:"})," Utilizes homography to map multiple points simultaneously, enhancing speed."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Grid Coordinates Generation:"})," Efficiently generates grid coordinates for the entire map in one step."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Valid Coordinate Filtering:"})," Ensures only valid mappings are processed, preventing errors and artifacts."]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"semantic-grid-map-design-choices",children:"Semantic Grid Map Design Choices"}),"\n",(0,a.jsx)(e.p,{children:"Designing an effective semantic grid map involves making informed decisions about various parameters and configurations. These choices significantly impact the map's utility, performance, and integration with downstream applications."}),"\n",(0,a.jsx)(e.h3,{id:"class-selection",children:"Class Selection"}),"\n",(0,a.jsx)(e.p,{children:"The selection of semantic classes is pivotal, as it defines the types of objects the grid map will represent. The chosen classes should align with the application's objectives and operational environment."}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Considerations:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Relevance:"})," Include classes that directly influence decision-making processes."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Granularity:"})," Balance between broad categories and specific object types."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Scalability:"})," Ensure the system can accommodate additional classes if needed."]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Examples:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Road Following:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Road"}),"\n",(0,a.jsx)(e.li,{children:"Lane Markings"}),"\n",(0,a.jsx)(e.li,{children:"Pedestrians"}),"\n",(0,a.jsx)(e.li,{children:"Vehicles"}),"\n",(0,a.jsx)(e.li,{children:"Obstacles"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Urban Planning:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Buildings"}),"\n",(0,a.jsx)(e.li,{children:"Pedestrian Zones"}),"\n",(0,a.jsx)(e.li,{children:"Vehicles"}),"\n",(0,a.jsx)(e.li,{children:"Traffic Signals"}),"\n",(0,a.jsx)(e.li,{children:"Green Spaces"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Best Practices:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Minimalism:"})," Avoid overcomplicating the map with excessive classes; focus on those critical for the task."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Consistency:"})," Maintain consistent class definitions across different mapping instances."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Prioritization:"})," Assign higher priority to dynamic and high-risk objects to enhance safety."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"grid-resolution",children:"Grid Resolution"}),"\n",(0,a.jsx)(e.p,{children:"Grid resolution defines the size of each cell in the semantic grid map, influencing both the map's detail and computational requirements."}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Factors to Consider:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Application Requirements:"})," Higher resolution for tasks requiring fine-grained detail (e.g., pedestrian detection)."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Computational Constraints:"})," Lower resolution reduces processing time and memory usage."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Environment Scale:"})," Larger areas may necessitate lower resolution to cover the space efficiently."]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Typical Resolutions:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"High Resolution:"})," 0.05 meters/cell"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Medium Resolution:"})," 0.1 meters/cell"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Low Resolution:"})," 0.5 meters/cell"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Trade-Offs:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Detail vs. Efficiency:"})," Higher resolution provides more detail but at the cost of increased computational resources."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Accuracy vs. Speed:"})," Balancing the need for accurate mapping with the requirement for real-time processing."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"color-coding-and-visualization",children:"Color Coding and Visualization"}),"\n",(0,a.jsx)(e.p,{children:"Effective visualization of semantic grid maps enhances interpretability and usability. Color coding is a common technique used to differentiate between semantic classes visually."}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Guidelines:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Distinct Colors:"})," Assign unique and distinguishable colors to each semantic class to prevent confusion."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Consistency:"})," Use the same color scheme across different maps and applications."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Legend Inclusion:"})," Always include a legend to explain the color mappings, aiding users in understanding the map."]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Example Color Scheme:"})}),"\n",(0,a.jsxs)(e.table,{children:[(0,a.jsx)(e.thead,{children:(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.th,{children:"Semantic Class"}),(0,a.jsx)(e.th,{children:"Color (RGB)"}),(0,a.jsx)(e.th,{children:"Hex Code"})]})}),(0,a.jsxs)(e.tbody,{children:[(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Road"}),(0,a.jsx)(e.td,{children:"Gray"}),(0,a.jsx)(e.td,{children:"#808080"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Sidewalk"}),(0,a.jsx)(e.td,{children:"Yellow"}),(0,a.jsx)(e.td,{children:"#FFFF00"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Building"}),(0,a.jsx)(e.td,{children:"Blue"}),(0,a.jsx)(e.td,{children:"#0000FF"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Pedestrian"}),(0,a.jsx)(e.td,{children:"Green"}),(0,a.jsx)(e.td,{children:"#00FF00"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Vehicle"}),(0,a.jsx)(e.td,{children:"Red"}),(0,a.jsx)(e.td,{children:"#FF0000"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Obstacle"}),(0,a.jsx)(e.td,{children:"Purple"}),(0,a.jsx)(e.td,{children:"#800080"})]})]})]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Visualization Tools:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"OpenCV:"})," For image-based visualization and saving."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Matplotlib:"})," For more advanced plotting and interactive visualization."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Custom GUI Applications:"})," For real-time monitoring and interaction with the semantic grid map."]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"challenges-and-future-directions",children:"Challenges and Future Directions"}),"\n",(0,a.jsx)(e.p,{children:"While semantic grid mapping offers significant advantages for autonomous systems, several challenges must be addressed to enhance its effectiveness and applicability. Understanding these challenges paves the way for future innovations and improvements."}),"\n",(0,a.jsx)(e.h3,{id:"field-of-view-limitations",children:"Field of View Limitations"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Issue:"}),"\nStitching multiple camera views to achieve a 360\xb0 semantic grid map requires precise calibration and synchronization. Misalignments or discrepancies in camera parameters can lead to gaps or overlaps in the grid map, compromising its integrity."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Advanced Calibration Techniques:"})," Utilize multi-camera calibration methods to ensure accurate parameter estimation."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Dynamic Adjustment:"})," Implement systems that can adjust camera parameters in real-time to account for changes or drifts."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Redundancy:"})," Incorporate overlapping camera views to provide fallback options in case of misalignments."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"computational-overhead",children:"Computational Overhead"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Issue:"}),"\nHigh-resolution images and multiple camera inputs significantly increase the computational load, potentially hindering real-time processing capabilities essential for autonomous applications."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Efficient Algorithms:"})," Develop optimized IPM and grid stitching algorithms that reduce computational complexity."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Hardware Acceleration:"})," Leverage GPUs and specialized hardware (e.g., FPGAs) to accelerate processing tasks."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Parallel Processing:"})," Implement parallel computing techniques to distribute the workload across multiple processors or cores."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"deep-learning-integration",children:"Deep Learning Integration"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Issue:"}),"\nWhile hybrid approaches that integrate geometry-based methods with deep learning offer improved accuracy, they introduce additional complexity in terms of model training, data requirements, and system integration."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Transfer Learning:"})," Utilize pre-trained models to reduce training time and data requirements."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Modular Architectures:"})," Design systems with modular components to simplify integration and maintenance."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Continuous Learning:"})," Implement mechanisms for models to adapt and learn from new data in real-time, enhancing robustness."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"real-time-processing",children:"Real-Time Processing"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Issue:"}),"\nAchieving real-time semantic grid mapping is critical for applications like autonomous driving, where delays can lead to unsafe conditions. Balancing accuracy with processing speed remains a significant challenge."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Algorithm Optimization:"})," Streamline algorithms to minimize computational steps without sacrificing accuracy."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Low-Latency Hardware:"})," Invest in high-speed processing units that can handle intensive computations swiftly."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Approximation Techniques:"})," Employ approximation methods where exact precision is less critical, thereby reducing processing time."]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"environmental-variability",children:"Environmental Variability"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Issue:"}),"\nSemantic grid mapping systems must perform reliably across diverse environments and conditions, including varying lighting, weather, and urban densities. Ensuring consistent performance in all scenarios is challenging."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Robust Segmentation Models:"})," Develop semantic segmentation algorithms that are resilient to environmental changes."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Sensor Fusion:"})," Integrate data from multiple sensors (e.g., LiDAR, radar) to complement camera data and enhance robustness."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Adaptive Systems:"})," Implement adaptive mechanisms that can adjust processing strategies based on the current environment."]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,a.jsx)(e.p,{children:"Semantic grid mapping is a transformative technology in the realm of autonomous systems, providing a structured and detailed representation of the vehicle's environment. By leveraging techniques like Inverse Perspective Mapping, it is possible to convert raw camera data into actionable semantic maps that inform navigation and decision-making processes."}),"\n",(0,a.jsx)(e.p,{children:"This documentation has explored the foundational concepts, mathematical underpinnings, and practical implementations of geometry-based semantic grid mapping. Additionally, it has examined alternative approaches, design considerations, and the challenges that lie ahead. As the field continues to evolve, integrating advanced methodologies and addressing existing limitations will be paramount in advancing the capabilities of autonomous systems."}),"\n",(0,a.jsx)(e.h3,{id:"further-exploration",children:"Further Exploration"}),"\n",(0,a.jsx)(e.p,{children:"To deepen your understanding and stay abreast of the latest developments, consider exploring the following areas:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Advanced Deep Learning Models:"})," Investigate state-of-the-art neural network architectures for semantic segmentation and grid mapping."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Sensor Fusion Techniques:"})," Explore methods for integrating data from various sensors to enhance mapping accuracy and robustness."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Real-World Implementations:"})," Study case studies and real-world applications to understand practical challenges and solutions."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Optimization Strategies:"})," Learn about algorithmic and hardware optimization techniques to achieve real-time performance."]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"glossary",children:"Glossary"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Intrinsic Parameters:"})," Camera-specific parameters that define the internal characteristics of the camera, such as focal length and optical center."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Extrinsic Parameters:"})," Parameters that describe the camera's position and orientation in the world frame."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Homography Matrix:"})," A transformation matrix that maps points from one plane to another, often used in perspective transformations."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Semantic Segmentation:"})," The process of classifying each pixel in an image into predefined categories."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Bird\u2019s Eye View (BEV):"})," A top-down perspective of a scene, often used in mapping and navigation."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Grid Cell:"})," The smallest unit in a grid map, representing a specific area in the environment."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Camera Calibration:"})," The process of determining a camera's intrinsic and extrinsic parameters."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Semantic Grid Map:"})," A grid-based map where each cell contains semantic information about the environment, such as object type."]}),"\n"]})]})}function h(s={}){const{wrapper:e}={...(0,t.R)(),...s.components};return e?(0,a.jsx)(e,{...s,children:(0,a.jsx)(d,{...s})}):d(s)}},8453:(s,e,n)=>{n.d(e,{R:()=>r,x:()=>l});var i=n(6540);const a={},t=i.createContext(a);function r(s){const e=i.useContext(t);return i.useMemo((function(){return"function"==typeof s?s(e):{...e,...s}}),[e,s])}function l(s){let e;return e=s.disableParentContext?"function"==typeof s.components?s.components(a):s.components||a:r(s.components),i.createElement(t.Provider,{value:e},s.children)}}}]);