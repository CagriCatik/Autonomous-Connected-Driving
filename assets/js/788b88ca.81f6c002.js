"use strict";(self.webpackChunkacd=self.webpackChunkacd||[]).push([[2572],{5916:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"introToolsSidebar":[{"type":"category","label":"Introduction","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Motivation","href":"/Autonomous-Connected-Driving/docs/theory/introduction-tools/introduction/Motivation","docId":"theory/introduction-tools/introduction/Motivation","unlisted":false},{"type":"link","label":"A-Model","href":"/Autonomous-Connected-Driving/docs/theory/introduction-tools/introduction/A_Model","docId":"theory/introduction-tools/introduction/A_Model","unlisted":false},{"type":"link","label":"Preface","href":"/Autonomous-Connected-Driving/docs/theory/introduction-tools/introduction/Preface","docId":"theory/introduction-tools/introduction/Preface","unlisted":false},{"type":"link","label":"Concept","href":"/Autonomous-Connected-Driving/docs/theory/introduction-tools/introduction/Concept","docId":"theory/introduction-tools/introduction/Concept","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/introduction"},{"type":"category","label":"Tools","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Topics","href":"/Autonomous-Connected-Driving/docs/theory/introduction-tools/tools/Topics","docId":"theory/introduction-tools/tools/Topics","unlisted":false},{"type":"link","label":"Tools Overview","href":"/Autonomous-Connected-Driving/docs/theory/introduction-tools/tools/Tools_Overview","docId":"theory/introduction-tools/tools/Tools_Overview","unlisted":false},{"type":"link","label":"Setup for Operating System","href":"/Autonomous-Connected-Driving/docs/theory/introduction-tools/tools/Setup_OS","docId":"theory/introduction-tools/tools/Setup_OS","unlisted":false},{"type":"link","label":"Setup ROS Coding Environment","href":"/Autonomous-Connected-Driving/docs/theory/introduction-tools/tools/Setup_ROS","docId":"theory/introduction-tools/tools/Setup_ROS","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/tools"}],"sensorSidebar":[{"type":"category","label":"Introduction","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Sensor Data Processing","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/introduction/","docId":"theory/sensor-data-processing/introduction/introduction","unlisted":false},{"type":"link","label":"Goals and Challenges of Environment Perception","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/introduction/goals_challenges","docId":"theory/sensor-data-processing/introduction/goals_challenges","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/introduction-1"},{"type":"category","label":"Image Segmentation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/image_segmentation/introduction","docId":"theory/sensor-data-processing/image_segmentation/introduction","unlisted":false},{"type":"link","label":"Deep Learning for Semantic Image Segmentation","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/image_segmentation/deep_learning","docId":"theory/sensor-data-processing/image_segmentation/deep_learning","unlisted":false},{"type":"link","label":"Training for Semantic Image Segmentation","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/image_segmentation/training","docId":"theory/sensor-data-processing/image_segmentation/training","unlisted":false},{"type":"link","label":"Evaluation","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/image_segmentation/evaluation","docId":"theory/sensor-data-processing/image_segmentation/evaluation","unlisted":false},{"type":"link","label":"Boosting Performance","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/image_segmentation/boosting_performance","docId":"theory/sensor-data-processing/image_segmentation/boosting_performance","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/image-segmentation"},{"type":"category","label":"Semantic Point Cloud Segmentation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/semantic_point_cloud_segmentation/introduction","docId":"theory/sensor-data-processing/semantic_point_cloud_segmentation/introduction","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/semantic_point_cloud_segmentation/deep_learning","docId":"theory/sensor-data-processing/semantic_point_cloud_segmentation/deep_learning","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/semantic_point_cloud_segmentation/training","docId":"theory/sensor-data-processing/semantic_point_cloud_segmentation/training","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/semantic_point_cloud_segmentation/evaluation","docId":"theory/sensor-data-processing/semantic_point_cloud_segmentation/evaluation","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/semantic_point_cloud_segmentation/boosting_performance","docId":"theory/sensor-data-processing/semantic_point_cloud_segmentation/boosting_performance","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/semantic-point-cloud-segmentation"},{"type":"category","label":"Object Detection","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/object_detection/introduction","docId":"theory/sensor-data-processing/object_detection/introduction","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/object_detection/deep_learning","docId":"theory/sensor-data-processing/object_detection/deep_learning","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/object_detection/training","docId":"theory/sensor-data-processing/object_detection/training","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/object_detection/evaluation","docId":"theory/sensor-data-processing/object_detection/evaluation","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/object-detection"},{"type":"category","label":"Point Cloud OGM","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/point_cloud_ogm/introduction","docId":"theory/sensor-data-processing/point_cloud_ogm/introduction","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/point_cloud_ogm/geometric_inverse_sensor","docId":"theory/sensor-data-processing/point_cloud_ogm/geometric_inverse_sensor","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/point_cloud_ogm/deep_inverse_sensor","docId":"theory/sensor-data-processing/point_cloud_ogm/deep_inverse_sensor","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/point_cloud_ogm/training_evaluation","docId":"theory/sensor-data-processing/point_cloud_ogm/training_evaluation","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/point-cloud-ogm"},{"type":"category","label":"Camera Based Semantic Grid Mapping","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/camera_based_semantic_grid_mapping/introduction","docId":"theory/sensor-data-processing/camera_based_semantic_grid_mapping/introduction","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/camera_based_semantic_grid_mapping/challenges","docId":"theory/sensor-data-processing/camera_based_semantic_grid_mapping/challenges","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/camera_based_semantic_grid_mapping/ipm","docId":"theory/sensor-data-processing/camera_based_semantic_grid_mapping/ipm","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/camera-based-semantic-grid-mapping"},{"type":"category","label":"Localization","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/localization/introduction","docId":"theory/sensor-data-processing/localization/introduction","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/localization/challenges","docId":"theory/sensor-data-processing/localization/challenges","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/localization/global_localization","docId":"theory/sensor-data-processing/localization/global_localization","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/localization/relative_localization","docId":"theory/sensor-data-processing/localization/relative_localization","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/sensor-data-processing/localization/combination_localization_approaches","docId":"theory/sensor-data-processing/localization/combination_localization_approaches","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/localization"}],"objectSidebar":[{"type":"category","label":"Semantic Point Cloud","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_fusion_tracking/introduction","docId":"theory/object-fusion-tracking/object_fusion_tracking/introduction","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_fusion_tracking/fundamentals","docId":"theory/object-fusion-tracking/object_fusion_tracking/fundamentals","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_fusion_tracking/traning","docId":"theory/object-fusion-tracking/object_fusion_tracking/traning","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_fusion_tracking/evaluation","docId":"theory/object-fusion-tracking/object_fusion_tracking/evaluation","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_fusion_tracking/boosting","docId":"theory/object-fusion-tracking/object_fusion_tracking/boosting","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/semantic-point-cloud"},{"type":"category","label":"Object Prediction","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_prediction/introduction","docId":"theory/object-fusion-tracking/object_prediction/introduction","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_prediction/deep-learning","docId":"theory/object-fusion-tracking/object_prediction/deep-learning","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_prediction/traning","docId":"theory/object-fusion-tracking/object_prediction/traning","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_prediction/evaluation","docId":"theory/object-fusion-tracking/object_prediction/evaluation","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_prediction/boosting","docId":"theory/object-fusion-tracking/object_prediction/boosting","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/object-prediction"},{"type":"category","label":"Object Association","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_association/introduction","docId":"theory/object-fusion-tracking/object_association/introduction","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_association/geometric_inverse_sensor_models","docId":"theory/object-fusion-tracking/object_association/geometric_inverse_sensor_models","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_association/deep_inverse_sensor_models","docId":"theory/object-fusion-tracking/object_association/deep_inverse_sensor_models","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_association/training_evaluation","docId":"theory/object-fusion-tracking/object_association/training_evaluation","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/object-association"},{"type":"category","label":"Object Fusion","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_fusion/challenges","docId":"theory/object-fusion-tracking/object_fusion/challenges","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/object_fusion/ipm","docId":"theory/object-fusion-tracking/object_fusion/ipm","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/object-fusion"},{"type":"category","label":"Localization","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/localization/introduction","docId":"theory/object-fusion-tracking/localization/introduction","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/localization/challenges","docId":"theory/object-fusion-tracking/localization/challenges","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/localization/global_localization","docId":"theory/object-fusion-tracking/localization/global_localization","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/localization/relative_localization","docId":"theory/object-fusion-tracking/localization/relative_localization","unlisted":false},{"type":"link","label":"Introduction","href":"/Autonomous-Connected-Driving/docs/theory/object-fusion-tracking/localization/combination_localization_approaches","docId":"theory/object-fusion-tracking/localization/combination_localization_approaches","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/localization-1"}],"vehicleSidebar":[{"type":"category","label":"Introduction","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Vehicle Guidance","href":"/Autonomous-Connected-Driving/docs/theory/vehicle-guidance/introduction/","docId":"theory/vehicle-guidance/introduction/introduction","unlisted":false},{"type":"link","label":"Goals, Challenges & Fundamentals","href":"/Autonomous-Connected-Driving/docs/theory/vehicle-guidance/introduction/goals_challenges_fundamentals","docId":"theory/vehicle-guidance/introduction/goals_challenges_fundamentals","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/introduction-2"},{"type":"category","label":"Navigation Level","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Vehicle Guidance on Navigation Level","href":"/Autonomous-Connected-Driving/docs/theory/vehicle-guidance/navigation_level/introduction_nav_level","docId":"theory/vehicle-guidance/navigation_level/introduction_nav_level","unlisted":false},{"type":"link","label":"Lanelet2","href":"/Autonomous-Connected-Driving/docs/theory/vehicle-guidance/navigation_level/lanelet2","docId":"theory/vehicle-guidance/navigation_level/lanelet2","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/navigation-level"},{"type":"category","label":"Guidance Level","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction to Guidance-Level Motion Planning","href":"/Autonomous-Connected-Driving/docs/theory/vehicle-guidance/guidance_level/introduction","docId":"theory/vehicle-guidance/guidance_level/introduction","unlisted":false},{"type":"link","label":"The Direct Multiple Shooting Approach","href":"/Autonomous-Connected-Driving/docs/theory/vehicle-guidance/guidance_level/direct_multiple_shooting","docId":"theory/vehicle-guidance/guidance_level/direct_multiple_shooting","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/guidance-level"},{"type":"category","label":"Stabilization Level","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Stabilization Level in Vehicle Control","href":"/Autonomous-Connected-Driving/docs/theory/vehicle-guidance/stabilization_level/introduction","docId":"theory/vehicle-guidance/stabilization_level/introduction","unlisted":false},{"type":"link","label":"Low-, High-, and Bi-Level Stabilization in Vehicle Control","href":"/Autonomous-Connected-Driving/docs/theory/vehicle-guidance/stabilization_level/levels","docId":"theory/vehicle-guidance/stabilization_level/levels","unlisted":false},{"type":"link","label":"Trajectory Control Using Feedback PID Controllers","href":"/Autonomous-Connected-Driving/docs/theory/vehicle-guidance/stabilization_level/trajectory_control","docId":"theory/vehicle-guidance/stabilization_level/trajectory_control","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/stabilization-level"}],"connectedSidebar":[{"type":"category","label":"Introduction ","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction to Connected Driving","href":"/Autonomous-Connected-Driving/docs/theory/connected-driving/introduction/","docId":"theory/connected-driving/introduction/introduction","unlisted":false},{"type":"link","label":"Connectivity in Automated Driving","href":"/Autonomous-Connected-Driving/docs/theory/connected-driving/introduction/categories","docId":"theory/connected-driving/introduction/categories","unlisted":false},{"type":"link","label":"Challenges of Automated and Connected Driving","href":"/Autonomous-Connected-Driving/docs/theory/connected-driving/introduction/challenges","docId":"theory/connected-driving/introduction/challenges","unlisted":false},{"type":"link","label":"Key Terminology in Connected Driving","href":"/Autonomous-Connected-Driving/docs/theory/connected-driving/introduction/key_term","docId":"theory/connected-driving/introduction/key_term","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/introduction-"},{"type":"category","label":"Collective Cloud Functions","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction to Collective Cloud Functions","href":"/Autonomous-Connected-Driving/docs/theory/connected-driving/collective_cloud_functions/fundamentals","docId":"theory/connected-driving/collective_cloud_functions/fundamentals","unlisted":false},{"type":"link","label":"Understanding MQTT Protocol for Connected Mobility","href":"/Autonomous-Connected-Driving/docs/theory/connected-driving/collective_cloud_functions/mqtt","docId":"theory/connected-driving/collective_cloud_functions/mqtt","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/collective-cloud-functions"},{"type":"category","label":"V2I Communication","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Infrastructure-to-Vehicle Communication (I2V) Documentation","href":"/Autonomous-Connected-Driving/docs/theory/connected-driving/v2i_communication/introduction","docId":"theory/connected-driving/v2i_communication/introduction","unlisted":false},{"type":"link","label":"SPAT and MAP Extended Messages in Connected Driving","href":"/Autonomous-Connected-Driving/docs/theory/connected-driving/v2i_communication/spatem","docId":"theory/connected-driving/v2i_communication/spatem","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/v2i-communication"}],"cppSidebar":[{"type":"category","label":"Introduction","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Syntax","href":"/Autonomous-Connected-Driving/docs/cpp/Introduction/syntax","docId":"cpp/Introduction/syntax","unlisted":false},{"type":"link","label":"Statements","href":"/Autonomous-Connected-Driving/docs/cpp/Introduction/statement","docId":"cpp/Introduction/statement","unlisted":false},{"type":"link","label":"Output for Text","href":"/Autonomous-Connected-Driving/docs/cpp/Introduction/print_text","docId":"cpp/Introduction/print_text","unlisted":false},{"type":"link","label":"Output for Numbers","href":"/Autonomous-Connected-Driving/docs/cpp/Introduction/print_numbers","docId":"cpp/Introduction/print_numbers","unlisted":false},{"type":"link","label":"New Lines","href":"/Autonomous-Connected-Driving/docs/cpp/Introduction/new_lines","docId":"cpp/Introduction/new_lines","unlisted":false},{"type":"link","label":"Pointers","href":"/Autonomous-Connected-Driving/docs/cpp/Introduction/pointers","docId":"cpp/Introduction/pointers","unlisted":false}]},{"type":"link","label":"content","href":"/Autonomous-Connected-Driving/docs/cpp/content","docId":"cpp/content","unlisted":false}],"pySidebar":[{"type":"link","label":"Intro","href":"/Autonomous-Connected-Driving/docs/python/Intro","docId":"python/Intro","unlisted":false},{"type":"link","label":"Syntax","href":"/Autonomous-Connected-Driving/docs/python/Syntax","docId":"python/Syntax","unlisted":false},{"type":"link","label":"Comments","href":"/Autonomous-Connected-Driving/docs/python/Comments","docId":"python/Comments","unlisted":false},{"type":"link","label":"Variables","href":"/Autonomous-Connected-Driving/docs/python/Variables","docId":"python/Variables","unlisted":false},{"type":"link","label":"content","href":"/Autonomous-Connected-Driving/docs/python/content","docId":"python/content","unlisted":false}],"rosSidebar":[{"type":"link","label":"ROS","href":"/Autonomous-Connected-Driving/docs/ros/introduction","docId":"ros/introduction","unlisted":false},{"type":"link","label":"content","href":"/Autonomous-Connected-Driving/docs/ros/content","docId":"ros/content","unlisted":false}],"ros2Sidebar":[{"type":"link","label":"ROS2","href":"/Autonomous-Connected-Driving/docs/ros2/introduction","docId":"ros2/introduction","unlisted":false},{"type":"link","label":"content","href":"/Autonomous-Connected-Driving/docs/ros2/content","docId":"ros2/content","unlisted":false}],"taskSidebar":[{"type":"category","label":"Introduction & Tools","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Task","href":"/Autonomous-Connected-Driving/docs/task/intro/1","docId":"task/intro/1","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/introduction--tools"},{"type":"category","label":"Sensor Data Processing","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Image Segmentation - Tasks","href":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/image_segmentation_tasks","docId":"task/sensor_data_processing/image_segmentation_tasks","unlisted":false},{"type":"link","label":"Image Segmentation - Solutions","href":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/image_segmentation_solutions","docId":"task/sensor_data_processing/image_segmentation_solutions","unlisted":false},{"type":"link","label":"Point Cloud Segmentation - Tasks","href":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/point_cloud_segmentation_tasks","docId":"task/sensor_data_processing/point_cloud_segmentation_tasks","unlisted":false},{"type":"link","label":"Point Cloud Segmentation - Solutions","href":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/point_cloud_segmentation_solutions","docId":"task/sensor_data_processing/point_cloud_segmentation_solutions","unlisted":false},{"type":"link","label":"Object Detection - Tasks","href":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/object_detection_tasks","docId":"task/sensor_data_processing/object_detection_tasks","unlisted":false},{"type":"link","label":"Object Detection - Solutions","href":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/object_detection_solutions","docId":"task/sensor_data_processing/object_detection_solutions","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/sensor-data-processing"},{"type":"category","label":"Object Fusion and Tracking","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"01_","href":"/Autonomous-Connected-Driving/docs/task/object_fusion_tracking/01_","docId":"task/object_fusion_tracking/01_","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/object-fusion-and-tracking"},{"type":"category","label":"Vehicle Guidance","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"01_","href":"/Autonomous-Connected-Driving/docs/task/vehicle_guidance/01_","docId":"task/vehicle_guidance/01_","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/vehicle-guidance"},{"type":"category","label":"Connected Driving","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"01_","href":"/Autonomous-Connected-Driving/docs/task/connected_driving/01_","docId":"task/connected_driving/01_","unlisted":false}],"href":"/Autonomous-Connected-Driving/docs/category/connected-driving"}]},"docs":{"cpp/content":{"id":"cpp/content","title":"content","description":"1. Introduction and Basics","sidebar":"cppSidebar"},"cpp/Introduction/new_lines":{"id":"cpp/Introduction/new_lines","title":"New Lines","description":"","sidebar":"cppSidebar"},"cpp/Introduction/pointers":{"id":"cpp/Introduction/pointers","title":"Pointers","description":"---","sidebar":"cppSidebar"},"cpp/Introduction/print_numbers":{"id":"cpp/Introduction/print_numbers","title":"Output for Numbers","description":"---","sidebar":"cppSidebar"},"cpp/Introduction/print_text":{"id":"cpp/Introduction/print_text","title":"Output for Text","description":"---","sidebar":"cppSidebar"},"cpp/Introduction/statement":{"id":"cpp/Introduction/statement","title":"Statements","description":"---","sidebar":"cppSidebar"},"cpp/Introduction/syntax":{"id":"cpp/Introduction/syntax","title":"Syntax","description":"---","sidebar":"cppSidebar"},"python/Comments":{"id":"python/Comments","title":"Comments","description":"","sidebar":"pySidebar"},"python/content":{"id":"python/content","title":"content","description":"1. Introduction and Basics","sidebar":"pySidebar"},"python/Intro":{"id":"python/Intro","title":"Intro","description":"","sidebar":"pySidebar"},"python/Syntax":{"id":"python/Syntax","title":"Syntax","description":"","sidebar":"pySidebar"},"python/Variables":{"id":"python/Variables","title":"Variables","description":"","sidebar":"pySidebar"},"ros/content":{"id":"ros/content","title":"content","description":"1. Introduction and Basics","sidebar":"rosSidebar"},"ros/introduction":{"id":"ros/introduction","title":"ROS","description":"","sidebar":"rosSidebar"},"ros2/content":{"id":"ros2/content","title":"content","description":"1. Introduction and Basics","sidebar":"ros2Sidebar"},"ros2/introduction":{"id":"ros2/introduction","title":"ROS2","description":"","sidebar":"ros2Sidebar"},"task/connected_driving/01_":{"id":"task/connected_driving/01_","title":"01_","description":"","sidebar":"taskSidebar"},"task/intro/1":{"id":"task/intro/1","title":"Task","description":"","sidebar":"taskSidebar"},"task/object_fusion_tracking/01_":{"id":"task/object_fusion_tracking/01_","title":"01_","description":"","sidebar":"taskSidebar"},"task/sensor_data_processing/image_segmentation_solutions":{"id":"task/sensor_data_processing/image_segmentation_solutions","title":"Image Segmentation - Solutions","description":"","sidebar":"taskSidebar"},"task/sensor_data_processing/image_segmentation_tasks":{"id":"task/sensor_data_processing/image_segmentation_tasks","title":"Image Segmentation - Tasks","description":"","sidebar":"taskSidebar"},"task/sensor_data_processing/object_detection_solutions":{"id":"task/sensor_data_processing/object_detection_solutions","title":"Object Detection - Solutions","description":"","sidebar":"taskSidebar"},"task/sensor_data_processing/object_detection_tasks":{"id":"task/sensor_data_processing/object_detection_tasks","title":"Object Detection - Tasks","description":"","sidebar":"taskSidebar"},"task/sensor_data_processing/point_cloud_segmentation_solutions":{"id":"task/sensor_data_processing/point_cloud_segmentation_solutions","title":"Point Cloud Segmentation - Solutions","description":"","sidebar":"taskSidebar"},"task/sensor_data_processing/point_cloud_segmentation_tasks":{"id":"task/sensor_data_processing/point_cloud_segmentation_tasks","title":"Point Cloud Segmentation - Tasks","description":"","sidebar":"taskSidebar"},"task/vehicle_guidance/01_":{"id":"task/vehicle_guidance/01_","title":"01_","description":"","sidebar":"taskSidebar"},"theory/connected-driving/collective_cloud_functions/fundamentals":{"id":"theory/connected-driving/collective_cloud_functions/fundamentals","title":"Introduction to Collective Cloud Functions","description":"Collective cloud functions are pivotal in the realm of automated driving, serving as the backbone for centralized data processing and distribution. These functions facilitate the seamless integration of data from multiple sources, ensuring that connected vehicles and infrastructure components operate with enhanced intelligence and coordination. The distinguishing features of collective cloud functions are:","sidebar":"connectedSidebar"},"theory/connected-driving/collective_cloud_functions/mqtt":{"id":"theory/connected-driving/collective_cloud_functions/mqtt","title":"Understanding MQTT Protocol for Connected Mobility","description":"In the rapidly evolving landscape of connected mobility, efficient and reliable communication protocols are paramount. The Message Queuing Telemetry Transport (MQTT) protocol stands out as a lightweight, scalable solution tailored for the Internet of Things (IoT). This documentation delves into the intricacies of MQTT, exploring its core features, architectural components, quality of service levels, and its seamless integration with the Robot Operating System (ROS). Whether you\'re a beginner embarking on your IoT journey or an advanced developer seeking to optimize your connected mobility systems, this guide offers comprehensive insights to enhance your understanding and application of MQTT.","sidebar":"connectedSidebar"},"theory/connected-driving/introduction/categories":{"id":"theory/connected-driving/introduction/categories","title":"Connectivity in Automated Driving","description":"Connectivity plays a pivotal role in automated driving, enabling a multitude of functions that enhance efficiency, safety, and overall functionality. These connectivity-enabled functions can be categorized into Cooperative Functions, Collective Functions, and Supportive Functions. This documentation delves into each category, providing comprehensive insights supported by concepts from the ACDC course material.","sidebar":"connectedSidebar"},"theory/connected-driving/introduction/challenges":{"id":"theory/connected-driving/introduction/challenges","title":"Challenges of Automated and Connected Driving","description":"Automated and connected driving is revolutionizing the landscape of mobility, promising significant advancements in safety, efficiency, comfort, and environmental sustainability. By leveraging cutting-edge technologies, these systems aim to reduce human error, optimize traffic flow, and minimize the environmental footprint of transportation. However, the journey towards fully realizing automated and connected driving is fraught with a myriad of challenges that span technological, infrastructural, regulatory, and implementation domains. Addressing these challenges is crucial to ensure the successful integration and widespread adoption of these transformative systems.","sidebar":"connectedSidebar"},"theory/connected-driving/introduction/introduction":{"id":"theory/connected-driving/introduction/introduction","title":"Introduction to Connected Driving","description":"The Connected Driving module introduces the fundamental concepts, goals, and benefits of integrating connected functionalities into automated vehicles, setting the stage for advanced understanding and practical implementations.","sidebar":"connectedSidebar"},"theory/connected-driving/introduction/key_term":{"id":"theory/connected-driving/introduction/key_term","title":"Key Terminology in Connected Driving","description":"Connected driving leverages advanced communication technologies to enhance vehicular interactions and transportation infrastructure. This documentation provides a comprehensive overview of essential concepts and terminologies associated with connected driving, catering to both beginners and advanced users.","sidebar":"connectedSidebar"},"theory/connected-driving/v2i_communication/introduction":{"id":"theory/connected-driving/v2i_communication/introduction","title":"Infrastructure-to-Vehicle Communication (I2V) Documentation","description":"Infrastructure-to-Vehicle (I2V) communication is a pivotal component in the landscape of connected and automated driving. By facilitating the exchange of critical data between road infrastructure, vehicles, and other traffic participants, I2V aims to significantly enhance road safety and traffic efficiency. This documentation delves into the standardized message formats, benefits, and challenges associated with I2V communication, as well as its potential to complement and augment vehicle sensor systems.","sidebar":"connectedSidebar"},"theory/connected-driving/v2i_communication/spatem":{"id":"theory/connected-driving/v2i_communication/spatem","title":"SPAT and MAP Extended Messages in Connected Driving","description":"In the rapidly evolving landscape of automated and connected driving, effective communication between vehicles and traffic infrastructure is paramount. Two pivotal components in this communication framework are the Signal Phase and Timing (SPAT) Extended Message and the MAP Extended Message. These messages enable seamless Vehicle-to-Infrastructure (V2I) interactions, which are essential for optimizing traffic flow, enhancing road safety, and paving the way for fully autonomous transportation systems.","sidebar":"connectedSidebar"},"theory/introduction-tools/introduction/A_Model":{"id":"theory/introduction-tools/introduction/A_Model","title":"A-Model","description":"The Automated and Connected Driving Challenges (ACDC) course is designed to provide comprehensive education on the methodologies and tools essential for understanding and advancing automated and connected vehicle systems. This documentation serves as a guide to understanding the course\'s structure, objectives, and key components such as the A-Model framework and the integration of the Robot Operating System (ROS).","sidebar":"introToolsSidebar"},"theory/introduction-tools/introduction/Concept":{"id":"theory/introduction-tools/introduction/Concept","title":"Concept","description":"","sidebar":"introToolsSidebar"},"theory/introduction-tools/introduction/Motivation":{"id":"theory/introduction-tools/introduction/Motivation","title":"Motivation","description":"Introduction","sidebar":"introToolsSidebar"},"theory/introduction-tools/introduction/Preface":{"id":"theory/introduction-tools/introduction/Preface","title":"Preface","description":"This Knowledge-Base is designed to serve as an all-encompassing guide, providing in-depth insights into the concepts, tools, and methodologies that underpin the Automated and Connected Driving (ACD) curriculum. Whether you are a beginner stepping into the world of autonomous systems or an experienced professional seeking to deepen your expertise, this resource offers structured, detailed, and actionable content to guide your learning journey.","sidebar":"introToolsSidebar"},"theory/introduction-tools/tools/Setup_OS":{"id":"theory/introduction-tools/tools/Setup_OS","title":"Setup for Operating System","description":"This part provides a structured and user-friendly guide to setting up the required environment for the ACDC programming exercises, focusing on ROS and Jupyter Notebook tasks. It caters to users on different operating systems, offering detailed explanations, installation steps, and troubleshooting tips.","sidebar":"introToolsSidebar"},"theory/introduction-tools/tools/Setup_ROS":{"id":"theory/introduction-tools/tools/Setup_ROS","title":"Setup ROS Coding Environment","description":"Introduction","sidebar":"introToolsSidebar"},"theory/introduction-tools/tools/Tools_Overview":{"id":"theory/introduction-tools/tools/Tools_Overview","title":"Tools Overview","description":"Automated and Connected Driving Challenges (ACDC) require the integration of various software tools to address complex tasks. This documentation provides an in-depth overview of the tools used in the ACDC course, focusing on their functionalities, applications, and role in learning and development. The tools covered include edX, Jupyter Notebooks, GitHub, Robot Operating System (ROS), Docker, and various programming languages.","sidebar":"introToolsSidebar"},"theory/introduction-tools/tools/Topics":{"id":"theory/introduction-tools/tools/Topics","title":"Topics","description":"","sidebar":"introToolsSidebar"},"theory/object-fusion-tracking/localization/challenges":{"id":"theory/object-fusion-tracking/localization/challenges","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/localization/combination_localization_approaches":{"id":"theory/object-fusion-tracking/localization/combination_localization_approaches","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/localization/global_localization":{"id":"theory/object-fusion-tracking/localization/global_localization","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/localization/introduction":{"id":"theory/object-fusion-tracking/localization/introduction","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/localization/relative_localization":{"id":"theory/object-fusion-tracking/localization/relative_localization","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_association/deep_inverse_sensor_models":{"id":"theory/object-fusion-tracking/object_association/deep_inverse_sensor_models","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_association/geometric_inverse_sensor_models":{"id":"theory/object-fusion-tracking/object_association/geometric_inverse_sensor_models","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_association/introduction":{"id":"theory/object-fusion-tracking/object_association/introduction","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_association/training_evaluation":{"id":"theory/object-fusion-tracking/object_association/training_evaluation","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_fusion_tracking/boosting":{"id":"theory/object-fusion-tracking/object_fusion_tracking/boosting","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_fusion_tracking/evaluation":{"id":"theory/object-fusion-tracking/object_fusion_tracking/evaluation","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_fusion_tracking/fundamentals":{"id":"theory/object-fusion-tracking/object_fusion_tracking/fundamentals","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_fusion_tracking/introduction":{"id":"theory/object-fusion-tracking/object_fusion_tracking/introduction","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_fusion_tracking/traning":{"id":"theory/object-fusion-tracking/object_fusion_tracking/traning","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_fusion/challenges":{"id":"theory/object-fusion-tracking/object_fusion/challenges","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_fusion/ipm":{"id":"theory/object-fusion-tracking/object_fusion/ipm","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_prediction/boosting":{"id":"theory/object-fusion-tracking/object_prediction/boosting","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_prediction/deep-learning":{"id":"theory/object-fusion-tracking/object_prediction/deep-learning","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_prediction/evaluation":{"id":"theory/object-fusion-tracking/object_prediction/evaluation","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_prediction/introduction":{"id":"theory/object-fusion-tracking/object_prediction/introduction","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/object-fusion-tracking/object_prediction/traning":{"id":"theory/object-fusion-tracking/object_prediction/traning","title":"Introduction","description":"","sidebar":"objectSidebar"},"theory/sensor-data-processing/camera_based_semantic_grid_mapping/challenges":{"id":"theory/sensor-data-processing/camera_based_semantic_grid_mapping/challenges","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/camera_based_semantic_grid_mapping/introduction":{"id":"theory/sensor-data-processing/camera_based_semantic_grid_mapping/introduction","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/camera_based_semantic_grid_mapping/ipm":{"id":"theory/sensor-data-processing/camera_based_semantic_grid_mapping/ipm","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/image_segmentation/boosting_performance":{"id":"theory/sensor-data-processing/image_segmentation/boosting_performance","title":"Boosting Performance","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/image_segmentation/deep_learning":{"id":"theory/sensor-data-processing/image_segmentation/deep_learning","title":"Deep Learning for Semantic Image Segmentation","description":"Deep learning has revolutionized semantic image segmentation, surpassing classical machine learning approaches in performance. This advancement is fueled by the availability of large datasets, significant hardware improvements, and the inherent ability of neural networks to learn complex patterns from data. This document delves into the principles, datasets, input-output representations, and architectures used in deep learning for semantic segmentation, particularly within the context of automated driving.","sidebar":"sensorSidebar"},"theory/sensor-data-processing/image_segmentation/evaluation":{"id":"theory/sensor-data-processing/image_segmentation/evaluation","title":"Evaluation","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/image_segmentation/introduction":{"id":"theory/sensor-data-processing/image_segmentation/introduction","title":"Introduction","description":"Semantic image segmentation is a cornerstone of computer vision in automated driving. It involves assigning a semantic class, such as \\"road,\\" \\"pedestrian,\\" or \\"car,\\" to every pixel in an image. This granular level of classification enables a vehicle to gain a comprehensive understanding of its surroundings, which is vital for safe navigation and informed decision-making. By accurately interpreting the visual environment, autonomous vehicles can effectively differentiate between various objects and surfaces, allowing for nuanced responses to dynamic driving conditions. This document delves into the fundamentals, challenges, and contemporary approaches to semantic segmentation, with a particular emphasis on modern deep learning techniques that drive advancements in this field.","sidebar":"sensorSidebar"},"theory/sensor-data-processing/image_segmentation/training":{"id":"theory/sensor-data-processing/image_segmentation/training","title":"Training for Semantic Image Segmentation","description":"Training deep learning models for semantic image segmentation is a meticulous process that involves designing appropriate network architectures, selecting effective loss functions, optimizing model parameters, and fine-tuning hyperparameters. This section provides a comprehensive overview of the training process, focusing on the encoder-decoder architecture, loss functions, optimization techniques, hyperparameter tuning, and practical applications within the context of automated driving.","sidebar":"sensorSidebar"},"theory/sensor-data-processing/introduction/goals_challenges":{"id":"theory/sensor-data-processing/introduction/goals_challenges","title":"Goals and Challenges of Environment Perception","description":"Environment perception is a critical component of sensor data processing in autonomous vehicles. It involves detecting and characterizing elements within the vehicle\'s surroundings to enable safe and intelligent decision-making. This document outlines the goals and challenges of environment perception, emphasizing the use of advanced algorithms, particularly neural networks, to tackle these tasks.","sidebar":"sensorSidebar"},"theory/sensor-data-processing/introduction/introduction":{"id":"theory/sensor-data-processing/introduction/introduction","title":"Sensor Data Processing","description":"Sensor data processing is a cornerstone of autonomous vehicle functionality. It enables vehicles to perceive and interpret their environment, similar to human perception, ensuring safe and efficient operation. This document introduces the goals, categories, and challenges of sensor data processing, focusing on environment perception through electromagnetic and pressure wave detection.","sidebar":"sensorSidebar"},"theory/sensor-data-processing/localization/challenges":{"id":"theory/sensor-data-processing/localization/challenges","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/localization/combination_localization_approaches":{"id":"theory/sensor-data-processing/localization/combination_localization_approaches","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/localization/global_localization":{"id":"theory/sensor-data-processing/localization/global_localization","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/localization/introduction":{"id":"theory/sensor-data-processing/localization/introduction","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/localization/relative_localization":{"id":"theory/sensor-data-processing/localization/relative_localization","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/object_detection/deep_learning":{"id":"theory/sensor-data-processing/object_detection/deep_learning","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/object_detection/evaluation":{"id":"theory/sensor-data-processing/object_detection/evaluation","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/object_detection/introduction":{"id":"theory/sensor-data-processing/object_detection/introduction","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/object_detection/training":{"id":"theory/sensor-data-processing/object_detection/training","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/point_cloud_ogm/deep_inverse_sensor":{"id":"theory/sensor-data-processing/point_cloud_ogm/deep_inverse_sensor","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/point_cloud_ogm/geometric_inverse_sensor":{"id":"theory/sensor-data-processing/point_cloud_ogm/geometric_inverse_sensor","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/point_cloud_ogm/introduction":{"id":"theory/sensor-data-processing/point_cloud_ogm/introduction","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/point_cloud_ogm/training_evaluation":{"id":"theory/sensor-data-processing/point_cloud_ogm/training_evaluation","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/semantic_point_cloud_segmentation/boosting_performance":{"id":"theory/sensor-data-processing/semantic_point_cloud_segmentation/boosting_performance","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/semantic_point_cloud_segmentation/deep_learning":{"id":"theory/sensor-data-processing/semantic_point_cloud_segmentation/deep_learning","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/semantic_point_cloud_segmentation/evaluation":{"id":"theory/sensor-data-processing/semantic_point_cloud_segmentation/evaluation","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/semantic_point_cloud_segmentation/introduction":{"id":"theory/sensor-data-processing/semantic_point_cloud_segmentation/introduction","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/sensor-data-processing/semantic_point_cloud_segmentation/training":{"id":"theory/sensor-data-processing/semantic_point_cloud_segmentation/training","title":"Introduction","description":"","sidebar":"sensorSidebar"},"theory/vehicle-guidance/guidance_level/direct_multiple_shooting":{"id":"theory/vehicle-guidance/guidance_level/direct_multiple_shooting","title":"The Direct Multiple Shooting Approach","description":"The Direct Multiple Shooting Approach is an advanced methodology for addressing Optimal Control Problems (OCPs) within the realm of motion planning for autonomous vehicles. Building upon the foundational principles of direct approaches, this technique discretizes the control function into distinct intervals and performs forward integration of the system dynamics within each interval. This strategic balance between flexibility and robustness renders the Direct Multiple Shooting Approach particularly well-suited for handling complex vehicle models and nonlinear systems, ensuring precise and reliable motion planning.","sidebar":"vehicleSidebar"},"theory/vehicle-guidance/guidance_level/introduction":{"id":"theory/vehicle-guidance/guidance_level/introduction","title":"Introduction to Guidance-Level Motion Planning","description":"The guidance-level task in autonomous driving is pivotal for achieving precise motion planning and control, enabling a vehicle to transition seamlessly from an initial state to a desired goal state. Building upon foundational concepts of vehicle guidance, such as the Optimal Control Problem (OCP), this section delves into three primary methods for solving the OCP: dynamic programming, direct approaches, and indirect approaches. Central to this exploration is the model of vehicle guidance by Donges, which provides a comprehensive framework for understanding and implementing these methodologies.","sidebar":"vehicleSidebar"},"theory/vehicle-guidance/introduction/goals_challenges_fundamentals":{"id":"theory/vehicle-guidance/introduction/goals_challenges_fundamentals","title":"Goals, Challenges & Fundamentals","description":"Vehicle guidance is a fundamental component of automated driving systems, ensuring the safe, efficient, and robust operation of autonomous vehicles (AVs). It encompasses the vehicle\u2019s ability to navigate complex environments, make tactical decisions, and execute precise control actions. This framework is structured across three hierarchical levels:","sidebar":"vehicleSidebar"},"theory/vehicle-guidance/introduction/introduction":{"id":"theory/vehicle-guidance/introduction/introduction","title":"Vehicle Guidance","description":"Vehicle guidance is a pivotal component within the software architecture of automated driving systems. It ensures the safe and efficient navigation of autonomous vehicles by leveraging data from various upstream modules, such as perception and environment modeling. Beyond mere collision avoidance, vehicle guidance aims to enhance driving comfort and operational efficiency. Functioning as a tactical process, it translates high-level strategic navigation plans into actionable instructions, effectively bridging the gap between overarching decision-making and granular vehicle control.","sidebar":"vehicleSidebar"},"theory/vehicle-guidance/navigation_level/introduction_nav_level":{"id":"theory/vehicle-guidance/navigation_level/introduction_nav_level","title":"Vehicle Guidance on Navigation Level","description":"Vehicle guidance is essential for enabling autonomous systems to navigate complex environments effectively. It encompasses methods and algorithms designed to solve navigation problems, optimizing for safety, efficiency, and adaptability. This document explores the theoretical foundations and practical applications of vehicle guidance, with a particular focus on dynamic programming methods grounded in Bellman\u2019s principle of optimality.","sidebar":"vehicleSidebar"},"theory/vehicle-guidance/navigation_level/lanelet2":{"id":"theory/vehicle-guidance/navigation_level/lanelet2","title":"Lanelet2","description":"The Lanelet2 framework stands at the forefront of digital map representation and route planning technologies tailored for autonomous driving applications. Building upon and extending the capabilities of traditional navigation systems, Lanelet2 introduces lanelets\u2014modular and extensible data structures that offer high-granularity representations of road networks. This framework seamlessly integrates with motion planning and guidance-level algorithms, such as the Dijkstra algorithm, facilitating efficient route computation and trajectory planning. As a cornerstone for autonomous driving systems, Lanelet2 provides robust solutions to complex routing and navigation challenges, enabling safer and more reliable autonomous vehicle (AV) operations.","sidebar":"vehicleSidebar"},"theory/vehicle-guidance/stabilization_level/introduction":{"id":"theory/vehicle-guidance/stabilization_level/introduction","title":"Stabilization Level in Vehicle Control","description":"The stabilization level is a pivotal component of vehicle control systems in autonomous driving, responsible for ensuring that the vehicle adheres to the planned trajectory with minimal deviation. It compensates for external disturbances and inaccuracies in both the vehicle\'s state and the planned trajectory. Operating closest to the vehicle\'s physical interface, the stabilization level bridges the gap between high-level trajectory planning and low-level actuator commands, ensuring smooth and precise vehicle maneuvers.","sidebar":"vehicleSidebar"},"theory/vehicle-guidance/stabilization_level/levels":{"id":"theory/vehicle-guidance/stabilization_level/levels","title":"Low-, High-, and Bi-Level Stabilization in Vehicle Control","description":"Vehicle stabilization approaches are essential for ensuring that autonomous vehicles adhere closely to their planned trajectories, minimizing deviations caused by various disturbances. This document delves into three primary stabilization methodologies\u2014low-level stabilization, high-level stabilization, and bi-level stabilization\u2014each tailored to address specific types of disturbances and operational scenarios within automated driving systems.","sidebar":"vehicleSidebar"},"theory/vehicle-guidance/stabilization_level/trajectory_control":{"id":"theory/vehicle-guidance/stabilization_level/trajectory_control","title":"Trajectory Control Using Feedback PID Controllers","description":"Trajectory control at the stabilization level is a cornerstone of autonomous driving systems, ensuring that vehicles accurately follow pre-planned paths with minimal deviation. This is achieved through the integration of feedback PID controllers with feedforward controls. The primary objective is to calculate and correct deviations in both longitudinal and lateral movements, maintaining precise adherence to the desired trajectory. This is implemented using a closed-loop simulation within the ROS (Robot Operating System) framework, leveraging odometry calculations, trajectory data interpolation, and sophisticated control system design.","sidebar":"vehicleSidebar"}}}}')}}]);