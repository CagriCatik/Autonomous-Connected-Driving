"use strict";(self.webpackChunkacd=self.webpackChunkacd||[]).push([[4878],{4976:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>r,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"task/sensor_data_processing/Semantic-Point-Cloud-Segmentation","title":"Perform Deep Learning based Semantic Point Cloud Segmentation","description":"ROS2","source":"@site/docs/task/02_sensor_data_processing/07_Semantic-Point-Cloud-Segmentation.md","sourceDirName":"task/02_sensor_data_processing","slug":"/task/sensor_data_processing/Semantic-Point-Cloud-Segmentation","permalink":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/Semantic-Point-Cloud-Segmentation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/task/02_sensor_data_processing/07_Semantic-Point-Cloud-Segmentation.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{},"sidebar":"taskSidebar","previous":{"title":"Perform Deep Learning based semantic image segmentation applied on camera images","permalink":"/Autonomous-Connected-Driving/docs/task/sensor_data_processing/Semantic-Image-Segmentation"},"next":{"title":"Object Fusion Tracking","permalink":"/Autonomous-Connected-Driving/docs/category/object-fusion-tracking"}}');var o=s(4848),t=s(8453);const l={},a="Perform Deep Learning based Semantic Point Cloud Segmentation",r={},d=[{value:"Start the Docker Environment",id:"start-the-docker-environment",level:2},{value:"Download and inspect bag file",id:"download-and-inspect-bag-file",level:2},{value:"ROS2&#39;s <code>sensor_msgs/msg/PointCloud2</code> Message",id:"ros2s-sensor_msgsmsgpointcloud2-message",level:2},{value:"Build and source the package",id:"build-and-source-the-package",level:2},{value:"Review of file pointcloud_segmentation.py",id:"review-of-file-pointcloud_segmentationpy",level:2},{value:"Task 1: Instantiate <code>PointCloud2</code> publisher for the segmented point cloud",id:"task-1-instantiate-pointcloud2-publisher-for-the-segmented-point-cloud",level:2},{value:"Task 2: Publish a <code>PointCloud2</code> message containing the segmented point cloud with the publisher",id:"task-2-publish-a-pointcloud2-message-containing-the-segmented-point-cloud-with-the-publisher",level:2},{value:"Run Node and use RVIZ for visualization",id:"run-node-and-use-rviz-for-visualization",level:2},{value:"Wrap-up",id:"wrap-up",level:2},{value:"ROS1 Instructions",id:"ros1-instructions",level:2},{value:"Perform Deep Learning based Semantic Point Cloud Segmentation",id:"perform-deep-learning-based-semantic-point-cloud-segmentation-1",level:4},{value:"Use the Docker Environment",id:"use-the-docker-environment",level:2},{value:"Download and inspect bag file",id:"download-and-inspect-bag-file-1",level:2},{value:"ROS&#39;s <code>sensor_msgs/PointCloud2</code> Message",id:"ross-sensor_msgspointcloud2-message",level:2},{value:"Build and source the package",id:"build-and-source-the-package-1",level:2},{value:"Replay rosbag and run point cloud segmentation",id:"replay-rosbag-and-run-point-cloud-segmentation",level:2},{value:"Review of file pointcloud_segmentation.py",id:"review-of-file-pointcloud_segmentationpy-1",level:2},{value:"Task 1: Instantiate <code>PointCloud2</code> publisher for the segmented point cloud",id:"task-1-instantiate-pointcloud2-publisher-for-the-segmented-point-cloud-1",level:2},{value:"Task 2: Publish a <code>PointCloud2</code> message containing the segmented point cloud with the publisher",id:"task-2-publish-a-pointcloud2-message-containing-the-segmented-point-cloud-with-the-publisher-1",level:2},{value:"Run Node and use RVIZ for visualization",id:"run-node-and-use-rviz-for-visualization-1",level:2},{value:"Wrap-up",id:"wrap-up-1",level:2}];function c(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h4:"h4",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"perform-deep-learning-based-semantic-point-cloud-segmentation",children:"Perform Deep Learning based Semantic Point Cloud Segmentation"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:"https://img.shields.io/badge/ROS2-red",alt:"ROS2"})}),"\n",(0,o.jsx)("img",{src:"../images/video2.gif",alt:"Description of image"}),"\n",(0,o.jsxs)(n.p,{children:["In this workshop, we will perform ",(0,o.jsx)(n.strong,{children:"semantic point cloud segmentation"})," on raw LiDAR data using the deep learning model from the notebooks. In particular, we will take a recording from our test vehicle which is equipped with a Velodyne VLP-32C and we will apply our detection model on the raw sensor data."]}),"\n",(0,o.jsx)(n.p,{children:"The  learning goals of this workshop are"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Inspect a rosbag which contains point cloud data"}),"\n",(0,o.jsxs)(n.li,{children:["Learn about ROS2' standard point cloud message definition ",(0,o.jsx)(n.code,{children:"points2"})]}),"\n",(0,o.jsx)(n.li,{children:"Learn about a simple Python inference node for semantic point cloud segmentation"}),"\n",(0,o.jsx)(n.li,{children:"Implement a ROS2 publisher which publishes the segmented point cloud"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"start-the-docker-environment",children:"Start the Docker Environment"}),"\n",(0,o.jsxs)(n.p,{children:["Navigate to the local directory ",(0,o.jsx)(n.code,{children:"${REPOSITORY}/docker"})," and execute ",(0,o.jsx)(n.code,{children:"./ros2_run.sh"}),". This will start the Docker container, in which ROS and all required libraries are preinstalled. You can stop the container by pressing ",(0,o.jsx)("kbd",{children:"Ctrl"}),"+",(0,o.jsx)("kbd",{children:"C"})," in the terminal. If everything is setup correctly you will see the following:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Starting new container...\n================================================================================\n\n=== CONTAINER INFORMATION ======================================================\nArchitecture: x86_64\nUbuntu: 22.04.2 LTS (Jammy Jellyfish)\nPython: 3.10.6\nROS: humble\nCMake: 3.22.1\nCUDA: 12.1.105\ncuDNN: 8.9.2\nTensorRT: 8.6.1\nTensorFlow Python: 2.13.0\nTensorFlow C/C++: \nPyTorch Python: \nPyTorch C/C++: \nAvailable GPUs: 1\n  name               driver_version   utilization.gpu [%]   utilization.memory [%]   memory.used [MiB]   memory.total [MiB]\n  NVIDIA TITAN RTX   470.182.03       0 %                   2 %                      552 MiB             24217 MiB\n===============================================================================\n\nroot@******:/home/rosuser/ws/colcon_workspace# \n"})}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"acdc"})," folder is mounted from your host into the container. Note that your current working directory inside the container is ",(0,o.jsx)(n.code,{children:"/home/rosuser/ws/colcon_workspace"}),"."]}),"\n",(0,o.jsx)(n.h2,{id:"download-and-inspect-bag-file",children:"Download and inspect bag file"}),"\n",(0,o.jsxs)(n.p,{children:["Download the file ",(0,o.jsx)(n.code,{children:"lidar_campus_melaten.db3"})," from ",(0,o.jsx)(n.a,{href:"https://rwth-aachen.sciebo.de/s/YALin3OaIdRjmhQ",children:"here (1.5 GB)"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["Save this file to your local directory ",(0,o.jsx)(n.code,{children:"${REPOSITORY}/bag"}),". This directory will be mounted into the docker container to the path ",(0,o.jsx)(n.code,{children:"/home/rosuser/ws/bag"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["You can start the docker container now with ",(0,o.jsx)(n.code,{children:"./ros2_run.sh"})," (if you haven't already)."]}),"\n",(0,o.jsxs)(n.p,{children:["Inside the container, you can navigate to ",(0,o.jsx)(n.code,{children:"/home/rosuser/ws/bag"})," and execute ",(0,o.jsx)(n.code,{children:"ros2 bag info lidar_campus_melaten.db3"})," to inspect the rosbag:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"~/bag$ ros2 bag info lidar_campus_melaten.db3\nFiles:             lidar_campus_melaten.db3\nBag size:          1.5 GiB\nStorage id:        sqlite3\nDuration:          119.955s\nStart:             Feb  5 2020 16:25:31.409 (1580916331.409)\nEnd:               Feb  5 2020 16:27:31.365 (1580916451.365)\nMessages:          1200\nTopic information: \n    Topic: /points2 | Type: sensor_msgs/msg/PointCloud2 | Count: 1199 | \n    Serialization Format: cdr\n    Topic: /tf_static | Type: tf2_msgs/msg/TFMessage | Count: 1 | \n    Serialization Format: cdr\n\n"})}),"\n",(0,o.jsxs)(n.p,{children:["You can see that the rosbag has a duration of 1 minute and 59 seconds and contains 1199 frames of type ",(0,o.jsx)(n.code,{children:"sensor_msgs/PointCloud2"}),". We will use these point cloud data in this assignment in order to apply semantic point cloud segmentation."]}),"\n",(0,o.jsxs)(n.h2,{id:"ros2s-sensor_msgsmsgpointcloud2-message",children:["ROS2's ",(0,o.jsx)(n.code,{children:"sensor_msgs/msg/PointCloud2"})," Message"]}),"\n",(0,o.jsxs)(n.p,{children:["The message definition ",(0,o.jsx)(n.a,{href:"https://docs.ros2.org/foxy/api/sensor_msgs/msg/PointCloud2.html",children:"sensor_msgs/PointCloud2"})," is ROS' standard point cloud message format.\nEach message contains a collection of XYZ points, which may also contain additional information such as timestamp, intensity or ring number. Feel free to read the documentation of ",(0,o.jsx)(n.a,{href:"https://docs.ros2.org/foxy/api/sensor_msgs/msg/PointCloud2.html",children:"sensor_msgs/msg/PointCloud2"})," to learn more details about it."]}),"\n",(0,o.jsx)(n.h2,{id:"build-and-source-the-package",children:"Build and source the package"}),"\n",(0,o.jsxs)(n.p,{children:["The code for the image segmentation inference node can be found in the directory ",(0,o.jsx)(n.code,{children:"src/section_2/pointcloud_segmentation_r2"}),". The structure of this ",(0,o.jsx)(n.strong,{children:"Python package"})," is illustrated in the following:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"pointcloud_segmentation_r2/\n\u251c\u2500\u2500 package.xml\n\u251c\u2500\u2500 setup.cfg\n\u251c\u2500\u2500 setup.py\n\u251c\u2500\u2500 config\n    \u2514\u2500\u2500 params.yaml\n\u251c\u2500\u2500 assets\n\u2502\xa0\xa0 \u251c\u2500\u2500 image1.png\n\u2502\xa0\xa0 \u251c\u2500\u2500 image2.png\n\u2502\xa0\xa0 \u251c\u2500\u2500 video1.gif\n\u2502\xa0\xa0 \u2514\u2500\u2500 video2.gif\n\u251c\u2500\u2500 launch\n\u2502\xa0\xa0 \u2514\u2500\u2500 start_all.launch\n\u251c\u2500\u2500 models\n\u2502\xa0\xa0 \u251c\u2500\u2500 class_id_to_rgb.xml\n\u2502\xa0\xa0 \u2514\u2500\u2500 miou62_squeezeseg\n\u2502\xa0\xa0     \u251c\u2500\u2500 saved_model.pb\n        \u251c\u2500\u2500 keras_metadata.pb\n\u2502\xa0\xa0     \u2514\u2500\u2500 variables\n\u2502\xa0\xa0         \u251c\u2500\u2500 variables.data-00000-of-00001\n\u2502\xa0\xa0         \u2514\u2500\u2500 variables.index\n\u2514\u2500\u2500 pointcloud_segmentation_r2\n\u2502   |\u2500\u2500 pointcloud_segmentation.py\n|   \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 resource\n\u2514\u2500\u2500 test    \n"})}),"\n",(0,o.jsxs)(n.p,{children:["The inference node source code is located in ",(0,o.jsx)(n.code,{children:"pointcloud_segmentation_r2/pointcloud_segmentation.py"}),". The pretrained model is located in the directory ",(0,o.jsx)(n.code,{children:"models"}),". The launch file and parameters are located in directory ",(0,o.jsx)(n.code,{children:"launch"}),". The conversion between RGB encoding and class IDs are defined in ",(0,o.jsx)(n.code,{children:"class_id_to_rgb.xml"}),". Feel free to read all the code, parameters and launch files to get a in-depth understanding how this inference node is working."]}),"\n",(0,o.jsx)(n.p,{children:"Note that the provided point cloud segmentation model is quite similar to the one you have trained in the assignment, but it was trained on a much larger dataset consisting of 40000 training samples."}),"\n",(0,o.jsxs)(n.p,{children:["Now, let's build the package with with ",(0,o.jsx)(n.code,{children:"colcon build"})]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"colcon build --packages-select pointcloud_segmentation_r2 --symlink-install\n"})}),"\n",(0,o.jsx)(n.p,{children:"and source the workspace"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"source install/setup.bash\n"})}),"\n",(0,o.jsx)(n.p,{children:"Perfect! Now you will be able to perform inference on point cloud data with this package. Let's go to the next section."}),"\n",(0,o.jsx)(n.h1,{id:"replay-rosbag-and-run-pointcloud-segmentation",children:"Replay rosbag and run pointcloud segmentation"}),"\n",(0,o.jsx)(n.p,{children:"We have already prepared a launch file for you to execute the image segmentation. Please read carefully through the following lines of code."}),"\n",(0,o.jsxs)(n.p,{children:["Contents of the file ",(0,o.jsx)(n.code,{children:"image_segmentation_r2.launch.py"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:"import os\n\nfrom ament_index_python.packages import get_package_share_directory\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument\nfrom launch_ros.actions import Node\nfrom launch.actions import ExecuteProcess\n\ndef generate_launch_description():\n\n    # Get the package and params directory\n    image_segmentation_dir = get_package_share_directory('pointcloud_segmentation_r2')\n    config = os.path.join(image_segmentation_dir, \"config\",\"params.yaml\")\n    \n    # Declare launch arguments\n    use_sim_time = DeclareLaunchArgument(\n        'use_sim_time',\n        default_value='true',\n        description='Use simulation clock time')\n        \n    # ROSBAG PLAY node\n    rosbag_play_node = ExecuteProcess(\n        cmd=['ros2', 'bag', 'play','--rate', '0.75', '-l',\n             '/home/rosuser/bag/lidar_campus_melaten',\n        ],\n        output='screen'\n    )\n        # CAMERA SEGMENTATION NODE\n    pointcloud_segmentation_node = Node(\n        package='pointcloud_segmentation_r2',\n        name='pointcloud_segmentation',\n        executable='pointcloud_segmentation',\n        output='screen',\n        parameters=[config]\n    )\n\n    # Create the launch description and populate\n    ld = LaunchDescription()\n\n    # Add the actions to the launch description\n    ld.add_action(use_sim_time)\n    ld.add_action(rosbag_play_node)\n    ld.add_action(pointcloud_segmentation_node)\n\n    return ld\n\n"})}),"\n",(0,o.jsx)(n.p,{children:"This launch file will start the following tasks:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Replay the rosbag"})," with a speed of 0.75. Feel free to adjust this replay speed depending on the performance of your hardware."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["Start the ",(0,o.jsx)(n.code,{children:"pointcloud_segmentation_py"})]})," node with the parameters__ that are necessary for the ",(0,o.jsx)(n.code,{children:"pointcloud_segmentation_py"})," node.\nNote, that ",(0,o.jsx)(n.code,{children:"params.yaml"})," contains the parameter"]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yml",children:"do_visualizations: True\n"})}),"\n",(0,o.jsxs)(n.p,{children:["which will enable an internal visualization of the segmented point cloud. You can also set this value to ",(0,o.jsx)(n.code,{children:"False"})," and visualize the point cloud with RVIZ."]}),"\n",(0,o.jsx)(n.p,{children:"We can now start the launch file with:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"ros2 launch pointcloud_segmentation_r2 pointcloud_segmentation_r2.launch.py \n"})}),"\n",(0,o.jsx)(n.p,{children:"You should see now the model's prediction as shown in the image below."}),"\n",(0,o.jsx)("img",{src:"../images/uploads/4a7ce26ec2d312a8a6396adaab190936/image.png",alt:"Description of image"}),"\n",(0,o.jsx)(n.h2,{id:"review-of-file-pointcloud_segmentationpy",children:"Review of file pointcloud_segmentation.py"}),"\n",(0,o.jsxs)(n.p,{children:["Before we start with the programming exercise, lets get an overview about the point cloud segmentation node ",(0,o.jsx)(n.a,{href:"https://github.com/ika-rwth-aachen/acdc/blob/main/colcon_workspace/src/section_2/pointcloud_segmentation_r2/image_segmentation_r2/image_segmentation.py",children:(0,o.jsx)(n.code,{children:"pointcloud_segmentation.py"})}),".Note, the segmentation node is quite complex and we do not require you to implement any in-depth function. We would like to encourage you to read the code and try to understand what each function is doing. To help you we have generated a little summary about the structure of the inference node."]}),"\n",(0,o.jsxs)(n.p,{children:["The inference node is implemented as a Python class called ",(0,o.jsx)(n.code,{children:"PCLSegmentation"}),". The class has the following member functions. We will give here a short description of each class so you can understand what each class is doing."]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"class PCLSegmentation"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["Class which implements the point cloud segmentation task. Listens on a topic of type ",(0,o.jsx)(n.code,{children:"PointCloud2"})," converts the point cloud to a 2D representation, applies point cloud segmentation and publishes the segmented point cloud on a ",(0,o.jsx)(n.code,{children:"PointCloud2"})," topic."]})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"__init__(self)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Calls all necessary functions for the initialization of the node"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"def setup(self)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["Loads and initializes the segmentation model from a file. Creates subscriber ",(0,o.jsx)(n.code,{children:"self.sub_pcl"})," and publisher ",(0,o.jsx)(n.code,{children:"self.pub_seg"})," which listen and send ",(0,o.jsx)(n.code,{children:"PointCloud2"})]})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"load_parameters(self)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Loads all ROS params and stores them as class members attributes,"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"parse_convert_xml(self, conversion_file_path)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["Reads the xml file from directory ",(0,o.jsx)(n.code,{children:"convert_xml"})," and constructs all necessary variables for the class ID to color association."]})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"def predict(self, pcl_msg)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["Callback function which is triggered when a new message of type ",(0,o.jsx)(n.code,{children:"PointCloud2"})," arrives at the subscriber ",(0,o.jsx)(n.code,{children:"self.sub_pcl"})]})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"make_point_field(self)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["Helper function to create a ",(0,o.jsx)(n.code,{children:"PointCloud2"})," with several fields."]})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"rgb_to_float(self, color)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Helper function which can convert a RGB value to a packed float value"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"hv_in_range(self, x, y, z, fov, fov_type='h')"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Function which can apply a field of view (FOV) to points with X, Y, Z values."})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"pcl_spherical_projection(self, pcl, height, width, num_channels, leftPhi, rightPhi)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Function which does a spherical projection of a 3D point cloud to a 2D representation"})}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.h2,{id:"task-1-instantiate-pointcloud2-publisher-for-the-segmented-point-cloud",children:["Task 1: Instantiate ",(0,o.jsx)(n.code,{children:"PointCloud2"})," publisher for the segmented point cloud"]}),"\n",(0,o.jsx)(n.p,{children:"In this task, you will have the easy task to implement a publisher for the segmented point cloud. As you may know, the publisher takes specific messages and sends them via the ROS Framework to other processing or visualization nodes."}),"\n",(0,o.jsxs)(n.p,{children:["Read the function ",(0,o.jsx)(n.code,{children:"setup()"})," in the file ",(0,o.jsx)(n.code,{children:"pointcloud_segmentation.py"}),". Here all important class members are created that will be called in later during the inference. You can see that we instantiate the segmentation model as ",(0,o.jsx)(n.code,{children:"self.model"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["We also instantiate the subscriber for the ",(0,o.jsx)(n.code,{children:"/points2"})," topic as ",(0,o.jsx)(n.code,{children:"self.sub_pcl"}),". The subscriber is connected with the function ",(0,o.jsx)(n.code,{children:"self.predict"}),". Whenever a new message of type ",(0,o.jsx)(n.code,{children:"PointCloud2"})," arrives on ",(0,o.jsx)(n.code,{children:"/point2"}),", then the callback ",(0,o.jsx)(n.code,{children:"self.predict"})," is called."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def setup(self):\n    # load inference model\n    self.model = tf.keras.models.load_model(self.model_path)\n\n    # create point field for cloud_creator\n    self.point_field = self.make_point_field()\n\n    ### START TASK 1 CODE HERE ###\n    # create publisher for the segmented point cloud, publish on topic "points2_segmented"\n    # Publish type PointCloud2 data format\n\n    ### END TASK 1 CODE HERE ###\n\n    # create points2 subcriber and listen to topic /points2\n    self.sub_pcl = self.create_subscription(PointCloud2, "/points2", self.predict, 1)\n'})}),"\n",(0,o.jsxs)(n.p,{children:["Your task is now to implement a ",(0,o.jsx)(n.code,{children:"PointCloud2"})," publisher."]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Hints:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Have a look how a ",(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html",children:"self.create_publisher()"})," works"]}),"\n",(0,o.jsxs)(n.li,{children:["We want to send messages on topic ",(0,o.jsx)(n.code,{children:"/points2_segmented"})]}),"\n",(0,o.jsxs)(n.li,{children:["We want to send messages of type ",(0,o.jsx)(n.code,{children:"PointCloud2"})," which are already imported by ",(0,o.jsx)(n.code,{children:"from sensor_msgs.msg import PointCloud2"})]}),"\n",(0,o.jsxs)(n.li,{children:["Use a ",(0,o.jsx)(n.code,{children:"queue_size"})," of 1"]}),"\n",(0,o.jsx)(n.li,{children:"Save the publisher as a class member attribute"}),"\n"]}),"\n",(0,o.jsxs)(n.h2,{id:"task-2-publish-a-pointcloud2-message-containing-the-segmented-point-cloud-with-the-publisher",children:["Task 2: Publish a ",(0,o.jsx)(n.code,{children:"PointCloud2"})," message containing the segmented point cloud with the publisher"]}),"\n",(0,o.jsxs)(n.p,{children:["Ok, now you should have setup the publisher. Now, we need to call the publisher after we perform inference in order to publish the segmented point cloud on topic ",(0,o.jsx)(n.code,{children:"/points2_segmented"}),". The following code block is a snippet from function ",(0,o.jsx)(n.code,{children:"def predict(self, pcl_msg)"})," in the file ",(0,o.jsx)(n.code,{children:"pointcloud_segmentation.py"}),"."]}),"\n",(0,o.jsx)(n.p,{children:"You will now have to call the publisher here"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'[ ... ]\n# create list of points\npoints = list(zip(x, y, z, i, l, rgb_float))\n\nsegmented_pcl_msg = pc2.create_cloud(header=pcl_msg.header,\n                                     fields=self.point_field,\n                                     points=points)\n\n### START TASK 2 CODE HERE ###\n\n# call publisher to publish "segmented_pcl_msg"\n\n### END TASK 2 CODE HERE###\n\n'})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Hints:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Use ",(0,o.jsx)(n.code,{children:".publish()"})]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"run-node-and-use-rviz-for-visualization",children:"Run Node and use RVIZ for visualization"}),"\n",(0,o.jsx)(n.p,{children:"Great, so now our inference node also publishes the segmented point cloud and we can now use RVIZ to visualize the segmented point cloud. You can open another terminal and start RVIZ:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"ros2 run rviz2 rviz2\n"})}),"\n",(0,o.jsx)(n.p,{children:"In RVIZ you could try to visualize the segmented point cloud to obtain an image as shown below."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Hints:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Add -> By Topic -> ",(0,o.jsx)(n.code,{children:"/points2_segmented"})," - ",(0,o.jsx)(n.code,{children:"PointCloud2"})," -> OK"]}),"\n",(0,o.jsxs)(n.li,{children:["Set the parameter ",(0,o.jsx)(n.code,{children:"Global Options / Fixed Frame"})," to ",(0,o.jsx)(n.code,{children:"vlp16_link"})]}),"\n",(0,o.jsxs)(n.li,{children:["Increase the ",(0,o.jsx)(n.code,{children:"Size"})," of the points"]}),"\n"]}),"\n",(0,o.jsx)("img",{src:"../images/uploads/cb4ded5b551f6fe13d9efeeac8180b86/image1.png",alt:"Description of image"}),"\n",(0,o.jsx)(n.h2,{id:"wrap-up",children:"Wrap-up"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["You learned about the ROS2 standard definition for point cloud data which is called ",(0,o.jsx)(n.code,{children:"sensor_msgs/PointCloud2"})]}),"\n",(0,o.jsx)(n.li,{children:"You learned about a simple ROS2 package for semantic point cloud segmentation"}),"\n",(0,o.jsx)(n.li,{children:"You learned how to write a ROS2 publisher which publishes point cloud data"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"ros1-instructions",children:"ROS1 Instructions"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:"https://img.shields.io/badge/ROS1-blue",alt:"ROS1"})}),"\n",(0,o.jsx)("img",{src:"../images/video2.gif",alt:"Description of image"}),"\n",(0,o.jsx)(n.h4,{id:"perform-deep-learning-based-semantic-point-cloud-segmentation-1",children:"Perform Deep Learning based Semantic Point Cloud Segmentation"}),"\n",(0,o.jsxs)(n.p,{children:["In this workshop, we will perform ",(0,o.jsx)(n.strong,{children:"semantic point cloud segmentation"})," on raw LiDAR data using the deep learning model from the notebooks. In particular, we will take a recording from our test vehicle which is equipped with a Velodyne VLP-32C and we will apply our detection model on the raw sensor data."]}),"\n",(0,o.jsx)(n.p,{children:"The  learning goals of this workshop are"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Inspect a rosbag which contains point cloud data"}),"\n",(0,o.jsxs)(n.li,{children:["Learn about ROS' standard point cloud message definition ",(0,o.jsx)(n.code,{children:"points2"})]}),"\n",(0,o.jsx)(n.li,{children:"Learn about a simple Python inference node for semantic point cloud segmentation"}),"\n",(0,o.jsx)(n.li,{children:"Implement a ROS publisher which publishes the segmented point cloud"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"use-the-docker-environment",children:"Use the Docker Environment"}),"\n",(0,o.jsxs)(n.p,{children:["Navigate to the local directory ",(0,o.jsx)(n.code,{children:"acdc/docker"})," and execute ",(0,o.jsx)(n.code,{children:"./ros1_run.sh"}),". This will start the Docker container, in which ROS and all required libraries are preinstalled. You can stop the container by pressing ",(0,o.jsx)("kbd",{children:"Ctrl"}),"+",(0,o.jsx)("kbd",{children:"C"})," in the terminal. If everything is setup correctly you will see the following:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Starting container ...\nStarting container in mode: gpu\nnon-network local connections being added to access control list\nContainer setup:\n- Ubuntu: 20.04.2 LTS (Focal Fossa) (user: rosuser, password: rosuser)\n- CUDA: Cuda compilation tools, release 11.2, V11.2.152\n- cuDNN: 8.1.0\n- TensorRT: 8.0.3\n- TensorFlow Python3: 2.6.0 (GPUs available: 1)\n- TensorFlow C/C++: 2.6\n- ROS: noetic\n- CMake: cmake version 3.12.3\n\nTemplate Commands:\n- Create new ROS package:            ros-add-package\n  - Add node to package:               ros-add-node\n  - Add nodelet to package:            ros-add-nodelet\n- Initialize ROS GitLab repository:  ros-init-repo\n\nhttps://gitlab.ika.rwth-aachen.de/automated-driving/docker#templates\n\nThe container is running. Execute the run script again from another terminal to open a shell in the container or press `CTRL-C` to stop the container.\n"})}),"\n",(0,o.jsxs)(n.p,{children:["From another terminal, execute ",(0,o.jsx)(n.code,{children:"./ros1_run.sh"})," again to open a shell in the running container. You should see this:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Attaching to running container ...\n===================================================================\n= ROS Docker Container                                            =\n===================================================================\n\nThis is the image.\nrosuser@******:~/ws/catkin_workspace$\n"})}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"acdc"})," folder is mounted from your host into the container. Note that your current working directory in the container is ",(0,o.jsx)(n.code,{children:"/home/rosuser/ws/catkin_workspace"}),"."]}),"\n",(0,o.jsx)(n.h2,{id:"download-and-inspect-bag-file-1",children:"Download and inspect bag file"}),"\n",(0,o.jsxs)(n.p,{children:["Download the file ",(0,o.jsx)(n.code,{children:"lidar_campus_melaten.bag"})," from ",(0,o.jsx)(n.a,{href:"https://rwth-aachen.sciebo.de/s/udlMYloXpCdVtyp",children:"here (1.7 GB)"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["Save this file to your local directory ",(0,o.jsx)(n.code,{children:"${REPOSITORY}/bag"}),". This directory will be mounted into the docker container to the path ",(0,o.jsx)(n.code,{children:"/home/rosuser/bag"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["You can start the docker container now with ",(0,o.jsx)(n.code,{children:"./ros1_run.sh"})," (if you haven't already)."]}),"\n",(0,o.jsxs)(n.p,{children:["Inside the container, you can navigate to ",(0,o.jsx)(n.code,{children:"/home/rosuser/bag"})," and execute ",(0,o.jsx)(n.code,{children:"rosbag info lidar_campus_melaten.bag"})," to inspect the rosbag:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"~/bag$ rosbag info lidar_campus_melaten.bag \npath:        lidar_campus_melaten.bag\nversion:     2.0\nduration:    1:59s (119s)\nstart:       Feb 05 2020 16:25:31.41 (1580916331.41)\nend:         Feb 05 2020 16:27:31.37 (1580916451.37)\nsize:        1.5 GB\nmessages:    1200\ncompression: none [1199/1199 chunks]\ntypes:       sensor_msgs/PointCloud2 [1158d486dd51d683ce2f1be655c3c181]\n             tf2_msgs/TFMessage      [94810edda583a504dfda3829e70d7eec]\ntopics:      /points2     1199 msgs    : sensor_msgs/PointCloud2\n             /tf_static      1 msg     : tf2_msgs/TFMessage\n"})}),"\n",(0,o.jsxs)(n.p,{children:["You can see that the rosbag has a duration of 1 minute and 59 seconds and contains 1199 frames of type ",(0,o.jsx)(n.code,{children:"sensor_msgs/PointCloud2"}),". We will use these point cloud data in this assignment in order to apply semantic point cloud segmentation."]}),"\n",(0,o.jsxs)(n.h2,{id:"ross-sensor_msgspointcloud2-message",children:["ROS's ",(0,o.jsx)(n.code,{children:"sensor_msgs/PointCloud2"})," Message"]}),"\n",(0,o.jsxs)(n.p,{children:["The message definition ",(0,o.jsx)(n.a,{href:"http://docs.ros.org/en/melodic/api/sensor_msgs/html/msg/PointCloud2.html",children:"sensor_msgs/PointCloud2"})," is ROS' standard point cloud message format.\nEach message contains a collection of XYZ points, which may also contain additional information such as timestamp, intensity or ring number. Feel free to read the documentation of ",(0,o.jsx)(n.a,{href:"http://docs.ros.org/en/melodic/api/sensor_msgs/html/msg/PointCloud2.html",children:"sensor_msgs/PointCloud2"})," to learn more details about it."]}),"\n",(0,o.jsx)(n.h2,{id:"build-and-source-the-package-1",children:"Build and source the package"}),"\n",(0,o.jsxs)(n.p,{children:["The code for the point cloud segmentation inference node can be found in the directory ",(0,o.jsx)(n.code,{children:"catkin_workspace/src/workshops/section_2/pointcloud_segmentation_py"}),". The structure of this ",(0,o.jsx)(n.strong,{children:"Python package"})," is illustrated in the following:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"pointcloud_segmentation_py/\n\u251c\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 package.xml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 assets\n\u2502\xa0\xa0 \u251c\u2500\u2500 image1.png\n\u2502\xa0\xa0 \u251c\u2500\u2500 image2.png\n\u2502\xa0\xa0 \u251c\u2500\u2500 video1.gif\n\u2502\xa0\xa0 \u2514\u2500\u2500 video2.gif\n\u251c\u2500\u2500 convert_xml\n\u2502\xa0\xa0 \u2514\u2500\u2500 class_id_to_rgb.xml\n\u251c\u2500\u2500 launch\n\u2502\xa0\xa0 \u251c\u2500\u2500 params.yaml\n\u2502\xa0\xa0 \u2514\u2500\u2500 start_all.launch\n\u251c\u2500\u2500 models\n\u2502\xa0\xa0 \u2514\u2500\u2500 miou62_squeezeseg\n\u2502\xa0\xa0     \u251c\u2500\u2500 saved_model.pb\n\u2502\xa0\xa0     \u2514\u2500\u2500 variables\n\u2502\xa0\xa0         \u251c\u2500\u2500 variables.data-00000-of-00001\n\u2502\xa0\xa0         \u2514\u2500\u2500 variables.index\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500 pointcloud_segmentation.py\n"})}),"\n",(0,o.jsxs)(n.p,{children:["The inference node source code is located in ",(0,o.jsx)(n.code,{children:"src/pointcloud_segmentation.py"}),". The pretrained model is located in the directory ",(0,o.jsx)(n.code,{children:"models"}),". The launch file and parameters are located in directory ",(0,o.jsx)(n.code,{children:"launch"}),". The conversion between RGB encoding and class IDs are defined in ",(0,o.jsx)(n.code,{children:"class_id_to_rgb.xml"}),". Feel free to read all the code, parameters and launch files to get a in-depth understanding how this inference node is working."]}),"\n",(0,o.jsx)(n.p,{children:"Note that the provided point cloud segmentation model is quite similar to the one you have trained in the assignment, but it was trained on a much larger dataset consisting of 40000 training samples."}),"\n",(0,o.jsxs)(n.p,{children:["Now, let's build the package with ",(0,o.jsx)(n.code,{children:"catkin build"})]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"catkin build pointcloud_segmentation_py\n"})}),"\n",(0,o.jsx)(n.p,{children:"and source the workspace"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"source devel/setup.bash\n"})}),"\n",(0,o.jsx)(n.p,{children:"Perfect! Now you will be able to perform inference on point cloud data with this package. Let's go to the next section."}),"\n",(0,o.jsx)(n.h2,{id:"replay-rosbag-and-run-point-cloud-segmentation",children:"Replay rosbag and run point cloud segmentation"}),"\n",(0,o.jsx)(n.p,{children:"We have already prepared a launch file for you to execute the point cloud segmentation model. Please read carefully through the following lines of code."}),"\n",(0,o.jsxs)(n.p,{children:["Contents of the file ",(0,o.jsx)(n.code,{children:"start_all.launch"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-xml",children:'<launch>\n    <param name ="/use_sim_time" value="true"/>\n\n    \x3c!-- PLAY ROSBAG--\x3e\n    <node \n        pkg="rosbag"\n        type="play"\n        args="--clock -l -r 0.75 /home/rosuser/bag/lidar_campus_melaten.bag"\n        name="player">\n    </node>\n\n    \x3c!--- PCL SEGMENTATION NODE Parameters --\x3e\n    <rosparam\n      command="load"\n      file="$(find pointcloud_segmentation_py)/launch/params.yaml">\n    </rosparam>\n\n    \x3c!-- PCL SEGMENTATION NODE --\x3e\n    <node\n        name="pointcloud_segmentation"\n        pkg="pointcloud_segmentation_py"\n        type="pointcloud_segmentation.py"\n        output="screen">\n    </node>\n</launch>\n'})}),"\n",(0,o.jsx)(n.p,{children:"This launch file will start the following tasks:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Replay the rosbag"})," with a speed of 0.75. Feel free to adjust this replay speed depending on the performance of your hardware."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Load the parameters"})," that are necessary for the ",(0,o.jsx)(n.code,{children:"pointcloud_segmentation_py"})," node"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["Start the ",(0,o.jsx)(n.code,{children:"pointcloud_segmentation_py"})]})," node"]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["Note, that ",(0,o.jsx)(n.code,{children:"params.yaml"})," contains the parameter"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yml",children:"do_visualizations: True\n"})}),"\n",(0,o.jsxs)(n.p,{children:["which will enable an internal visualization of the segmented point cloud. You can also set this value to ",(0,o.jsx)(n.code,{children:"False"})," and visualize the point cloud with RVIZ."]}),"\n",(0,o.jsx)(n.p,{children:"We can now start the launch file with:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"roslaunch pointcloud_segmentation_py start_all.launch\n"})}),"\n",(0,o.jsx)(n.p,{children:"You should see now the model's prediction as shown in the image below."}),"\n",(0,o.jsx)("img",{src:"../images/uploads/4a7ce26ec2d312a8a6396adaab190936/image.png",alt:"Description of image"}),"\n",(0,o.jsx)(n.h2,{id:"review-of-file-pointcloud_segmentationpy-1",children:"Review of file pointcloud_segmentation.py"}),"\n",(0,o.jsxs)(n.p,{children:["Before we start with the programming exercise, lets get an overview about the point cloud segmentation node ",(0,o.jsx)(n.a,{href:"https://github.com/ika-rwth-aachen/acdc/blob/main/catkin_workspace/src/workshops/section_2/pointcloud_segmentation_py/src/pointcloud_segmentation.py",children:(0,o.jsx)(n.code,{children:"pointcloud_segmentation.py"})}),". Note, the segmentation node is quite complex and we do not require you to implement any in-depth function. We would like to encourage you to read the code and try to understand what each function is doing. To help you we have generated a little summary about the structure of the inference node."]}),"\n",(0,o.jsxs)(n.p,{children:["The inference node is implemented as a Python class called ",(0,o.jsx)(n.code,{children:"PCLSegmentation"}),". The class has the following member functions. We will give here a short description of each class so you can understand what each class is doing."]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"class PCLSegmentation"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["Class which implements the point cloud segmentation task. Listens on a topic of type ",(0,o.jsx)(n.code,{children:"PointCloud2"})," converts the point cloud to a 2D representation, applies point cloud segmentation and publishes the segmented point cloud on a ",(0,o.jsx)(n.code,{children:"PointCloud2"})," topic."]})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"__init__(self)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Calls all necessary functions for the initialization of the node"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"def setup(self)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["Loads and initializes the segmentation model from a file. Creates subscriber ",(0,o.jsx)(n.code,{children:"self.sub_pcl"})," and publisher ",(0,o.jsx)(n.code,{children:"self.pub_seg"})," which listen and send ",(0,o.jsx)(n.code,{children:"PointCloud2"})]})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"load_parameters(self)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Loads all ROS params and stores them as class members attributes,"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"parse_convert_xml(self, conversion_file_path)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["Reads the xml file from directory ",(0,o.jsx)(n.code,{children:"convert_xml"})," and constructs all necessary variables for the class ID to color association."]})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"def predict(self, pcl_msg)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["Callback function which is triggered when a new message of type ",(0,o.jsx)(n.code,{children:"PointCloud2"})," arrives at the subscriber ",(0,o.jsx)(n.code,{children:"self.sub_pcl"})]})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"make_point_field(self)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["Helper function to create a ",(0,o.jsx)(n.code,{children:"PointCloud2"})," with several fields."]})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"rgb_to_float(self, color)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Helper function which can convert a RGB value to a packed float value"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"hv_in_range(self, x, y, z, fov, fov_type='h')"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Function which can apply a field of view (FOV) to points with X, Y, Z values."})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"pcl_spherical_projection(self, pcl, height, width, num_channels, leftPhi, rightPhi)"})})}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Function which does a spherical projection of a 3D point cloud to a 2D representation"})}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.h2,{id:"task-1-instantiate-pointcloud2-publisher-for-the-segmented-point-cloud-1",children:["Task 1: Instantiate ",(0,o.jsx)(n.code,{children:"PointCloud2"})," publisher for the segmented point cloud"]}),"\n",(0,o.jsx)(n.p,{children:"In this task, you will have the easy task to implement a publisher for the segmented point cloud. As you may know, the publisher takes specific messages and sends them via the ROS Framework to other processing or visualization nodes."}),"\n",(0,o.jsxs)(n.p,{children:["Read the function ",(0,o.jsx)(n.code,{children:"setup()"})," in the file ",(0,o.jsx)(n.code,{children:"pointcloud_segmentation.py"}),". Here all important class members are created that will be called in later during the inference. You can see that we instantiate the segmentation model as ",(0,o.jsx)(n.code,{children:"self.model"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["We also instantiate the subscriber for the ",(0,o.jsx)(n.code,{children:"/points2"})," topic as ",(0,o.jsx)(n.code,{children:"self.sub_pcl"}),". The subscriber is connected with the function ",(0,o.jsx)(n.code,{children:"self.predict"}),". Whenever a new message of type ",(0,o.jsx)(n.code,{children:"PointCloud2"})," arrives on ",(0,o.jsx)(n.code,{children:"/point2"}),", then the callback ",(0,o.jsx)(n.code,{children:"self.predict"})," is called."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def setup(self):\n    # load inference model\n    self.model = tf.keras.models.load_model(self.model_path)\n\n    # create point field for cloud_creator\n    self.point_field = self.make_point_field()\n\n    ### START TASK 1 CODE HERE ###\n    # create publisher for the segmented point cloud, publish on topic "points2_segmented"\n    # Publish type PointCloud2 data format\n\n    ### END TASK 1 CODE HERE ###\n\n    # create points2 subcriber and listen to topic /points2\n    self.sub_pcl = rospy.Subscriber("/points2", PointCloud2, self.predict, queue_size=1)\n'})}),"\n",(0,o.jsxs)(n.p,{children:["Your task is now to implement a ",(0,o.jsx)(n.code,{children:"PointCloud2"})," publisher."]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Hints:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Have a look how a ",(0,o.jsx)(n.a,{href:"https://wiki.ros.org/rospy/Overview/Publishers%20and%20Subscribers",children:"rospy.Publisher()"})," works"]}),"\n",(0,o.jsxs)(n.li,{children:["We want to send messages on topic ",(0,o.jsx)(n.code,{children:"/points2_segmented"})]}),"\n",(0,o.jsxs)(n.li,{children:["We want to send messages of type ",(0,o.jsx)(n.code,{children:"PointCloud2"})," which are already imported by ",(0,o.jsx)(n.code,{children:"from sensor_msgs.msg import PointCloud2"})]}),"\n",(0,o.jsxs)(n.li,{children:["Use a ",(0,o.jsx)(n.code,{children:"queue_size"})," of 1"]}),"\n",(0,o.jsx)(n.li,{children:"Save the publisher as a class member attribute"}),"\n"]}),"\n",(0,o.jsxs)(n.h2,{id:"task-2-publish-a-pointcloud2-message-containing-the-segmented-point-cloud-with-the-publisher-1",children:["Task 2: Publish a ",(0,o.jsx)(n.code,{children:"PointCloud2"})," message containing the segmented point cloud with the publisher"]}),"\n",(0,o.jsxs)(n.p,{children:["Ok, now you should have setup the publisher. Now, we need to call the publisher after we perform inference in order to publish the segmented point cloud on topic ",(0,o.jsx)(n.code,{children:"/points2_segmented"}),". The following code block is a snippet from function ",(0,o.jsx)(n.code,{children:"def predict(self, pcl_msg)"})," in the file ",(0,o.jsx)(n.code,{children:"pointcloud_segmentation.py"}),"."]}),"\n",(0,o.jsx)(n.p,{children:"You will now have to call the publisher here"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'[ ... ]\n# create list of points\npoints = list(zip(x, y, z, i, l, rgb_float))\n\nsegmented_pcl_msg = pc2.create_cloud(header=pcl_msg.header,\n                                     fields=self.point_field,\n                                     points=points)\n\n### START TASK 2 CODE HERE ###\n\n# call publisher to publish "segmented_pcl_msg"\n\n### END TASK 2 CODE HERE###\n\n'})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Hints:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Use ",(0,o.jsx)(n.code,{children:".publish()"})]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"run-node-and-use-rviz-for-visualization-1",children:"Run Node and use RVIZ for visualization"}),"\n",(0,o.jsx)(n.p,{children:"Great, so now our inference node also publishes the segmented point cloud and we can now use RVIZ to visualize the segmented point cloud. You can open another terminal and start RVIZ. In RVIZ you could try to visualize the segmented point cloud to obtain an image as shown below."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"Hints:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Add -> By Topic -> ",(0,o.jsx)(n.code,{children:"/points2_segmented"})," - ",(0,o.jsx)(n.code,{children:"PointCloud2"})," -> OK"]}),"\n",(0,o.jsxs)(n.li,{children:["Set the parameter ",(0,o.jsx)(n.code,{children:"Global Options / Fixed Frame"})," to ",(0,o.jsx)(n.code,{children:"vlp16_link"})]}),"\n",(0,o.jsxs)(n.li,{children:["Increase the ",(0,o.jsx)(n.code,{children:"Size"})," of the points"]}),"\n"]}),"\n",(0,o.jsx)("img",{src:"../images/uploads/cb4ded5b551f6fe13d9efeeac8180b86/image1.png",alt:"Description of image"}),"\n",(0,o.jsx)(n.h2,{id:"wrap-up-1",children:"Wrap-up"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["You learned about the ROS standard definition for point cloud data which is called ",(0,o.jsx)(n.code,{children:"sensor_msgs/PointCloud2"})]}),"\n",(0,o.jsx)(n.li,{children:"You learned about a simple ROS package for semantic point cloud segmentation"}),"\n",(0,o.jsx)(n.li,{children:"You learned how to write a ROS publisher which publishes point cloud data"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>a});var i=s(6540);const o={},t=i.createContext(o);function l(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:l(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);